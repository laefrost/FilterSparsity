{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'filter_sparsity')\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from oto_modelling.pytorch_lenet5 import LeNet5\n",
    "from only_train_once.only_train_once import OTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size, test_batch_size): \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data.fashionMNIST', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.Pad(2),\n",
    "                        #transforms.RandomCrop(32),\n",
    "                        #transforms.RandomHorizontalFlip(),\n",
    "                        #transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5,), (0.5,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data.fashionMNIST', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def check_accuracy(model, testloader, two_input=False):\n",
    "    correct1 = 0\n",
    "    correct5 = 0\n",
    "    total = 0\n",
    "    model = model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            if two_input:\n",
    "                y_pred = model.forward(X, X)\n",
    "            else:\n",
    "                y_pred = model.forward(X)\n",
    "            total += y.size(0)\n",
    "\n",
    "            prec1, prec5 = accuracy_topk(y_pred.data, y, topk=(1, 5))\n",
    "            \n",
    "            correct1 += prec1.item()\n",
    "            correct5 += prec5.item()\n",
    "\n",
    "    model = model.train()\n",
    "    accuracy1 = correct1 / total\n",
    "    accuracy5 = correct5 / total\n",
    "    return accuracy1, accuracy5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(batch_size, test_batch_size): \n",
    "    train_loader, test_loader = get_loaders(batch_size, test_batch_size)\n",
    "    \n",
    "    model = LeNet5()\n",
    "    dummy_input = torch.rand(1, 1, 32, 32)\n",
    "    oto = OTO(model=model.cuda(), dummy_input=dummy_input.cuda())\n",
    "    \n",
    "    optimizer = oto.hesso(\n",
    "        variant='sgd', \n",
    "        lr=0.1, \n",
    "        weight_decay=1e-4,\n",
    "        target_group_sparsity=0.7,\n",
    "        start_pruning_step=10 * len(train_loader), \n",
    "        pruning_periods=10,\n",
    "        pruning_steps=10 * len(train_loader)\n",
    "    )\n",
    "    \n",
    "    max_epoch = 100\n",
    "    model.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Every 50 epochs, decay lr by 10.0\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1) \n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        f_avg_val = 0.0\n",
    "        model.train()\n",
    "        lr_scheduler.step()\n",
    "        for X, y in train_loader:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "            y_pred = model.forward(X)\n",
    "            f = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            f.backward()\n",
    "            f_avg_val += f\n",
    "            optimizer.step()\n",
    "        group_sparsity, param_norm, _ = optimizer.compute_group_sparsity_param_norm()\n",
    "        norm_important, norm_redundant, num_grps_important, num_grps_redundant = optimizer.compute_norm_groups()\n",
    "        # TODO: change accuracy metric or check that is does the correct thing\n",
    "        accuracy1, accuracy5 = check_accuracy(model, test_loader)\n",
    "        f_avg_val = f_avg_val.cpu().item() / len(train_loader)\n",
    "        \n",
    "        print(\"Ep: {ep}, loss: {f:.2f}, norm_all:{param_norm:.2f}, grp_sparsity: {gs:.2f}, acc1: {acc1:.4f}, norm_import: {norm_import:.2f}, norm_redund: {norm_redund:.2f}, num_grp_import: {num_grps_import}, num_grp_redund: {num_grps_redund}\"\\\n",
    "            .format(ep=epoch, f=f_avg_val, param_norm=param_norm, gs=group_sparsity, acc1=accuracy1,\\\n",
    "            norm_import=norm_important, norm_redund=norm_redundant, num_grps_import=num_grps_important, num_grps_redund=num_grps_redundant\n",
    "            ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
