{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'filter_sparsity')\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from polar_ns.train import fit_model\n",
    "from polar_ns.prune import main\n",
    "from polar_ns.fine_tune import fine_tune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_train = {\n",
    "    #'config' : [6, 'A', 16, 'A'],\n",
    "    'loss' : 'zol', \n",
    "    'lbd' : 0.0001, \n",
    "    'alpha' : 1, \n",
    "    't' : 25,\n",
    "    'epochs' : 50, \n",
    "    'batch_size' : 256, \n",
    "    'test_batch_size' : 256,\n",
    "    'max_epoch' : None, \n",
    "    'lr' : 0.15, \n",
    "    'momentum' : 0.9, \n",
    "    'weight_decay': 0.0, \n",
    "    'resume' : None,\n",
    "    'no_cuda': True, \n",
    "    'seed' : 1234, \n",
    "    'log_interval' : 10,\n",
    "    'bn_init_value' : 0.5, \n",
    "    'clamp' : 1.0, \n",
    "    'gate' : False, \n",
    "    'flops_weighted' : False,\n",
    "    'weight-max': None, \n",
    "    'weight-min' : None, \n",
    "    'bn_wd' : True, \n",
    "    'target-flops' : None, \n",
    "    'debug' : False,\n",
    "    'arch' : 'leNet', \n",
    "    'retrain' : False, \n",
    "    'save' : './checkpoints/', \n",
    "    'backup' : './backup/', \n",
    "    'log' : './events/',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5 make_layers: feature cfg [6, 'A', 16, 'A']\n",
      "Weight decay param: parameter name feature.0.conv.weight\n",
      "Weight decay param: parameter name feature.0.batch_norm.weight\n",
      "Weight decay param: parameter name feature.0.batch_norm.bias\n",
      "Weight decay param: parameter name feature.2.conv.weight\n",
      "Weight decay param: parameter name feature.2.batch_norm.weight\n",
      "Weight decay param: parameter name feature.2.batch_norm.bias\n",
      "Weight decay param: parameter name classifier.0.weight\n",
      "Weight decay param: parameter name classifier.0.bias\n",
      "Weight decay param: parameter name classifier.2.weight\n",
      "Weight decay param: parameter name classifier.2.bias\n",
      "Weight decay param: parameter name classifier.4.weight\n",
      "Weight decay param: parameter name classifier.4.bias\n",
      "Start epoch 0/50...\n",
      "Step: 1 Train Epoch: 0 [0/60000 (0.0%)]\tLoss: 2.330164\n",
      "Step: 11 Train Epoch: 0 [2560/60000 (4.3%)]\tLoss: 2.326730\n",
      "Step: 21 Train Epoch: 0 [5120/60000 (8.5%)]\tLoss: 2.327187\n",
      "Step: 31 Train Epoch: 0 [7680/60000 (12.8%)]\tLoss: 2.326176\n",
      "Step: 41 Train Epoch: 0 [10240/60000 (17.0%)]\tLoss: 2.322763\n",
      "Step: 51 Train Epoch: 0 [12800/60000 (21.3%)]\tLoss: 2.301907\n",
      "Step: 61 Train Epoch: 0 [15360/60000 (25.5%)]\tLoss: 2.219747\n",
      "Step: 71 Train Epoch: 0 [17920/60000 (29.8%)]\tLoss: 1.965673\n",
      "Step: 81 Train Epoch: 0 [20480/60000 (34.0%)]\tLoss: 1.681190\n",
      "Step: 91 Train Epoch: 0 [23040/60000 (38.3%)]\tLoss: 1.552760\n",
      "Step: 101 Train Epoch: 0 [25600/60000 (42.6%)]\tLoss: 1.539170\n",
      "Step: 111 Train Epoch: 0 [28160/60000 (46.8%)]\tLoss: 1.550634\n",
      "Step: 121 Train Epoch: 0 [30720/60000 (51.1%)]\tLoss: 1.409699\n",
      "Step: 131 Train Epoch: 0 [33280/60000 (55.3%)]\tLoss: 1.138878\n",
      "Step: 141 Train Epoch: 0 [35840/60000 (59.6%)]\tLoss: 1.093156\n",
      "Step: 151 Train Epoch: 0 [38400/60000 (63.8%)]\tLoss: 1.202486\n",
      "Step: 161 Train Epoch: 0 [40960/60000 (68.1%)]\tLoss: 1.086819\n",
      "Step: 171 Train Epoch: 0 [43520/60000 (72.3%)]\tLoss: 1.089881\n",
      "Step: 181 Train Epoch: 0 [46080/60000 (76.6%)]\tLoss: 0.858240\n",
      "Step: 191 Train Epoch: 0 [48640/60000 (80.9%)]\tLoss: 0.801816\n",
      "Step: 201 Train Epoch: 0 [51200/60000 (85.1%)]\tLoss: 0.787717\n",
      "Step: 211 Train Epoch: 0 [53760/60000 (89.4%)]\tLoss: 0.689216\n",
      "Step: 221 Train Epoch: 0 [56320/60000 (93.6%)]\tLoss: 0.687179\n",
      "Step: 231 Train Epoch: 0 [58880/60000 (97.9%)]\tLoss: 0.610854\n",
      "\n",
      "Test set: Average loss: 0.6457, Accuracy: 7353/10000 (73.5300%)\n",
      "\n",
      "Start epoch 1/50...\n",
      "Step: 236 Train Epoch: 1 [0/60000 (0.0%)]\tLoss: 0.664012\n",
      "Step: 246 Train Epoch: 1 [2560/60000 (4.3%)]\tLoss: 0.573409\n",
      "Step: 256 Train Epoch: 1 [5120/60000 (8.5%)]\tLoss: 0.505607\n",
      "Step: 266 Train Epoch: 1 [7680/60000 (12.8%)]\tLoss: 0.605992\n",
      "Step: 276 Train Epoch: 1 [10240/60000 (17.0%)]\tLoss: 0.461579\n",
      "Step: 286 Train Epoch: 1 [12800/60000 (21.3%)]\tLoss: 0.599291\n",
      "Step: 296 Train Epoch: 1 [15360/60000 (25.5%)]\tLoss: 0.515155\n",
      "Step: 306 Train Epoch: 1 [17920/60000 (29.8%)]\tLoss: 0.560467\n",
      "Step: 316 Train Epoch: 1 [20480/60000 (34.0%)]\tLoss: 0.538531\n",
      "Step: 326 Train Epoch: 1 [23040/60000 (38.3%)]\tLoss: 0.509439\n",
      "Step: 336 Train Epoch: 1 [25600/60000 (42.6%)]\tLoss: 0.546342\n",
      "Step: 346 Train Epoch: 1 [28160/60000 (46.8%)]\tLoss: 0.469578\n",
      "Step: 356 Train Epoch: 1 [30720/60000 (51.1%)]\tLoss: 0.536036\n",
      "Step: 366 Train Epoch: 1 [33280/60000 (55.3%)]\tLoss: 0.484192\n",
      "Step: 376 Train Epoch: 1 [35840/60000 (59.6%)]\tLoss: 0.525452\n",
      "Step: 386 Train Epoch: 1 [38400/60000 (63.8%)]\tLoss: 0.559554\n",
      "Step: 396 Train Epoch: 1 [40960/60000 (68.1%)]\tLoss: 0.487180\n",
      "Step: 406 Train Epoch: 1 [43520/60000 (72.3%)]\tLoss: 0.489340\n",
      "Step: 416 Train Epoch: 1 [46080/60000 (76.6%)]\tLoss: 0.460516\n",
      "Step: 426 Train Epoch: 1 [48640/60000 (80.9%)]\tLoss: 0.496612\n",
      "Step: 436 Train Epoch: 1 [51200/60000 (85.1%)]\tLoss: 0.495217\n",
      "Step: 446 Train Epoch: 1 [53760/60000 (89.4%)]\tLoss: 0.453976\n",
      "Step: 456 Train Epoch: 1 [56320/60000 (93.6%)]\tLoss: 0.381615\n",
      "Step: 466 Train Epoch: 1 [58880/60000 (97.9%)]\tLoss: 0.458949\n",
      "\n",
      "Test set: Average loss: 0.4294, Accuracy: 8404/10000 (84.0400%)\n",
      "\n",
      "Start epoch 2/50...\n",
      "Step: 471 Train Epoch: 2 [0/60000 (0.0%)]\tLoss: 0.342815\n",
      "Step: 481 Train Epoch: 2 [2560/60000 (4.3%)]\tLoss: 0.398004\n",
      "Step: 491 Train Epoch: 2 [5120/60000 (8.5%)]\tLoss: 0.366905\n",
      "Step: 501 Train Epoch: 2 [7680/60000 (12.8%)]\tLoss: 0.393105\n",
      "Step: 511 Train Epoch: 2 [10240/60000 (17.0%)]\tLoss: 0.379244\n",
      "Step: 521 Train Epoch: 2 [12800/60000 (21.3%)]\tLoss: 0.321781\n",
      "Step: 531 Train Epoch: 2 [15360/60000 (25.5%)]\tLoss: 0.415089\n",
      "Step: 541 Train Epoch: 2 [17920/60000 (29.8%)]\tLoss: 0.475467\n",
      "Step: 551 Train Epoch: 2 [20480/60000 (34.0%)]\tLoss: 0.295641\n",
      "Step: 561 Train Epoch: 2 [23040/60000 (38.3%)]\tLoss: 0.480222\n",
      "Step: 571 Train Epoch: 2 [25600/60000 (42.6%)]\tLoss: 0.398017\n",
      "Step: 581 Train Epoch: 2 [28160/60000 (46.8%)]\tLoss: 0.441586\n",
      "Step: 591 Train Epoch: 2 [30720/60000 (51.1%)]\tLoss: 0.453029\n",
      "Step: 601 Train Epoch: 2 [33280/60000 (55.3%)]\tLoss: 0.451084\n",
      "Step: 611 Train Epoch: 2 [35840/60000 (59.6%)]\tLoss: 0.367001\n",
      "Step: 621 Train Epoch: 2 [38400/60000 (63.8%)]\tLoss: 0.524191\n",
      "Step: 631 Train Epoch: 2 [40960/60000 (68.1%)]\tLoss: 0.434618\n",
      "Step: 641 Train Epoch: 2 [43520/60000 (72.3%)]\tLoss: 0.419593\n",
      "Step: 651 Train Epoch: 2 [46080/60000 (76.6%)]\tLoss: 0.356877\n",
      "Step: 661 Train Epoch: 2 [48640/60000 (80.9%)]\tLoss: 0.402053\n",
      "Step: 671 Train Epoch: 2 [51200/60000 (85.1%)]\tLoss: 0.397781\n",
      "Step: 681 Train Epoch: 2 [53760/60000 (89.4%)]\tLoss: 0.396024\n",
      "Step: 691 Train Epoch: 2 [56320/60000 (93.6%)]\tLoss: 0.364681\n",
      "Step: 701 Train Epoch: 2 [58880/60000 (97.9%)]\tLoss: 0.356750\n",
      "\n",
      "Test set: Average loss: 0.3643, Accuracy: 8655/10000 (86.5500%)\n",
      "\n",
      "Start epoch 3/50...\n",
      "Step: 706 Train Epoch: 3 [0/60000 (0.0%)]\tLoss: 0.371896\n",
      "Step: 716 Train Epoch: 3 [2560/60000 (4.3%)]\tLoss: 0.331501\n",
      "Step: 726 Train Epoch: 3 [5120/60000 (8.5%)]\tLoss: 0.309926\n",
      "Step: 736 Train Epoch: 3 [7680/60000 (12.8%)]\tLoss: 0.311620\n",
      "Step: 746 Train Epoch: 3 [10240/60000 (17.0%)]\tLoss: 0.386398\n",
      "Step: 756 Train Epoch: 3 [12800/60000 (21.3%)]\tLoss: 0.355112\n",
      "Step: 766 Train Epoch: 3 [15360/60000 (25.5%)]\tLoss: 0.356889\n",
      "Step: 776 Train Epoch: 3 [17920/60000 (29.8%)]\tLoss: 0.398833\n",
      "Step: 786 Train Epoch: 3 [20480/60000 (34.0%)]\tLoss: 0.426456\n",
      "Step: 796 Train Epoch: 3 [23040/60000 (38.3%)]\tLoss: 0.465255\n",
      "Step: 806 Train Epoch: 3 [25600/60000 (42.6%)]\tLoss: 0.349866\n",
      "Step: 816 Train Epoch: 3 [28160/60000 (46.8%)]\tLoss: 0.393282\n",
      "Step: 826 Train Epoch: 3 [30720/60000 (51.1%)]\tLoss: 0.376517\n",
      "Step: 836 Train Epoch: 3 [33280/60000 (55.3%)]\tLoss: 0.338963\n",
      "Step: 846 Train Epoch: 3 [35840/60000 (59.6%)]\tLoss: 0.345939\n",
      "Step: 856 Train Epoch: 3 [38400/60000 (63.8%)]\tLoss: 0.348577\n",
      "Step: 866 Train Epoch: 3 [40960/60000 (68.1%)]\tLoss: 0.416291\n",
      "Step: 876 Train Epoch: 3 [43520/60000 (72.3%)]\tLoss: 0.419112\n",
      "Step: 886 Train Epoch: 3 [46080/60000 (76.6%)]\tLoss: 0.337714\n",
      "Step: 896 Train Epoch: 3 [48640/60000 (80.9%)]\tLoss: 0.367808\n",
      "Step: 906 Train Epoch: 3 [51200/60000 (85.1%)]\tLoss: 0.300343\n",
      "Step: 916 Train Epoch: 3 [53760/60000 (89.4%)]\tLoss: 0.325031\n",
      "Step: 926 Train Epoch: 3 [56320/60000 (93.6%)]\tLoss: 0.385063\n",
      "Step: 936 Train Epoch: 3 [58880/60000 (97.9%)]\tLoss: 0.265362\n",
      "\n",
      "Test set: Average loss: 0.3534, Accuracy: 8696/10000 (86.9600%)\n",
      "\n",
      "Start epoch 4/50...\n",
      "Step: 941 Train Epoch: 4 [0/60000 (0.0%)]\tLoss: 0.426669\n",
      "Step: 951 Train Epoch: 4 [2560/60000 (4.3%)]\tLoss: 0.349875\n",
      "Step: 961 Train Epoch: 4 [5120/60000 (8.5%)]\tLoss: 0.363841\n",
      "Step: 971 Train Epoch: 4 [7680/60000 (12.8%)]\tLoss: 0.385066\n",
      "Step: 981 Train Epoch: 4 [10240/60000 (17.0%)]\tLoss: 0.400746\n",
      "Step: 991 Train Epoch: 4 [12800/60000 (21.3%)]\tLoss: 0.387100\n",
      "Step: 1001 Train Epoch: 4 [15360/60000 (25.5%)]\tLoss: 0.401168\n",
      "Step: 1011 Train Epoch: 4 [17920/60000 (29.8%)]\tLoss: 0.348981\n",
      "Step: 1021 Train Epoch: 4 [20480/60000 (34.0%)]\tLoss: 0.320009\n",
      "Step: 1031 Train Epoch: 4 [23040/60000 (38.3%)]\tLoss: 0.516175\n",
      "Step: 1041 Train Epoch: 4 [25600/60000 (42.6%)]\tLoss: 0.340417\n",
      "Step: 1051 Train Epoch: 4 [28160/60000 (46.8%)]\tLoss: 0.351743\n",
      "Step: 1061 Train Epoch: 4 [30720/60000 (51.1%)]\tLoss: 0.400477\n",
      "Step: 1071 Train Epoch: 4 [33280/60000 (55.3%)]\tLoss: 0.344294\n",
      "Step: 1081 Train Epoch: 4 [35840/60000 (59.6%)]\tLoss: 0.344345\n",
      "Step: 1091 Train Epoch: 4 [38400/60000 (63.8%)]\tLoss: 0.351469\n",
      "Step: 1101 Train Epoch: 4 [40960/60000 (68.1%)]\tLoss: 0.297966\n",
      "Step: 1111 Train Epoch: 4 [43520/60000 (72.3%)]\tLoss: 0.362138\n",
      "Step: 1121 Train Epoch: 4 [46080/60000 (76.6%)]\tLoss: 0.314128\n",
      "Step: 1131 Train Epoch: 4 [48640/60000 (80.9%)]\tLoss: 0.266551\n",
      "Step: 1141 Train Epoch: 4 [51200/60000 (85.1%)]\tLoss: 0.322533\n",
      "Step: 1151 Train Epoch: 4 [53760/60000 (89.4%)]\tLoss: 0.330608\n",
      "Step: 1161 Train Epoch: 4 [56320/60000 (93.6%)]\tLoss: 0.278956\n",
      "Step: 1171 Train Epoch: 4 [58880/60000 (97.9%)]\tLoss: 0.263132\n",
      "\n",
      "Test set: Average loss: 0.3918, Accuracy: 8615/10000 (86.1500%)\n",
      "\n",
      "Start epoch 5/50...\n",
      "Step: 1176 Train Epoch: 5 [0/60000 (0.0%)]\tLoss: 0.341793\n",
      "Step: 1186 Train Epoch: 5 [2560/60000 (4.3%)]\tLoss: 0.335352\n",
      "Step: 1196 Train Epoch: 5 [5120/60000 (8.5%)]\tLoss: 0.326548\n",
      "Step: 1206 Train Epoch: 5 [7680/60000 (12.8%)]\tLoss: 0.343874\n",
      "Step: 1216 Train Epoch: 5 [10240/60000 (17.0%)]\tLoss: 0.389045\n",
      "Step: 1226 Train Epoch: 5 [12800/60000 (21.3%)]\tLoss: 0.355692\n",
      "Step: 1236 Train Epoch: 5 [15360/60000 (25.5%)]\tLoss: 0.279152\n",
      "Step: 1246 Train Epoch: 5 [17920/60000 (29.8%)]\tLoss: 0.358799\n",
      "Step: 1256 Train Epoch: 5 [20480/60000 (34.0%)]\tLoss: 0.327465\n",
      "Step: 1266 Train Epoch: 5 [23040/60000 (38.3%)]\tLoss: 0.285314\n",
      "Step: 1276 Train Epoch: 5 [25600/60000 (42.6%)]\tLoss: 0.313370\n",
      "Step: 1286 Train Epoch: 5 [28160/60000 (46.8%)]\tLoss: 0.314141\n",
      "Step: 1296 Train Epoch: 5 [30720/60000 (51.1%)]\tLoss: 0.311692\n",
      "Step: 1306 Train Epoch: 5 [33280/60000 (55.3%)]\tLoss: 0.280205\n",
      "Step: 1316 Train Epoch: 5 [35840/60000 (59.6%)]\tLoss: 0.334136\n",
      "Step: 1326 Train Epoch: 5 [38400/60000 (63.8%)]\tLoss: 0.307106\n",
      "Step: 1336 Train Epoch: 5 [40960/60000 (68.1%)]\tLoss: 0.332216\n",
      "Step: 1346 Train Epoch: 5 [43520/60000 (72.3%)]\tLoss: 0.284877\n",
      "Step: 1356 Train Epoch: 5 [46080/60000 (76.6%)]\tLoss: 0.347978\n",
      "Step: 1366 Train Epoch: 5 [48640/60000 (80.9%)]\tLoss: 0.306781\n",
      "Step: 1376 Train Epoch: 5 [51200/60000 (85.1%)]\tLoss: 0.312867\n",
      "Step: 1386 Train Epoch: 5 [53760/60000 (89.4%)]\tLoss: 0.403190\n",
      "Step: 1396 Train Epoch: 5 [56320/60000 (93.6%)]\tLoss: 0.427449\n",
      "Step: 1406 Train Epoch: 5 [58880/60000 (97.9%)]\tLoss: 0.293760\n",
      "\n",
      "Test set: Average loss: 0.3612, Accuracy: 8735/10000 (87.3500%)\n",
      "\n",
      "Start epoch 6/50...\n",
      "Step: 1411 Train Epoch: 6 [0/60000 (0.0%)]\tLoss: 0.336806\n",
      "Step: 1421 Train Epoch: 6 [2560/60000 (4.3%)]\tLoss: 0.354732\n",
      "Step: 1431 Train Epoch: 6 [5120/60000 (8.5%)]\tLoss: 0.416218\n",
      "Step: 1441 Train Epoch: 6 [7680/60000 (12.8%)]\tLoss: 0.361657\n",
      "Step: 1451 Train Epoch: 6 [10240/60000 (17.0%)]\tLoss: 0.272707\n",
      "Step: 1461 Train Epoch: 6 [12800/60000 (21.3%)]\tLoss: 0.304358\n",
      "Step: 1471 Train Epoch: 6 [15360/60000 (25.5%)]\tLoss: 0.305568\n",
      "Step: 1481 Train Epoch: 6 [17920/60000 (29.8%)]\tLoss: 0.304556\n",
      "Step: 1491 Train Epoch: 6 [20480/60000 (34.0%)]\tLoss: 0.287258\n",
      "Step: 1501 Train Epoch: 6 [23040/60000 (38.3%)]\tLoss: 0.393670\n",
      "Step: 1511 Train Epoch: 6 [25600/60000 (42.6%)]\tLoss: 0.283892\n",
      "Step: 1521 Train Epoch: 6 [28160/60000 (46.8%)]\tLoss: 0.291235\n",
      "Step: 1531 Train Epoch: 6 [30720/60000 (51.1%)]\tLoss: 0.311496\n",
      "Step: 1541 Train Epoch: 6 [33280/60000 (55.3%)]\tLoss: 0.324472\n",
      "Step: 1551 Train Epoch: 6 [35840/60000 (59.6%)]\tLoss: 0.278808\n",
      "Step: 1561 Train Epoch: 6 [38400/60000 (63.8%)]\tLoss: 0.275378\n",
      "Step: 1571 Train Epoch: 6 [40960/60000 (68.1%)]\tLoss: 0.296035\n",
      "Step: 1581 Train Epoch: 6 [43520/60000 (72.3%)]\tLoss: 0.290087\n",
      "Step: 1591 Train Epoch: 6 [46080/60000 (76.6%)]\tLoss: 0.321283\n",
      "Step: 1601 Train Epoch: 6 [48640/60000 (80.9%)]\tLoss: 0.241527\n",
      "Step: 1611 Train Epoch: 6 [51200/60000 (85.1%)]\tLoss: 0.284747\n",
      "Step: 1621 Train Epoch: 6 [53760/60000 (89.4%)]\tLoss: 0.299604\n",
      "Step: 1631 Train Epoch: 6 [56320/60000 (93.6%)]\tLoss: 0.315170\n",
      "Step: 1641 Train Epoch: 6 [58880/60000 (97.9%)]\tLoss: 0.336663\n",
      "\n",
      "Test set: Average loss: 0.3293, Accuracy: 8806/10000 (88.0600%)\n",
      "\n",
      "Start epoch 7/50...\n",
      "Step: 1646 Train Epoch: 7 [0/60000 (0.0%)]\tLoss: 0.328828\n",
      "Step: 1656 Train Epoch: 7 [2560/60000 (4.3%)]\tLoss: 0.251228\n",
      "Step: 1666 Train Epoch: 7 [5120/60000 (8.5%)]\tLoss: 0.299723\n",
      "Step: 1676 Train Epoch: 7 [7680/60000 (12.8%)]\tLoss: 0.306604\n",
      "Step: 1686 Train Epoch: 7 [10240/60000 (17.0%)]\tLoss: 0.278778\n",
      "Step: 1696 Train Epoch: 7 [12800/60000 (21.3%)]\tLoss: 0.277899\n",
      "Step: 1706 Train Epoch: 7 [15360/60000 (25.5%)]\tLoss: 0.301181\n",
      "Step: 1716 Train Epoch: 7 [17920/60000 (29.8%)]\tLoss: 0.232758\n",
      "Step: 1726 Train Epoch: 7 [20480/60000 (34.0%)]\tLoss: 0.268398\n",
      "Step: 1736 Train Epoch: 7 [23040/60000 (38.3%)]\tLoss: 0.258232\n",
      "Step: 1746 Train Epoch: 7 [25600/60000 (42.6%)]\tLoss: 0.225036\n",
      "Step: 1756 Train Epoch: 7 [28160/60000 (46.8%)]\tLoss: 0.302328\n",
      "Step: 1766 Train Epoch: 7 [30720/60000 (51.1%)]\tLoss: 0.309919\n",
      "Step: 1776 Train Epoch: 7 [33280/60000 (55.3%)]\tLoss: 0.269172\n",
      "Step: 1786 Train Epoch: 7 [35840/60000 (59.6%)]\tLoss: 0.336659\n",
      "Step: 1796 Train Epoch: 7 [38400/60000 (63.8%)]\tLoss: 0.365634\n",
      "Step: 1806 Train Epoch: 7 [40960/60000 (68.1%)]\tLoss: 0.326945\n",
      "Step: 1816 Train Epoch: 7 [43520/60000 (72.3%)]\tLoss: 0.325644\n",
      "Step: 1826 Train Epoch: 7 [46080/60000 (76.6%)]\tLoss: 0.268503\n",
      "Step: 1836 Train Epoch: 7 [48640/60000 (80.9%)]\tLoss: 0.218564\n",
      "Step: 1846 Train Epoch: 7 [51200/60000 (85.1%)]\tLoss: 0.287974\n",
      "Step: 1856 Train Epoch: 7 [53760/60000 (89.4%)]\tLoss: 0.324700\n",
      "Step: 1866 Train Epoch: 7 [56320/60000 (93.6%)]\tLoss: 0.232750\n",
      "Step: 1876 Train Epoch: 7 [58880/60000 (97.9%)]\tLoss: 0.305404\n",
      "\n",
      "Test set: Average loss: 0.2949, Accuracy: 8905/10000 (89.0500%)\n",
      "\n",
      "Start epoch 8/50...\n",
      "Step: 1881 Train Epoch: 8 [0/60000 (0.0%)]\tLoss: 0.281330\n",
      "Step: 1891 Train Epoch: 8 [2560/60000 (4.3%)]\tLoss: 0.297072\n",
      "Step: 1901 Train Epoch: 8 [5120/60000 (8.5%)]\tLoss: 0.248014\n",
      "Step: 1911 Train Epoch: 8 [7680/60000 (12.8%)]\tLoss: 0.289635\n",
      "Step: 1921 Train Epoch: 8 [10240/60000 (17.0%)]\tLoss: 0.288312\n",
      "Step: 1931 Train Epoch: 8 [12800/60000 (21.3%)]\tLoss: 0.307724\n",
      "Step: 1941 Train Epoch: 8 [15360/60000 (25.5%)]\tLoss: 0.199339\n",
      "Step: 1951 Train Epoch: 8 [17920/60000 (29.8%)]\tLoss: 0.229046\n",
      "Step: 1961 Train Epoch: 8 [20480/60000 (34.0%)]\tLoss: 0.265582\n",
      "Step: 1971 Train Epoch: 8 [23040/60000 (38.3%)]\tLoss: 0.280307\n",
      "Step: 1981 Train Epoch: 8 [25600/60000 (42.6%)]\tLoss: 0.293670\n",
      "Step: 1991 Train Epoch: 8 [28160/60000 (46.8%)]\tLoss: 0.382678\n",
      "Step: 2001 Train Epoch: 8 [30720/60000 (51.1%)]\tLoss: 0.255107\n",
      "Step: 2011 Train Epoch: 8 [33280/60000 (55.3%)]\tLoss: 0.257473\n",
      "Step: 2021 Train Epoch: 8 [35840/60000 (59.6%)]\tLoss: 0.315260\n",
      "Step: 2031 Train Epoch: 8 [38400/60000 (63.8%)]\tLoss: 0.280871\n",
      "Step: 2041 Train Epoch: 8 [40960/60000 (68.1%)]\tLoss: 0.356894\n",
      "Step: 2051 Train Epoch: 8 [43520/60000 (72.3%)]\tLoss: 0.366026\n",
      "Step: 2061 Train Epoch: 8 [46080/60000 (76.6%)]\tLoss: 0.196020\n",
      "Step: 2071 Train Epoch: 8 [48640/60000 (80.9%)]\tLoss: 0.327250\n",
      "Step: 2081 Train Epoch: 8 [51200/60000 (85.1%)]\tLoss: 0.225974\n",
      "Step: 2091 Train Epoch: 8 [53760/60000 (89.4%)]\tLoss: 0.274694\n",
      "Step: 2101 Train Epoch: 8 [56320/60000 (93.6%)]\tLoss: 0.386166\n",
      "Step: 2111 Train Epoch: 8 [58880/60000 (97.9%)]\tLoss: 0.241851\n",
      "\n",
      "Test set: Average loss: 0.2798, Accuracy: 8967/10000 (89.6700%)\n",
      "\n",
      "Start epoch 9/50...\n",
      "Step: 2116 Train Epoch: 9 [0/60000 (0.0%)]\tLoss: 0.242427\n",
      "Step: 2126 Train Epoch: 9 [2560/60000 (4.3%)]\tLoss: 0.281426\n",
      "Step: 2136 Train Epoch: 9 [5120/60000 (8.5%)]\tLoss: 0.256902\n",
      "Step: 2146 Train Epoch: 9 [7680/60000 (12.8%)]\tLoss: 0.287423\n",
      "Step: 2156 Train Epoch: 9 [10240/60000 (17.0%)]\tLoss: 0.301624\n",
      "Step: 2166 Train Epoch: 9 [12800/60000 (21.3%)]\tLoss: 0.349820\n",
      "Step: 2176 Train Epoch: 9 [15360/60000 (25.5%)]\tLoss: 0.331078\n",
      "Step: 2186 Train Epoch: 9 [17920/60000 (29.8%)]\tLoss: 0.394817\n",
      "Step: 2196 Train Epoch: 9 [20480/60000 (34.0%)]\tLoss: 0.267634\n",
      "Step: 2206 Train Epoch: 9 [23040/60000 (38.3%)]\tLoss: 0.282128\n",
      "Step: 2216 Train Epoch: 9 [25600/60000 (42.6%)]\tLoss: 0.248503\n",
      "Step: 2226 Train Epoch: 9 [28160/60000 (46.8%)]\tLoss: 0.320638\n",
      "Step: 2236 Train Epoch: 9 [30720/60000 (51.1%)]\tLoss: 0.279526\n",
      "Step: 2246 Train Epoch: 9 [33280/60000 (55.3%)]\tLoss: 0.254810\n",
      "Step: 2256 Train Epoch: 9 [35840/60000 (59.6%)]\tLoss: 0.273307\n",
      "Step: 2266 Train Epoch: 9 [38400/60000 (63.8%)]\tLoss: 0.286708\n",
      "Step: 2276 Train Epoch: 9 [40960/60000 (68.1%)]\tLoss: 0.215009\n",
      "Step: 2286 Train Epoch: 9 [43520/60000 (72.3%)]\tLoss: 0.289514\n",
      "Step: 2296 Train Epoch: 9 [46080/60000 (76.6%)]\tLoss: 0.223996\n",
      "Step: 2306 Train Epoch: 9 [48640/60000 (80.9%)]\tLoss: 0.309197\n",
      "Step: 2316 Train Epoch: 9 [51200/60000 (85.1%)]\tLoss: 0.263072\n",
      "Step: 2326 Train Epoch: 9 [53760/60000 (89.4%)]\tLoss: 0.283800\n",
      "Step: 2336 Train Epoch: 9 [56320/60000 (93.6%)]\tLoss: 0.280021\n",
      "Step: 2346 Train Epoch: 9 [58880/60000 (97.9%)]\tLoss: 0.202730\n",
      "\n",
      "Test set: Average loss: 0.2960, Accuracy: 8930/10000 (89.3000%)\n",
      "\n",
      "Start epoch 10/50...\n",
      "Step: 2351 Train Epoch: 10 [0/60000 (0.0%)]\tLoss: 0.244495\n",
      "Step: 2361 Train Epoch: 10 [2560/60000 (4.3%)]\tLoss: 0.375883\n",
      "Step: 2371 Train Epoch: 10 [5120/60000 (8.5%)]\tLoss: 0.280849\n",
      "Step: 2381 Train Epoch: 10 [7680/60000 (12.8%)]\tLoss: 0.349316\n",
      "Step: 2391 Train Epoch: 10 [10240/60000 (17.0%)]\tLoss: 0.342498\n",
      "Step: 2401 Train Epoch: 10 [12800/60000 (21.3%)]\tLoss: 0.347470\n",
      "Step: 2411 Train Epoch: 10 [15360/60000 (25.5%)]\tLoss: 0.275376\n",
      "Step: 2421 Train Epoch: 10 [17920/60000 (29.8%)]\tLoss: 0.306625\n",
      "Step: 2431 Train Epoch: 10 [20480/60000 (34.0%)]\tLoss: 0.204361\n",
      "Step: 2441 Train Epoch: 10 [23040/60000 (38.3%)]\tLoss: 0.331124\n",
      "Step: 2451 Train Epoch: 10 [25600/60000 (42.6%)]\tLoss: 0.236307\n",
      "Step: 2461 Train Epoch: 10 [28160/60000 (46.8%)]\tLoss: 0.296915\n",
      "Step: 2471 Train Epoch: 10 [30720/60000 (51.1%)]\tLoss: 0.251603\n",
      "Step: 2481 Train Epoch: 10 [33280/60000 (55.3%)]\tLoss: 0.232651\n",
      "Step: 2491 Train Epoch: 10 [35840/60000 (59.6%)]\tLoss: 0.247172\n",
      "Step: 2501 Train Epoch: 10 [38400/60000 (63.8%)]\tLoss: 0.316691\n",
      "Step: 2511 Train Epoch: 10 [40960/60000 (68.1%)]\tLoss: 0.255900\n",
      "Step: 2521 Train Epoch: 10 [43520/60000 (72.3%)]\tLoss: 0.197910\n",
      "Step: 2531 Train Epoch: 10 [46080/60000 (76.6%)]\tLoss: 0.281050\n",
      "Step: 2541 Train Epoch: 10 [48640/60000 (80.9%)]\tLoss: 0.209307\n",
      "Step: 2551 Train Epoch: 10 [51200/60000 (85.1%)]\tLoss: 0.282758\n",
      "Step: 2561 Train Epoch: 10 [53760/60000 (89.4%)]\tLoss: 0.320861\n",
      "Step: 2571 Train Epoch: 10 [56320/60000 (93.6%)]\tLoss: 0.301739\n",
      "Step: 2581 Train Epoch: 10 [58880/60000 (97.9%)]\tLoss: 0.340306\n",
      "\n",
      "Test set: Average loss: 0.3441, Accuracy: 8762/10000 (87.6200%)\n",
      "\n",
      "Start epoch 11/50...\n",
      "Step: 2586 Train Epoch: 11 [0/60000 (0.0%)]\tLoss: 0.298819\n",
      "Step: 2596 Train Epoch: 11 [2560/60000 (4.3%)]\tLoss: 0.238972\n",
      "Step: 2606 Train Epoch: 11 [5120/60000 (8.5%)]\tLoss: 0.274329\n",
      "Step: 2616 Train Epoch: 11 [7680/60000 (12.8%)]\tLoss: 0.245657\n",
      "Step: 2626 Train Epoch: 11 [10240/60000 (17.0%)]\tLoss: 0.328386\n",
      "Step: 2636 Train Epoch: 11 [12800/60000 (21.3%)]\tLoss: 0.352831\n",
      "Step: 2646 Train Epoch: 11 [15360/60000 (25.5%)]\tLoss: 0.246104\n",
      "Step: 2656 Train Epoch: 11 [17920/60000 (29.8%)]\tLoss: 0.267147\n",
      "Step: 2666 Train Epoch: 11 [20480/60000 (34.0%)]\tLoss: 0.240230\n",
      "Step: 2676 Train Epoch: 11 [23040/60000 (38.3%)]\tLoss: 0.247096\n",
      "Step: 2686 Train Epoch: 11 [25600/60000 (42.6%)]\tLoss: 0.251357\n",
      "Step: 2696 Train Epoch: 11 [28160/60000 (46.8%)]\tLoss: 0.248739\n",
      "Step: 2706 Train Epoch: 11 [30720/60000 (51.1%)]\tLoss: 0.263339\n",
      "Step: 2716 Train Epoch: 11 [33280/60000 (55.3%)]\tLoss: 0.220588\n",
      "Step: 2726 Train Epoch: 11 [35840/60000 (59.6%)]\tLoss: 0.230684\n",
      "Step: 2736 Train Epoch: 11 [38400/60000 (63.8%)]\tLoss: 0.245558\n",
      "Step: 2746 Train Epoch: 11 [40960/60000 (68.1%)]\tLoss: 0.209512\n",
      "Step: 2756 Train Epoch: 11 [43520/60000 (72.3%)]\tLoss: 0.269995\n",
      "Step: 2766 Train Epoch: 11 [46080/60000 (76.6%)]\tLoss: 0.266190\n",
      "Step: 2776 Train Epoch: 11 [48640/60000 (80.9%)]\tLoss: 0.266643\n",
      "Step: 2786 Train Epoch: 11 [51200/60000 (85.1%)]\tLoss: 0.276366\n",
      "Step: 2796 Train Epoch: 11 [53760/60000 (89.4%)]\tLoss: 0.273145\n",
      "Step: 2806 Train Epoch: 11 [56320/60000 (93.6%)]\tLoss: 0.276735\n",
      "Step: 2816 Train Epoch: 11 [58880/60000 (97.9%)]\tLoss: 0.238828\n",
      "\n",
      "Test set: Average loss: 0.3117, Accuracy: 8867/10000 (88.6700%)\n",
      "\n",
      "Start epoch 12/50...\n",
      "Step: 2821 Train Epoch: 12 [0/60000 (0.0%)]\tLoss: 0.205541\n",
      "Step: 2831 Train Epoch: 12 [2560/60000 (4.3%)]\tLoss: 0.287333\n",
      "Step: 2841 Train Epoch: 12 [5120/60000 (8.5%)]\tLoss: 0.237416\n",
      "Step: 2851 Train Epoch: 12 [7680/60000 (12.8%)]\tLoss: 0.240727\n",
      "Step: 2861 Train Epoch: 12 [10240/60000 (17.0%)]\tLoss: 0.286860\n",
      "Step: 2871 Train Epoch: 12 [12800/60000 (21.3%)]\tLoss: 0.263783\n",
      "Step: 2881 Train Epoch: 12 [15360/60000 (25.5%)]\tLoss: 0.225347\n",
      "Step: 2891 Train Epoch: 12 [17920/60000 (29.8%)]\tLoss: 0.228153\n",
      "Step: 2901 Train Epoch: 12 [20480/60000 (34.0%)]\tLoss: 0.310120\n",
      "Step: 2911 Train Epoch: 12 [23040/60000 (38.3%)]\tLoss: 0.290512\n",
      "Step: 2921 Train Epoch: 12 [25600/60000 (42.6%)]\tLoss: 0.243356\n",
      "Step: 2931 Train Epoch: 12 [28160/60000 (46.8%)]\tLoss: 0.248043\n",
      "Step: 2941 Train Epoch: 12 [30720/60000 (51.1%)]\tLoss: 0.246500\n",
      "Step: 2951 Train Epoch: 12 [33280/60000 (55.3%)]\tLoss: 0.194516\n",
      "Step: 2961 Train Epoch: 12 [35840/60000 (59.6%)]\tLoss: 0.244265\n",
      "Step: 2971 Train Epoch: 12 [38400/60000 (63.8%)]\tLoss: 0.331093\n",
      "Step: 2981 Train Epoch: 12 [40960/60000 (68.1%)]\tLoss: 0.209693\n",
      "Step: 2991 Train Epoch: 12 [43520/60000 (72.3%)]\tLoss: 0.212878\n",
      "Step: 3001 Train Epoch: 12 [46080/60000 (76.6%)]\tLoss: 0.323831\n",
      "Step: 3011 Train Epoch: 12 [48640/60000 (80.9%)]\tLoss: 0.233361\n",
      "Step: 3021 Train Epoch: 12 [51200/60000 (85.1%)]\tLoss: 0.231826\n",
      "Step: 3031 Train Epoch: 12 [53760/60000 (89.4%)]\tLoss: 0.246425\n",
      "Step: 3041 Train Epoch: 12 [56320/60000 (93.6%)]\tLoss: 0.302259\n",
      "Step: 3051 Train Epoch: 12 [58880/60000 (97.9%)]\tLoss: 0.236366\n",
      "\n",
      "Test set: Average loss: 0.2881, Accuracy: 8938/10000 (89.3800%)\n",
      "\n",
      "Start epoch 13/50...\n",
      "Step: 3056 Train Epoch: 13 [0/60000 (0.0%)]\tLoss: 0.205877\n",
      "Step: 3066 Train Epoch: 13 [2560/60000 (4.3%)]\tLoss: 0.175842\n",
      "Step: 3076 Train Epoch: 13 [5120/60000 (8.5%)]\tLoss: 0.192331\n",
      "Step: 3086 Train Epoch: 13 [7680/60000 (12.8%)]\tLoss: 0.237301\n",
      "Step: 3096 Train Epoch: 13 [10240/60000 (17.0%)]\tLoss: 0.264625\n",
      "Step: 3106 Train Epoch: 13 [12800/60000 (21.3%)]\tLoss: 0.308265\n",
      "Step: 3116 Train Epoch: 13 [15360/60000 (25.5%)]\tLoss: 0.255023\n",
      "Step: 3126 Train Epoch: 13 [17920/60000 (29.8%)]\tLoss: 0.216148\n",
      "Step: 3136 Train Epoch: 13 [20480/60000 (34.0%)]\tLoss: 0.251938\n",
      "Step: 3146 Train Epoch: 13 [23040/60000 (38.3%)]\tLoss: 0.211628\n",
      "Step: 3156 Train Epoch: 13 [25600/60000 (42.6%)]\tLoss: 0.192954\n",
      "Step: 3166 Train Epoch: 13 [28160/60000 (46.8%)]\tLoss: 0.228921\n",
      "Step: 3176 Train Epoch: 13 [30720/60000 (51.1%)]\tLoss: 0.246599\n",
      "Step: 3186 Train Epoch: 13 [33280/60000 (55.3%)]\tLoss: 0.169207\n",
      "Step: 3196 Train Epoch: 13 [35840/60000 (59.6%)]\tLoss: 0.285623\n",
      "Step: 3206 Train Epoch: 13 [38400/60000 (63.8%)]\tLoss: 0.298870\n",
      "Step: 3216 Train Epoch: 13 [40960/60000 (68.1%)]\tLoss: 0.312347\n",
      "Step: 3226 Train Epoch: 13 [43520/60000 (72.3%)]\tLoss: 0.212239\n",
      "Step: 3236 Train Epoch: 13 [46080/60000 (76.6%)]\tLoss: 0.274195\n",
      "Step: 3246 Train Epoch: 13 [48640/60000 (80.9%)]\tLoss: 0.250493\n",
      "Step: 3256 Train Epoch: 13 [51200/60000 (85.1%)]\tLoss: 0.189832\n",
      "Step: 3266 Train Epoch: 13 [53760/60000 (89.4%)]\tLoss: 0.206231\n",
      "Step: 3276 Train Epoch: 13 [56320/60000 (93.6%)]\tLoss: 0.251903\n",
      "Step: 3286 Train Epoch: 13 [58880/60000 (97.9%)]\tLoss: 0.185356\n",
      "\n",
      "Test set: Average loss: 0.2661, Accuracy: 9008/10000 (90.0800%)\n",
      "\n",
      "Start epoch 14/50...\n",
      "Step: 3291 Train Epoch: 14 [0/60000 (0.0%)]\tLoss: 0.260298\n",
      "Step: 3301 Train Epoch: 14 [2560/60000 (4.3%)]\tLoss: 0.235779\n",
      "Step: 3311 Train Epoch: 14 [5120/60000 (8.5%)]\tLoss: 0.177398\n",
      "Step: 3321 Train Epoch: 14 [7680/60000 (12.8%)]\tLoss: 0.225862\n",
      "Step: 3331 Train Epoch: 14 [10240/60000 (17.0%)]\tLoss: 0.250186\n",
      "Step: 3341 Train Epoch: 14 [12800/60000 (21.3%)]\tLoss: 0.171606\n",
      "Step: 3351 Train Epoch: 14 [15360/60000 (25.5%)]\tLoss: 0.167551\n",
      "Step: 3361 Train Epoch: 14 [17920/60000 (29.8%)]\tLoss: 0.244129\n",
      "Step: 3371 Train Epoch: 14 [20480/60000 (34.0%)]\tLoss: 0.245896\n",
      "Step: 3381 Train Epoch: 14 [23040/60000 (38.3%)]\tLoss: 0.256340\n",
      "Step: 3391 Train Epoch: 14 [25600/60000 (42.6%)]\tLoss: 0.198796\n",
      "Step: 3401 Train Epoch: 14 [28160/60000 (46.8%)]\tLoss: 0.304906\n",
      "Step: 3411 Train Epoch: 14 [30720/60000 (51.1%)]\tLoss: 0.338606\n",
      "Step: 3421 Train Epoch: 14 [33280/60000 (55.3%)]\tLoss: 0.215397\n",
      "Step: 3431 Train Epoch: 14 [35840/60000 (59.6%)]\tLoss: 0.222938\n",
      "Step: 3441 Train Epoch: 14 [38400/60000 (63.8%)]\tLoss: 0.226640\n",
      "Step: 3451 Train Epoch: 14 [40960/60000 (68.1%)]\tLoss: 0.275547\n",
      "Step: 3461 Train Epoch: 14 [43520/60000 (72.3%)]\tLoss: 0.276425\n",
      "Step: 3471 Train Epoch: 14 [46080/60000 (76.6%)]\tLoss: 0.260359\n",
      "Step: 3481 Train Epoch: 14 [48640/60000 (80.9%)]\tLoss: 0.213495\n",
      "Step: 3491 Train Epoch: 14 [51200/60000 (85.1%)]\tLoss: 0.275136\n",
      "Step: 3501 Train Epoch: 14 [53760/60000 (89.4%)]\tLoss: 0.274709\n",
      "Step: 3511 Train Epoch: 14 [56320/60000 (93.6%)]\tLoss: 0.158806\n",
      "Step: 3521 Train Epoch: 14 [58880/60000 (97.9%)]\tLoss: 0.200588\n",
      "\n",
      "Test set: Average loss: 0.2581, Accuracy: 9055/10000 (90.5500%)\n",
      "\n",
      "Start epoch 15/50...\n",
      "Step: 3526 Train Epoch: 15 [0/60000 (0.0%)]\tLoss: 0.215844\n",
      "Step: 3536 Train Epoch: 15 [2560/60000 (4.3%)]\tLoss: 0.219007\n",
      "Step: 3546 Train Epoch: 15 [5120/60000 (8.5%)]\tLoss: 0.244112\n",
      "Step: 3556 Train Epoch: 15 [7680/60000 (12.8%)]\tLoss: 0.218599\n",
      "Step: 3566 Train Epoch: 15 [10240/60000 (17.0%)]\tLoss: 0.183071\n",
      "Step: 3576 Train Epoch: 15 [12800/60000 (21.3%)]\tLoss: 0.213718\n",
      "Step: 3586 Train Epoch: 15 [15360/60000 (25.5%)]\tLoss: 0.298270\n",
      "Step: 3596 Train Epoch: 15 [17920/60000 (29.8%)]\tLoss: 0.184823\n",
      "Step: 3606 Train Epoch: 15 [20480/60000 (34.0%)]\tLoss: 0.290135\n",
      "Step: 3616 Train Epoch: 15 [23040/60000 (38.3%)]\tLoss: 0.217208\n",
      "Step: 3626 Train Epoch: 15 [25600/60000 (42.6%)]\tLoss: 0.269510\n",
      "Step: 3636 Train Epoch: 15 [28160/60000 (46.8%)]\tLoss: 0.285419\n",
      "Step: 3646 Train Epoch: 15 [30720/60000 (51.1%)]\tLoss: 0.240248\n",
      "Step: 3656 Train Epoch: 15 [33280/60000 (55.3%)]\tLoss: 0.211259\n",
      "Step: 3666 Train Epoch: 15 [35840/60000 (59.6%)]\tLoss: 0.267656\n",
      "Step: 3676 Train Epoch: 15 [38400/60000 (63.8%)]\tLoss: 0.217537\n",
      "Step: 3686 Train Epoch: 15 [40960/60000 (68.1%)]\tLoss: 0.283181\n",
      "Step: 3696 Train Epoch: 15 [43520/60000 (72.3%)]\tLoss: 0.181195\n",
      "Step: 3706 Train Epoch: 15 [46080/60000 (76.6%)]\tLoss: 0.182999\n",
      "Step: 3716 Train Epoch: 15 [48640/60000 (80.9%)]\tLoss: 0.198619\n",
      "Step: 3726 Train Epoch: 15 [51200/60000 (85.1%)]\tLoss: 0.228293\n",
      "Step: 3736 Train Epoch: 15 [53760/60000 (89.4%)]\tLoss: 0.212967\n",
      "Step: 3746 Train Epoch: 15 [56320/60000 (93.6%)]\tLoss: 0.251892\n",
      "Step: 3756 Train Epoch: 15 [58880/60000 (97.9%)]\tLoss: 0.282209\n",
      "\n",
      "Test set: Average loss: 0.2765, Accuracy: 8977/10000 (89.7700%)\n",
      "\n",
      "Start epoch 16/50...\n",
      "Step: 3761 Train Epoch: 16 [0/60000 (0.0%)]\tLoss: 0.225455\n",
      "Step: 3771 Train Epoch: 16 [2560/60000 (4.3%)]\tLoss: 0.255647\n",
      "Step: 3781 Train Epoch: 16 [5120/60000 (8.5%)]\tLoss: 0.263473\n",
      "Step: 3791 Train Epoch: 16 [7680/60000 (12.8%)]\tLoss: 0.253802\n",
      "Step: 3801 Train Epoch: 16 [10240/60000 (17.0%)]\tLoss: 0.300828\n",
      "Step: 3811 Train Epoch: 16 [12800/60000 (21.3%)]\tLoss: 0.215993\n",
      "Step: 3821 Train Epoch: 16 [15360/60000 (25.5%)]\tLoss: 0.339814\n",
      "Step: 3831 Train Epoch: 16 [17920/60000 (29.8%)]\tLoss: 0.227966\n",
      "Step: 3841 Train Epoch: 16 [20480/60000 (34.0%)]\tLoss: 0.271354\n",
      "Step: 3851 Train Epoch: 16 [23040/60000 (38.3%)]\tLoss: 0.195338\n",
      "Step: 3861 Train Epoch: 16 [25600/60000 (42.6%)]\tLoss: 0.330011\n",
      "Step: 3871 Train Epoch: 16 [28160/60000 (46.8%)]\tLoss: 0.261806\n",
      "Step: 3881 Train Epoch: 16 [30720/60000 (51.1%)]\tLoss: 0.203068\n",
      "Step: 3891 Train Epoch: 16 [33280/60000 (55.3%)]\tLoss: 0.279474\n",
      "Step: 3901 Train Epoch: 16 [35840/60000 (59.6%)]\tLoss: 0.205179\n",
      "Step: 3911 Train Epoch: 16 [38400/60000 (63.8%)]\tLoss: 0.212843\n",
      "Step: 3921 Train Epoch: 16 [40960/60000 (68.1%)]\tLoss: 0.257728\n",
      "Step: 3931 Train Epoch: 16 [43520/60000 (72.3%)]\tLoss: 0.243322\n",
      "Step: 3941 Train Epoch: 16 [46080/60000 (76.6%)]\tLoss: 0.201428\n",
      "Step: 3951 Train Epoch: 16 [48640/60000 (80.9%)]\tLoss: 0.236747\n",
      "Step: 3961 Train Epoch: 16 [51200/60000 (85.1%)]\tLoss: 0.241546\n",
      "Step: 3971 Train Epoch: 16 [53760/60000 (89.4%)]\tLoss: 0.270210\n",
      "Step: 3981 Train Epoch: 16 [56320/60000 (93.6%)]\tLoss: 0.225851\n",
      "Step: 3991 Train Epoch: 16 [58880/60000 (97.9%)]\tLoss: 0.255555\n",
      "\n",
      "Test set: Average loss: 0.3092, Accuracy: 8909/10000 (89.0900%)\n",
      "\n",
      "Start epoch 17/50...\n",
      "Step: 3996 Train Epoch: 17 [0/60000 (0.0%)]\tLoss: 0.227406\n",
      "Step: 4006 Train Epoch: 17 [2560/60000 (4.3%)]\tLoss: 0.168739\n",
      "Step: 4016 Train Epoch: 17 [5120/60000 (8.5%)]\tLoss: 0.246863\n",
      "Step: 4026 Train Epoch: 17 [7680/60000 (12.8%)]\tLoss: 0.184612\n",
      "Step: 4036 Train Epoch: 17 [10240/60000 (17.0%)]\tLoss: 0.300762\n",
      "Step: 4046 Train Epoch: 17 [12800/60000 (21.3%)]\tLoss: 0.222039\n",
      "Step: 4056 Train Epoch: 17 [15360/60000 (25.5%)]\tLoss: 0.212411\n",
      "Step: 4066 Train Epoch: 17 [17920/60000 (29.8%)]\tLoss: 0.237867\n",
      "Step: 4076 Train Epoch: 17 [20480/60000 (34.0%)]\tLoss: 0.262183\n",
      "Step: 4086 Train Epoch: 17 [23040/60000 (38.3%)]\tLoss: 0.300770\n",
      "Step: 4096 Train Epoch: 17 [25600/60000 (42.6%)]\tLoss: 0.245268\n",
      "Step: 4106 Train Epoch: 17 [28160/60000 (46.8%)]\tLoss: 0.181101\n",
      "Step: 4116 Train Epoch: 17 [30720/60000 (51.1%)]\tLoss: 0.257793\n",
      "Step: 4126 Train Epoch: 17 [33280/60000 (55.3%)]\tLoss: 0.192170\n",
      "Step: 4136 Train Epoch: 17 [35840/60000 (59.6%)]\tLoss: 0.223629\n",
      "Step: 4146 Train Epoch: 17 [38400/60000 (63.8%)]\tLoss: 0.211561\n",
      "Step: 4156 Train Epoch: 17 [40960/60000 (68.1%)]\tLoss: 0.234102\n",
      "Step: 4166 Train Epoch: 17 [43520/60000 (72.3%)]\tLoss: 0.229043\n",
      "Step: 4176 Train Epoch: 17 [46080/60000 (76.6%)]\tLoss: 0.235272\n",
      "Step: 4186 Train Epoch: 17 [48640/60000 (80.9%)]\tLoss: 0.251064\n",
      "Step: 4196 Train Epoch: 17 [51200/60000 (85.1%)]\tLoss: 0.235329\n",
      "Step: 4206 Train Epoch: 17 [53760/60000 (89.4%)]\tLoss: 0.363781\n",
      "Step: 4216 Train Epoch: 17 [56320/60000 (93.6%)]\tLoss: 0.344380\n",
      "Step: 4226 Train Epoch: 17 [58880/60000 (97.9%)]\tLoss: 0.303807\n",
      "\n",
      "Test set: Average loss: 0.3229, Accuracy: 8838/10000 (88.3800%)\n",
      "\n",
      "Start epoch 18/50...\n",
      "Step: 4231 Train Epoch: 18 [0/60000 (0.0%)]\tLoss: 0.237259\n",
      "Step: 4241 Train Epoch: 18 [2560/60000 (4.3%)]\tLoss: 0.241795\n",
      "Step: 4251 Train Epoch: 18 [5120/60000 (8.5%)]\tLoss: 0.197924\n",
      "Step: 4261 Train Epoch: 18 [7680/60000 (12.8%)]\tLoss: 0.235427\n",
      "Step: 4271 Train Epoch: 18 [10240/60000 (17.0%)]\tLoss: 0.215130\n",
      "Step: 4281 Train Epoch: 18 [12800/60000 (21.3%)]\tLoss: 0.236987\n",
      "Step: 4291 Train Epoch: 18 [15360/60000 (25.5%)]\tLoss: 0.210724\n",
      "Step: 4301 Train Epoch: 18 [17920/60000 (29.8%)]\tLoss: 0.152759\n",
      "Step: 4311 Train Epoch: 18 [20480/60000 (34.0%)]\tLoss: 0.217191\n",
      "Step: 4321 Train Epoch: 18 [23040/60000 (38.3%)]\tLoss: 0.215038\n",
      "Step: 4331 Train Epoch: 18 [25600/60000 (42.6%)]\tLoss: 0.151050\n",
      "Step: 4341 Train Epoch: 18 [28160/60000 (46.8%)]\tLoss: 0.252399\n",
      "Step: 4351 Train Epoch: 18 [30720/60000 (51.1%)]\tLoss: 0.240944\n",
      "Step: 4361 Train Epoch: 18 [33280/60000 (55.3%)]\tLoss: 0.253184\n",
      "Step: 4371 Train Epoch: 18 [35840/60000 (59.6%)]\tLoss: 0.257990\n",
      "Step: 4381 Train Epoch: 18 [38400/60000 (63.8%)]\tLoss: 0.237187\n",
      "Step: 4391 Train Epoch: 18 [40960/60000 (68.1%)]\tLoss: 0.261976\n",
      "Step: 4401 Train Epoch: 18 [43520/60000 (72.3%)]\tLoss: 0.161089\n",
      "Step: 4411 Train Epoch: 18 [46080/60000 (76.6%)]\tLoss: 0.295495\n",
      "Step: 4421 Train Epoch: 18 [48640/60000 (80.9%)]\tLoss: 0.209381\n",
      "Step: 4431 Train Epoch: 18 [51200/60000 (85.1%)]\tLoss: 0.259669\n",
      "Step: 4441 Train Epoch: 18 [53760/60000 (89.4%)]\tLoss: 0.238943\n",
      "Step: 4451 Train Epoch: 18 [56320/60000 (93.6%)]\tLoss: 0.212936\n",
      "Step: 4461 Train Epoch: 18 [58880/60000 (97.9%)]\tLoss: 0.260708\n",
      "\n",
      "Test set: Average loss: 0.2628, Accuracy: 9050/10000 (90.5000%)\n",
      "\n",
      "Start epoch 19/50...\n",
      "Step: 4466 Train Epoch: 19 [0/60000 (0.0%)]\tLoss: 0.216984\n",
      "Step: 4476 Train Epoch: 19 [2560/60000 (4.3%)]\tLoss: 0.216001\n",
      "Step: 4486 Train Epoch: 19 [5120/60000 (8.5%)]\tLoss: 0.182743\n",
      "Step: 4496 Train Epoch: 19 [7680/60000 (12.8%)]\tLoss: 0.207913\n",
      "Step: 4506 Train Epoch: 19 [10240/60000 (17.0%)]\tLoss: 0.182989\n",
      "Step: 4516 Train Epoch: 19 [12800/60000 (21.3%)]\tLoss: 0.226273\n",
      "Step: 4526 Train Epoch: 19 [15360/60000 (25.5%)]\tLoss: 0.207675\n",
      "Step: 4536 Train Epoch: 19 [17920/60000 (29.8%)]\tLoss: 0.150153\n",
      "Step: 4546 Train Epoch: 19 [20480/60000 (34.0%)]\tLoss: 0.242273\n",
      "Step: 4556 Train Epoch: 19 [23040/60000 (38.3%)]\tLoss: 0.219644\n",
      "Step: 4566 Train Epoch: 19 [25600/60000 (42.6%)]\tLoss: 0.247105\n",
      "Step: 4576 Train Epoch: 19 [28160/60000 (46.8%)]\tLoss: 0.248374\n",
      "Step: 4586 Train Epoch: 19 [30720/60000 (51.1%)]\tLoss: 0.298286\n",
      "Step: 4596 Train Epoch: 19 [33280/60000 (55.3%)]\tLoss: 0.293704\n",
      "Step: 4606 Train Epoch: 19 [35840/60000 (59.6%)]\tLoss: 0.304814\n",
      "Step: 4616 Train Epoch: 19 [38400/60000 (63.8%)]\tLoss: 0.237137\n",
      "Step: 4626 Train Epoch: 19 [40960/60000 (68.1%)]\tLoss: 0.286728\n",
      "Step: 4636 Train Epoch: 19 [43520/60000 (72.3%)]\tLoss: 0.241795\n",
      "Step: 4646 Train Epoch: 19 [46080/60000 (76.6%)]\tLoss: 0.248769\n",
      "Step: 4656 Train Epoch: 19 [48640/60000 (80.9%)]\tLoss: 0.236559\n",
      "Step: 4666 Train Epoch: 19 [51200/60000 (85.1%)]\tLoss: 0.172157\n",
      "Step: 4676 Train Epoch: 19 [53760/60000 (89.4%)]\tLoss: 0.204949\n",
      "Step: 4686 Train Epoch: 19 [56320/60000 (93.6%)]\tLoss: 0.194914\n",
      "Step: 4696 Train Epoch: 19 [58880/60000 (97.9%)]\tLoss: 0.187372\n",
      "\n",
      "Test set: Average loss: 0.2492, Accuracy: 9077/10000 (90.7700%)\n",
      "\n",
      "Start epoch 20/50...\n",
      "Step: 4701 Train Epoch: 20 [0/60000 (0.0%)]\tLoss: 0.204145\n",
      "Step: 4711 Train Epoch: 20 [2560/60000 (4.3%)]\tLoss: 0.208931\n",
      "Step: 4721 Train Epoch: 20 [5120/60000 (8.5%)]\tLoss: 0.293869\n",
      "Step: 4731 Train Epoch: 20 [7680/60000 (12.8%)]\tLoss: 0.198510\n",
      "Step: 4741 Train Epoch: 20 [10240/60000 (17.0%)]\tLoss: 0.181674\n",
      "Step: 4751 Train Epoch: 20 [12800/60000 (21.3%)]\tLoss: 0.193859\n",
      "Step: 4761 Train Epoch: 20 [15360/60000 (25.5%)]\tLoss: 0.259048\n",
      "Step: 4771 Train Epoch: 20 [17920/60000 (29.8%)]\tLoss: 0.195838\n",
      "Step: 4781 Train Epoch: 20 [20480/60000 (34.0%)]\tLoss: 0.243406\n",
      "Step: 4791 Train Epoch: 20 [23040/60000 (38.3%)]\tLoss: 0.315896\n",
      "Step: 4801 Train Epoch: 20 [25600/60000 (42.6%)]\tLoss: 0.235203\n",
      "Step: 4811 Train Epoch: 20 [28160/60000 (46.8%)]\tLoss: 0.236718\n",
      "Step: 4821 Train Epoch: 20 [30720/60000 (51.1%)]\tLoss: 0.293303\n",
      "Step: 4831 Train Epoch: 20 [33280/60000 (55.3%)]\tLoss: 0.271716\n",
      "Step: 4841 Train Epoch: 20 [35840/60000 (59.6%)]\tLoss: 0.210247\n",
      "Step: 4851 Train Epoch: 20 [38400/60000 (63.8%)]\tLoss: 0.279588\n",
      "Step: 4861 Train Epoch: 20 [40960/60000 (68.1%)]\tLoss: 0.230824\n",
      "Step: 4871 Train Epoch: 20 [43520/60000 (72.3%)]\tLoss: 0.230324\n",
      "Step: 4881 Train Epoch: 20 [46080/60000 (76.6%)]\tLoss: 0.149538\n",
      "Step: 4891 Train Epoch: 20 [48640/60000 (80.9%)]\tLoss: 0.223836\n",
      "Step: 4901 Train Epoch: 20 [51200/60000 (85.1%)]\tLoss: 0.214000\n",
      "Step: 4911 Train Epoch: 20 [53760/60000 (89.4%)]\tLoss: 0.240259\n",
      "Step: 4921 Train Epoch: 20 [56320/60000 (93.6%)]\tLoss: 0.279747\n",
      "Step: 4931 Train Epoch: 20 [58880/60000 (97.9%)]\tLoss: 0.216487\n",
      "\n",
      "Test set: Average loss: 0.2537, Accuracy: 9081/10000 (90.8100%)\n",
      "\n",
      "Start epoch 21/50...\n",
      "Step: 4936 Train Epoch: 21 [0/60000 (0.0%)]\tLoss: 0.171354\n",
      "Step: 4946 Train Epoch: 21 [2560/60000 (4.3%)]\tLoss: 0.209714\n",
      "Step: 4956 Train Epoch: 21 [5120/60000 (8.5%)]\tLoss: 0.192034\n",
      "Step: 4966 Train Epoch: 21 [7680/60000 (12.8%)]\tLoss: 0.208015\n",
      "Step: 4976 Train Epoch: 21 [10240/60000 (17.0%)]\tLoss: 0.240945\n",
      "Step: 4986 Train Epoch: 21 [12800/60000 (21.3%)]\tLoss: 0.246795\n",
      "Step: 4996 Train Epoch: 21 [15360/60000 (25.5%)]\tLoss: 0.237217\n",
      "Step: 5006 Train Epoch: 21 [17920/60000 (29.8%)]\tLoss: 0.323057\n",
      "Step: 5016 Train Epoch: 21 [20480/60000 (34.0%)]\tLoss: 0.257936\n",
      "Step: 5026 Train Epoch: 21 [23040/60000 (38.3%)]\tLoss: 0.199876\n",
      "Step: 5036 Train Epoch: 21 [25600/60000 (42.6%)]\tLoss: 0.187967\n",
      "Step: 5046 Train Epoch: 21 [28160/60000 (46.8%)]\tLoss: 0.189750\n",
      "Step: 5056 Train Epoch: 21 [30720/60000 (51.1%)]\tLoss: 0.269296\n",
      "Step: 5066 Train Epoch: 21 [33280/60000 (55.3%)]\tLoss: 0.149322\n",
      "Step: 5076 Train Epoch: 21 [35840/60000 (59.6%)]\tLoss: 0.176271\n",
      "Step: 5086 Train Epoch: 21 [38400/60000 (63.8%)]\tLoss: 0.218274\n",
      "Step: 5096 Train Epoch: 21 [40960/60000 (68.1%)]\tLoss: 0.210286\n",
      "Step: 5106 Train Epoch: 21 [43520/60000 (72.3%)]\tLoss: 0.186857\n",
      "Step: 5116 Train Epoch: 21 [46080/60000 (76.6%)]\tLoss: 0.174324\n",
      "Step: 5126 Train Epoch: 21 [48640/60000 (80.9%)]\tLoss: 0.211720\n",
      "Step: 5136 Train Epoch: 21 [51200/60000 (85.1%)]\tLoss: 0.211226\n",
      "Step: 5146 Train Epoch: 21 [53760/60000 (89.4%)]\tLoss: 0.282910\n",
      "Step: 5156 Train Epoch: 21 [56320/60000 (93.6%)]\tLoss: 0.203417\n",
      "Step: 5166 Train Epoch: 21 [58880/60000 (97.9%)]\tLoss: 0.197290\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 8963/10000 (89.6300%)\n",
      "\n",
      "Start epoch 22/50...\n",
      "Step: 5171 Train Epoch: 22 [0/60000 (0.0%)]\tLoss: 0.205149\n",
      "Step: 5181 Train Epoch: 22 [2560/60000 (4.3%)]\tLoss: 0.214813\n",
      "Step: 5191 Train Epoch: 22 [5120/60000 (8.5%)]\tLoss: 0.369561\n",
      "Step: 5201 Train Epoch: 22 [7680/60000 (12.8%)]\tLoss: 0.231850\n",
      "Step: 5211 Train Epoch: 22 [10240/60000 (17.0%)]\tLoss: 0.218855\n",
      "Step: 5221 Train Epoch: 22 [12800/60000 (21.3%)]\tLoss: 0.227714\n",
      "Step: 5231 Train Epoch: 22 [15360/60000 (25.5%)]\tLoss: 0.252311\n",
      "Step: 5241 Train Epoch: 22 [17920/60000 (29.8%)]\tLoss: 0.254951\n",
      "Step: 5251 Train Epoch: 22 [20480/60000 (34.0%)]\tLoss: 0.181716\n",
      "Step: 5261 Train Epoch: 22 [23040/60000 (38.3%)]\tLoss: 0.198444\n",
      "Step: 5271 Train Epoch: 22 [25600/60000 (42.6%)]\tLoss: 0.177983\n",
      "Step: 5281 Train Epoch: 22 [28160/60000 (46.8%)]\tLoss: 0.199827\n",
      "Step: 5291 Train Epoch: 22 [30720/60000 (51.1%)]\tLoss: 0.141721\n",
      "Step: 5301 Train Epoch: 22 [33280/60000 (55.3%)]\tLoss: 0.196573\n",
      "Step: 5311 Train Epoch: 22 [35840/60000 (59.6%)]\tLoss: 0.168946\n",
      "Step: 5321 Train Epoch: 22 [38400/60000 (63.8%)]\tLoss: 0.167130\n",
      "Step: 5331 Train Epoch: 22 [40960/60000 (68.1%)]\tLoss: 0.207314\n",
      "Step: 5341 Train Epoch: 22 [43520/60000 (72.3%)]\tLoss: 0.181341\n",
      "Step: 5351 Train Epoch: 22 [46080/60000 (76.6%)]\tLoss: 0.192647\n",
      "Step: 5361 Train Epoch: 22 [48640/60000 (80.9%)]\tLoss: 0.240035\n",
      "Step: 5371 Train Epoch: 22 [51200/60000 (85.1%)]\tLoss: 0.301366\n",
      "Step: 5381 Train Epoch: 22 [53760/60000 (89.4%)]\tLoss: 0.242024\n",
      "Step: 5391 Train Epoch: 22 [56320/60000 (93.6%)]\tLoss: 0.245332\n",
      "Step: 5401 Train Epoch: 22 [58880/60000 (97.9%)]\tLoss: 0.249463\n",
      "\n",
      "Test set: Average loss: 0.3001, Accuracy: 8947/10000 (89.4700%)\n",
      "\n",
      "Start epoch 23/50...\n",
      "Step: 5406 Train Epoch: 23 [0/60000 (0.0%)]\tLoss: 0.272922\n",
      "Step: 5416 Train Epoch: 23 [2560/60000 (4.3%)]\tLoss: 0.216424\n",
      "Step: 5426 Train Epoch: 23 [5120/60000 (8.5%)]\tLoss: 0.224132\n",
      "Step: 5436 Train Epoch: 23 [7680/60000 (12.8%)]\tLoss: 0.202228\n",
      "Step: 5446 Train Epoch: 23 [10240/60000 (17.0%)]\tLoss: 0.266725\n",
      "Step: 5456 Train Epoch: 23 [12800/60000 (21.3%)]\tLoss: 0.310131\n",
      "Step: 5466 Train Epoch: 23 [15360/60000 (25.5%)]\tLoss: 0.196436\n",
      "Step: 5476 Train Epoch: 23 [17920/60000 (29.8%)]\tLoss: 0.187862\n",
      "Step: 5486 Train Epoch: 23 [20480/60000 (34.0%)]\tLoss: 0.208310\n",
      "Step: 5496 Train Epoch: 23 [23040/60000 (38.3%)]\tLoss: 0.178423\n",
      "Step: 5506 Train Epoch: 23 [25600/60000 (42.6%)]\tLoss: 0.168013\n",
      "Step: 5516 Train Epoch: 23 [28160/60000 (46.8%)]\tLoss: 0.204871\n",
      "Step: 5526 Train Epoch: 23 [30720/60000 (51.1%)]\tLoss: 0.148480\n",
      "Step: 5536 Train Epoch: 23 [33280/60000 (55.3%)]\tLoss: 0.189976\n",
      "Step: 5546 Train Epoch: 23 [35840/60000 (59.6%)]\tLoss: 0.177839\n",
      "Step: 5556 Train Epoch: 23 [38400/60000 (63.8%)]\tLoss: 0.184160\n",
      "Step: 5566 Train Epoch: 23 [40960/60000 (68.1%)]\tLoss: 0.177804\n",
      "Step: 5576 Train Epoch: 23 [43520/60000 (72.3%)]\tLoss: 0.211140\n",
      "Step: 5586 Train Epoch: 23 [46080/60000 (76.6%)]\tLoss: 0.257090\n",
      "Step: 5596 Train Epoch: 23 [48640/60000 (80.9%)]\tLoss: 0.239348\n",
      "Step: 5606 Train Epoch: 23 [51200/60000 (85.1%)]\tLoss: 0.257762\n",
      "Step: 5616 Train Epoch: 23 [53760/60000 (89.4%)]\tLoss: 0.276100\n",
      "Step: 5626 Train Epoch: 23 [56320/60000 (93.6%)]\tLoss: 0.218841\n",
      "Step: 5636 Train Epoch: 23 [58880/60000 (97.9%)]\tLoss: 0.200354\n",
      "\n",
      "Test set: Average loss: 0.2645, Accuracy: 9060/10000 (90.6000%)\n",
      "\n",
      "Start epoch 24/50...\n",
      "Step: 5641 Train Epoch: 24 [0/60000 (0.0%)]\tLoss: 0.159657\n",
      "Step: 5651 Train Epoch: 24 [2560/60000 (4.3%)]\tLoss: 0.231628\n",
      "Step: 5661 Train Epoch: 24 [5120/60000 (8.5%)]\tLoss: 0.223923\n",
      "Step: 5671 Train Epoch: 24 [7680/60000 (12.8%)]\tLoss: 0.193996\n",
      "Step: 5681 Train Epoch: 24 [10240/60000 (17.0%)]\tLoss: 0.182220\n",
      "Step: 5691 Train Epoch: 24 [12800/60000 (21.3%)]\tLoss: 0.222267\n",
      "Step: 5701 Train Epoch: 24 [15360/60000 (25.5%)]\tLoss: 0.156939\n",
      "Step: 5711 Train Epoch: 24 [17920/60000 (29.8%)]\tLoss: 0.220434\n",
      "Step: 5721 Train Epoch: 24 [20480/60000 (34.0%)]\tLoss: 0.207988\n",
      "Step: 5731 Train Epoch: 24 [23040/60000 (38.3%)]\tLoss: 0.206591\n",
      "Step: 5741 Train Epoch: 24 [25600/60000 (42.6%)]\tLoss: 0.166908\n",
      "Step: 5751 Train Epoch: 24 [28160/60000 (46.8%)]\tLoss: 0.172342\n",
      "Step: 5761 Train Epoch: 24 [30720/60000 (51.1%)]\tLoss: 0.233669\n",
      "Step: 5771 Train Epoch: 24 [33280/60000 (55.3%)]\tLoss: 0.241158\n",
      "Step: 5781 Train Epoch: 24 [35840/60000 (59.6%)]\tLoss: 0.143744\n",
      "Step: 5791 Train Epoch: 24 [38400/60000 (63.8%)]\tLoss: 0.195619\n",
      "Step: 5801 Train Epoch: 24 [40960/60000 (68.1%)]\tLoss: 0.232793\n",
      "Step: 5811 Train Epoch: 24 [43520/60000 (72.3%)]\tLoss: 0.161561\n",
      "Step: 5821 Train Epoch: 24 [46080/60000 (76.6%)]\tLoss: 0.263180\n",
      "Step: 5831 Train Epoch: 24 [48640/60000 (80.9%)]\tLoss: 0.252865\n",
      "Step: 5841 Train Epoch: 24 [51200/60000 (85.1%)]\tLoss: 0.283626\n",
      "Step: 5851 Train Epoch: 24 [53760/60000 (89.4%)]\tLoss: 0.214402\n",
      "Step: 5861 Train Epoch: 24 [56320/60000 (93.6%)]\tLoss: 0.161978\n",
      "Step: 5871 Train Epoch: 24 [58880/60000 (97.9%)]\tLoss: 0.170146\n",
      "\n",
      "Test set: Average loss: 0.2583, Accuracy: 9076/10000 (90.7600%)\n",
      "\n",
      "Start epoch 25/50...\n",
      "Step: 5876 Train Epoch: 25 [0/60000 (0.0%)]\tLoss: 0.164360\n",
      "Step: 5886 Train Epoch: 25 [2560/60000 (4.3%)]\tLoss: 0.220049\n",
      "Step: 5896 Train Epoch: 25 [5120/60000 (8.5%)]\tLoss: 0.197172\n",
      "Step: 5906 Train Epoch: 25 [7680/60000 (12.8%)]\tLoss: 0.207153\n",
      "Step: 5916 Train Epoch: 25 [10240/60000 (17.0%)]\tLoss: 0.174851\n",
      "Step: 5926 Train Epoch: 25 [12800/60000 (21.3%)]\tLoss: 0.195552\n",
      "Step: 5936 Train Epoch: 25 [15360/60000 (25.5%)]\tLoss: 0.269345\n",
      "Step: 5946 Train Epoch: 25 [17920/60000 (29.8%)]\tLoss: 0.157917\n",
      "Step: 5956 Train Epoch: 25 [20480/60000 (34.0%)]\tLoss: 0.184720\n",
      "Step: 5966 Train Epoch: 25 [23040/60000 (38.3%)]\tLoss: 0.194779\n",
      "Step: 5976 Train Epoch: 25 [25600/60000 (42.6%)]\tLoss: 0.167325\n",
      "Step: 5986 Train Epoch: 25 [28160/60000 (46.8%)]\tLoss: 0.237731\n",
      "Step: 5996 Train Epoch: 25 [30720/60000 (51.1%)]\tLoss: 0.217637\n",
      "Step: 6006 Train Epoch: 25 [33280/60000 (55.3%)]\tLoss: 0.297379\n",
      "Step: 6016 Train Epoch: 25 [35840/60000 (59.6%)]\tLoss: 0.224316\n",
      "Step: 6026 Train Epoch: 25 [38400/60000 (63.8%)]\tLoss: 0.271687\n",
      "Step: 6036 Train Epoch: 25 [40960/60000 (68.1%)]\tLoss: 0.218394\n",
      "Step: 6046 Train Epoch: 25 [43520/60000 (72.3%)]\tLoss: 0.184922\n",
      "Step: 6056 Train Epoch: 25 [46080/60000 (76.6%)]\tLoss: 0.148017\n",
      "Step: 6066 Train Epoch: 25 [48640/60000 (80.9%)]\tLoss: 0.169455\n",
      "Step: 6076 Train Epoch: 25 [51200/60000 (85.1%)]\tLoss: 0.155073\n",
      "Step: 6086 Train Epoch: 25 [53760/60000 (89.4%)]\tLoss: 0.262494\n",
      "Step: 6096 Train Epoch: 25 [56320/60000 (93.6%)]\tLoss: 0.167816\n",
      "Step: 6106 Train Epoch: 25 [58880/60000 (97.9%)]\tLoss: 0.214464\n",
      "\n",
      "Test set: Average loss: 0.2446, Accuracy: 9115/10000 (91.1500%)\n",
      "\n",
      "Start epoch 26/50...\n",
      "Step: 6111 Train Epoch: 26 [0/60000 (0.0%)]\tLoss: 0.202431\n",
      "Step: 6121 Train Epoch: 26 [2560/60000 (4.3%)]\tLoss: 0.157122\n",
      "Step: 6131 Train Epoch: 26 [5120/60000 (8.5%)]\tLoss: 0.133853\n",
      "Step: 6141 Train Epoch: 26 [7680/60000 (12.8%)]\tLoss: 0.198171\n",
      "Step: 6151 Train Epoch: 26 [10240/60000 (17.0%)]\tLoss: 0.166187\n",
      "Step: 6161 Train Epoch: 26 [12800/60000 (21.3%)]\tLoss: 0.255159\n",
      "Step: 6171 Train Epoch: 26 [15360/60000 (25.5%)]\tLoss: 0.241679\n",
      "Step: 6181 Train Epoch: 26 [17920/60000 (29.8%)]\tLoss: 0.227846\n",
      "Step: 6191 Train Epoch: 26 [20480/60000 (34.0%)]\tLoss: 0.236506\n",
      "Step: 6201 Train Epoch: 26 [23040/60000 (38.3%)]\tLoss: 0.219473\n",
      "Step: 6211 Train Epoch: 26 [25600/60000 (42.6%)]\tLoss: 0.237044\n",
      "Step: 6221 Train Epoch: 26 [28160/60000 (46.8%)]\tLoss: 0.271361\n",
      "Step: 6231 Train Epoch: 26 [30720/60000 (51.1%)]\tLoss: 0.166810\n",
      "Step: 6241 Train Epoch: 26 [33280/60000 (55.3%)]\tLoss: 0.236631\n",
      "Step: 6251 Train Epoch: 26 [35840/60000 (59.6%)]\tLoss: 0.192772\n",
      "Step: 6261 Train Epoch: 26 [38400/60000 (63.8%)]\tLoss: 0.170689\n",
      "Step: 6271 Train Epoch: 26 [40960/60000 (68.1%)]\tLoss: 0.148607\n",
      "Step: 6281 Train Epoch: 26 [43520/60000 (72.3%)]\tLoss: 0.177160\n",
      "Step: 6291 Train Epoch: 26 [46080/60000 (76.6%)]\tLoss: 0.171078\n",
      "Step: 6301 Train Epoch: 26 [48640/60000 (80.9%)]\tLoss: 0.156935\n",
      "Step: 6311 Train Epoch: 26 [51200/60000 (85.1%)]\tLoss: 0.233679\n",
      "Step: 6321 Train Epoch: 26 [53760/60000 (89.4%)]\tLoss: 0.141643\n",
      "Step: 6331 Train Epoch: 26 [56320/60000 (93.6%)]\tLoss: 0.157516\n",
      "Step: 6341 Train Epoch: 26 [58880/60000 (97.9%)]\tLoss: 0.201219\n",
      "\n",
      "Test set: Average loss: 0.2562, Accuracy: 9111/10000 (91.1100%)\n",
      "\n",
      "Start epoch 27/50...\n",
      "Step: 6346 Train Epoch: 27 [0/60000 (0.0%)]\tLoss: 0.221720\n",
      "Step: 6356 Train Epoch: 27 [2560/60000 (4.3%)]\tLoss: 0.194290\n",
      "Step: 6366 Train Epoch: 27 [5120/60000 (8.5%)]\tLoss: 0.216190\n",
      "Step: 6376 Train Epoch: 27 [7680/60000 (12.8%)]\tLoss: 0.266571\n",
      "Step: 6386 Train Epoch: 27 [10240/60000 (17.0%)]\tLoss: 0.209814\n",
      "Step: 6396 Train Epoch: 27 [12800/60000 (21.3%)]\tLoss: 0.258990\n",
      "Step: 6406 Train Epoch: 27 [15360/60000 (25.5%)]\tLoss: 0.176681\n",
      "Step: 6416 Train Epoch: 27 [17920/60000 (29.8%)]\tLoss: 0.207763\n",
      "Step: 6426 Train Epoch: 27 [20480/60000 (34.0%)]\tLoss: 0.228262\n",
      "Step: 6436 Train Epoch: 27 [23040/60000 (38.3%)]\tLoss: 0.177979\n",
      "Step: 6446 Train Epoch: 27 [25600/60000 (42.6%)]\tLoss: 0.242154\n",
      "Step: 6456 Train Epoch: 27 [28160/60000 (46.8%)]\tLoss: 0.234602\n",
      "Step: 6466 Train Epoch: 27 [30720/60000 (51.1%)]\tLoss: 0.193415\n",
      "Step: 6476 Train Epoch: 27 [33280/60000 (55.3%)]\tLoss: 0.136753\n",
      "Step: 6486 Train Epoch: 27 [35840/60000 (59.6%)]\tLoss: 0.189221\n",
      "Step: 6496 Train Epoch: 27 [38400/60000 (63.8%)]\tLoss: 0.153950\n",
      "Step: 6506 Train Epoch: 27 [40960/60000 (68.1%)]\tLoss: 0.274354\n",
      "Step: 6516 Train Epoch: 27 [43520/60000 (72.3%)]\tLoss: 0.172949\n",
      "Step: 6526 Train Epoch: 27 [46080/60000 (76.6%)]\tLoss: 0.244888\n",
      "Step: 6536 Train Epoch: 27 [48640/60000 (80.9%)]\tLoss: 0.259687\n",
      "Step: 6546 Train Epoch: 27 [51200/60000 (85.1%)]\tLoss: 0.227430\n",
      "Step: 6556 Train Epoch: 27 [53760/60000 (89.4%)]\tLoss: 0.232972\n",
      "Step: 6566 Train Epoch: 27 [56320/60000 (93.6%)]\tLoss: 0.229282\n",
      "Step: 6576 Train Epoch: 27 [58880/60000 (97.9%)]\tLoss: 0.212923\n",
      "\n",
      "Test set: Average loss: 0.2714, Accuracy: 9047/10000 (90.4700%)\n",
      "\n",
      "Start epoch 28/50...\n",
      "Step: 6581 Train Epoch: 28 [0/60000 (0.0%)]\tLoss: 0.200699\n",
      "Step: 6591 Train Epoch: 28 [2560/60000 (4.3%)]\tLoss: 0.203768\n",
      "Step: 6601 Train Epoch: 28 [5120/60000 (8.5%)]\tLoss: 0.192533\n",
      "Step: 6611 Train Epoch: 28 [7680/60000 (12.8%)]\tLoss: 0.243911\n",
      "Step: 6621 Train Epoch: 28 [10240/60000 (17.0%)]\tLoss: 0.219014\n",
      "Step: 6631 Train Epoch: 28 [12800/60000 (21.3%)]\tLoss: 0.238898\n",
      "Step: 6641 Train Epoch: 28 [15360/60000 (25.5%)]\tLoss: 0.214436\n",
      "Step: 6651 Train Epoch: 28 [17920/60000 (29.8%)]\tLoss: 0.156606\n",
      "Step: 6661 Train Epoch: 28 [20480/60000 (34.0%)]\tLoss: 0.153650\n",
      "Step: 6671 Train Epoch: 28 [23040/60000 (38.3%)]\tLoss: 0.163554\n",
      "Step: 6681 Train Epoch: 28 [25600/60000 (42.6%)]\tLoss: 0.210143\n",
      "Step: 6691 Train Epoch: 28 [28160/60000 (46.8%)]\tLoss: 0.173919\n",
      "Step: 6701 Train Epoch: 28 [30720/60000 (51.1%)]\tLoss: 0.175301\n",
      "Step: 6711 Train Epoch: 28 [33280/60000 (55.3%)]\tLoss: 0.170824\n",
      "Step: 6721 Train Epoch: 28 [35840/60000 (59.6%)]\tLoss: 0.142707\n",
      "Step: 6731 Train Epoch: 28 [38400/60000 (63.8%)]\tLoss: 0.169164\n",
      "Step: 6741 Train Epoch: 28 [40960/60000 (68.1%)]\tLoss: 0.235726\n",
      "Step: 6751 Train Epoch: 28 [43520/60000 (72.3%)]\tLoss: 0.175362\n",
      "Step: 6761 Train Epoch: 28 [46080/60000 (76.6%)]\tLoss: 0.160349\n",
      "Step: 6771 Train Epoch: 28 [48640/60000 (80.9%)]\tLoss: 0.186331\n",
      "Step: 6781 Train Epoch: 28 [51200/60000 (85.1%)]\tLoss: 0.244280\n",
      "Step: 6791 Train Epoch: 28 [53760/60000 (89.4%)]\tLoss: 0.248696\n",
      "Step: 6801 Train Epoch: 28 [56320/60000 (93.6%)]\tLoss: 0.202692\n",
      "Step: 6811 Train Epoch: 28 [58880/60000 (97.9%)]\tLoss: 0.206301\n",
      "\n",
      "Test set: Average loss: 0.3347, Accuracy: 8854/10000 (88.5400%)\n",
      "\n",
      "Start epoch 29/50...\n",
      "Step: 6816 Train Epoch: 29 [0/60000 (0.0%)]\tLoss: 0.321479\n",
      "Step: 6826 Train Epoch: 29 [2560/60000 (4.3%)]\tLoss: 0.187251\n",
      "Step: 6836 Train Epoch: 29 [5120/60000 (8.5%)]\tLoss: 0.182004\n",
      "Step: 6846 Train Epoch: 29 [7680/60000 (12.8%)]\tLoss: 0.201495\n",
      "Step: 6856 Train Epoch: 29 [10240/60000 (17.0%)]\tLoss: 0.238650\n",
      "Step: 6866 Train Epoch: 29 [12800/60000 (21.3%)]\tLoss: 0.165050\n",
      "Step: 6876 Train Epoch: 29 [15360/60000 (25.5%)]\tLoss: 0.132816\n",
      "Step: 6886 Train Epoch: 29 [17920/60000 (29.8%)]\tLoss: 0.159318\n",
      "Step: 6896 Train Epoch: 29 [20480/60000 (34.0%)]\tLoss: 0.191328\n",
      "Step: 6906 Train Epoch: 29 [23040/60000 (38.3%)]\tLoss: 0.151819\n",
      "Step: 6916 Train Epoch: 29 [25600/60000 (42.6%)]\tLoss: 0.193130\n",
      "Step: 6926 Train Epoch: 29 [28160/60000 (46.8%)]\tLoss: 0.111092\n",
      "Step: 6936 Train Epoch: 29 [30720/60000 (51.1%)]\tLoss: 0.155631\n",
      "Step: 6946 Train Epoch: 29 [33280/60000 (55.3%)]\tLoss: 0.210758\n",
      "Step: 6956 Train Epoch: 29 [35840/60000 (59.6%)]\tLoss: 0.177659\n",
      "Step: 6966 Train Epoch: 29 [38400/60000 (63.8%)]\tLoss: 0.168150\n",
      "Step: 6976 Train Epoch: 29 [40960/60000 (68.1%)]\tLoss: 0.220815\n",
      "Step: 6986 Train Epoch: 29 [43520/60000 (72.3%)]\tLoss: 0.182807\n",
      "Step: 6996 Train Epoch: 29 [46080/60000 (76.6%)]\tLoss: 0.221347\n",
      "Step: 7006 Train Epoch: 29 [48640/60000 (80.9%)]\tLoss: 0.325707\n",
      "Step: 7016 Train Epoch: 29 [51200/60000 (85.1%)]\tLoss: 0.183217\n",
      "Step: 7026 Train Epoch: 29 [53760/60000 (89.4%)]\tLoss: 0.236196\n",
      "Step: 7036 Train Epoch: 29 [56320/60000 (93.6%)]\tLoss: 0.174351\n",
      "Step: 7046 Train Epoch: 29 [58880/60000 (97.9%)]\tLoss: 0.174582\n",
      "\n",
      "Test set: Average loss: 0.2658, Accuracy: 9093/10000 (90.9300%)\n",
      "\n",
      "Start epoch 30/50...\n",
      "Step: 7051 Train Epoch: 30 [0/60000 (0.0%)]\tLoss: 0.218594\n",
      "Step: 7061 Train Epoch: 30 [2560/60000 (4.3%)]\tLoss: 0.211255\n",
      "Step: 7071 Train Epoch: 30 [5120/60000 (8.5%)]\tLoss: 0.144258\n",
      "Step: 7081 Train Epoch: 30 [7680/60000 (12.8%)]\tLoss: 0.150552\n",
      "Step: 7091 Train Epoch: 30 [10240/60000 (17.0%)]\tLoss: 0.197366\n",
      "Step: 7101 Train Epoch: 30 [12800/60000 (21.3%)]\tLoss: 0.162731\n",
      "Step: 7111 Train Epoch: 30 [15360/60000 (25.5%)]\tLoss: 0.171482\n",
      "Step: 7121 Train Epoch: 30 [17920/60000 (29.8%)]\tLoss: 0.161547\n",
      "Step: 7131 Train Epoch: 30 [20480/60000 (34.0%)]\tLoss: 0.144865\n",
      "Step: 7141 Train Epoch: 30 [23040/60000 (38.3%)]\tLoss: 0.170355\n",
      "Step: 7151 Train Epoch: 30 [25600/60000 (42.6%)]\tLoss: 0.159961\n",
      "Step: 7161 Train Epoch: 30 [28160/60000 (46.8%)]\tLoss: 0.174763\n",
      "Step: 7171 Train Epoch: 30 [30720/60000 (51.1%)]\tLoss: 0.218899\n",
      "Step: 7181 Train Epoch: 30 [33280/60000 (55.3%)]\tLoss: 0.167922\n",
      "Step: 7191 Train Epoch: 30 [35840/60000 (59.6%)]\tLoss: 0.201733\n",
      "Step: 7201 Train Epoch: 30 [38400/60000 (63.8%)]\tLoss: 0.204441\n",
      "Step: 7211 Train Epoch: 30 [40960/60000 (68.1%)]\tLoss: 0.185678\n",
      "Step: 7221 Train Epoch: 30 [43520/60000 (72.3%)]\tLoss: 0.187917\n",
      "Step: 7231 Train Epoch: 30 [46080/60000 (76.6%)]\tLoss: 0.197529\n",
      "Step: 7241 Train Epoch: 30 [48640/60000 (80.9%)]\tLoss: 0.170596\n",
      "Step: 7251 Train Epoch: 30 [51200/60000 (85.1%)]\tLoss: 0.185176\n",
      "Step: 7261 Train Epoch: 30 [53760/60000 (89.4%)]\tLoss: 0.153192\n",
      "Step: 7271 Train Epoch: 30 [56320/60000 (93.6%)]\tLoss: 0.175377\n",
      "Step: 7281 Train Epoch: 30 [58880/60000 (97.9%)]\tLoss: 0.173431\n",
      "\n",
      "Test set: Average loss: 0.2500, Accuracy: 9102/10000 (91.0200%)\n",
      "\n",
      "Start epoch 31/50...\n",
      "Step: 7286 Train Epoch: 31 [0/60000 (0.0%)]\tLoss: 0.172111\n",
      "Step: 7296 Train Epoch: 31 [2560/60000 (4.3%)]\tLoss: 0.162361\n",
      "Step: 7306 Train Epoch: 31 [5120/60000 (8.5%)]\tLoss: 0.134783\n",
      "Step: 7316 Train Epoch: 31 [7680/60000 (12.8%)]\tLoss: 0.137703\n",
      "Step: 7326 Train Epoch: 31 [10240/60000 (17.0%)]\tLoss: 0.172108\n",
      "Step: 7336 Train Epoch: 31 [12800/60000 (21.3%)]\tLoss: 0.153624\n",
      "Step: 7346 Train Epoch: 31 [15360/60000 (25.5%)]\tLoss: 0.248352\n",
      "Step: 7356 Train Epoch: 31 [17920/60000 (29.8%)]\tLoss: 0.156292\n",
      "Step: 7366 Train Epoch: 31 [20480/60000 (34.0%)]\tLoss: 0.162579\n",
      "Step: 7376 Train Epoch: 31 [23040/60000 (38.3%)]\tLoss: 0.203864\n",
      "Step: 7386 Train Epoch: 31 [25600/60000 (42.6%)]\tLoss: 0.170915\n",
      "Step: 7396 Train Epoch: 31 [28160/60000 (46.8%)]\tLoss: 0.238773\n",
      "Step: 7406 Train Epoch: 31 [30720/60000 (51.1%)]\tLoss: 0.200059\n",
      "Step: 7416 Train Epoch: 31 [33280/60000 (55.3%)]\tLoss: 0.312965\n",
      "Step: 7426 Train Epoch: 31 [35840/60000 (59.6%)]\tLoss: 0.178842\n",
      "Step: 7436 Train Epoch: 31 [38400/60000 (63.8%)]\tLoss: 0.177034\n",
      "Step: 7446 Train Epoch: 31 [40960/60000 (68.1%)]\tLoss: 0.193047\n",
      "Step: 7456 Train Epoch: 31 [43520/60000 (72.3%)]\tLoss: 0.222054\n",
      "Step: 7466 Train Epoch: 31 [46080/60000 (76.6%)]\tLoss: 0.224636\n",
      "Step: 7476 Train Epoch: 31 [48640/60000 (80.9%)]\tLoss: 0.144103\n",
      "Step: 7486 Train Epoch: 31 [51200/60000 (85.1%)]\tLoss: 0.185749\n",
      "Step: 7496 Train Epoch: 31 [53760/60000 (89.4%)]\tLoss: 0.170550\n",
      "Step: 7506 Train Epoch: 31 [56320/60000 (93.6%)]\tLoss: 0.180554\n",
      "Step: 7516 Train Epoch: 31 [58880/60000 (97.9%)]\tLoss: 0.222488\n",
      "\n",
      "Test set: Average loss: 0.2522, Accuracy: 9123/10000 (91.2300%)\n",
      "\n",
      "Start epoch 32/50...\n",
      "Step: 7521 Train Epoch: 32 [0/60000 (0.0%)]\tLoss: 0.148564\n",
      "Step: 7531 Train Epoch: 32 [2560/60000 (4.3%)]\tLoss: 0.115717\n",
      "Step: 7541 Train Epoch: 32 [5120/60000 (8.5%)]\tLoss: 0.151508\n",
      "Step: 7551 Train Epoch: 32 [7680/60000 (12.8%)]\tLoss: 0.142925\n",
      "Step: 7561 Train Epoch: 32 [10240/60000 (17.0%)]\tLoss: 0.196123\n",
      "Step: 7571 Train Epoch: 32 [12800/60000 (21.3%)]\tLoss: 0.210677\n",
      "Step: 7581 Train Epoch: 32 [15360/60000 (25.5%)]\tLoss: 0.219278\n",
      "Step: 7591 Train Epoch: 32 [17920/60000 (29.8%)]\tLoss: 0.182035\n",
      "Step: 7601 Train Epoch: 32 [20480/60000 (34.0%)]\tLoss: 0.182227\n",
      "Step: 7611 Train Epoch: 32 [23040/60000 (38.3%)]\tLoss: 0.281592\n",
      "Step: 7621 Train Epoch: 32 [25600/60000 (42.6%)]\tLoss: 0.267256\n",
      "Step: 7631 Train Epoch: 32 [28160/60000 (46.8%)]\tLoss: 0.269448\n",
      "Step: 7641 Train Epoch: 32 [30720/60000 (51.1%)]\tLoss: 0.192417\n",
      "Step: 7651 Train Epoch: 32 [33280/60000 (55.3%)]\tLoss: 0.250954\n",
      "Step: 7661 Train Epoch: 32 [35840/60000 (59.6%)]\tLoss: 0.176301\n",
      "Step: 7671 Train Epoch: 32 [38400/60000 (63.8%)]\tLoss: 0.213791\n",
      "Step: 7681 Train Epoch: 32 [40960/60000 (68.1%)]\tLoss: 0.163812\n",
      "Step: 7691 Train Epoch: 32 [43520/60000 (72.3%)]\tLoss: 0.145381\n",
      "Step: 7701 Train Epoch: 32 [46080/60000 (76.6%)]\tLoss: 0.150933\n",
      "Step: 7711 Train Epoch: 32 [48640/60000 (80.9%)]\tLoss: 0.160831\n",
      "Step: 7721 Train Epoch: 32 [51200/60000 (85.1%)]\tLoss: 0.175912\n",
      "Step: 7731 Train Epoch: 32 [53760/60000 (89.4%)]\tLoss: 0.154886\n",
      "Step: 7741 Train Epoch: 32 [56320/60000 (93.6%)]\tLoss: 0.161223\n",
      "Step: 7751 Train Epoch: 32 [58880/60000 (97.9%)]\tLoss: 0.212048\n",
      "\n",
      "Test set: Average loss: 0.2593, Accuracy: 9084/10000 (90.8400%)\n",
      "\n",
      "Start epoch 33/50...\n",
      "Step: 7756 Train Epoch: 33 [0/60000 (0.0%)]\tLoss: 0.153639\n",
      "Step: 7766 Train Epoch: 33 [2560/60000 (4.3%)]\tLoss: 0.250391\n",
      "Step: 7776 Train Epoch: 33 [5120/60000 (8.5%)]\tLoss: 0.171287\n",
      "Step: 7786 Train Epoch: 33 [7680/60000 (12.8%)]\tLoss: 0.256165\n",
      "Step: 7796 Train Epoch: 33 [10240/60000 (17.0%)]\tLoss: 0.183396\n",
      "Step: 7806 Train Epoch: 33 [12800/60000 (21.3%)]\tLoss: 0.340226\n",
      "Step: 7816 Train Epoch: 33 [15360/60000 (25.5%)]\tLoss: 0.156759\n",
      "Step: 7826 Train Epoch: 33 [17920/60000 (29.8%)]\tLoss: 0.181718\n",
      "Step: 7836 Train Epoch: 33 [20480/60000 (34.0%)]\tLoss: 0.247335\n",
      "Step: 7846 Train Epoch: 33 [23040/60000 (38.3%)]\tLoss: 0.159534\n",
      "Step: 7856 Train Epoch: 33 [25600/60000 (42.6%)]\tLoss: 0.183860\n",
      "Step: 7866 Train Epoch: 33 [28160/60000 (46.8%)]\tLoss: 0.172702\n",
      "Step: 7876 Train Epoch: 33 [30720/60000 (51.1%)]\tLoss: 0.198916\n",
      "Step: 7886 Train Epoch: 33 [33280/60000 (55.3%)]\tLoss: 0.216246\n",
      "Step: 7896 Train Epoch: 33 [35840/60000 (59.6%)]\tLoss: 0.217279\n",
      "Step: 7906 Train Epoch: 33 [38400/60000 (63.8%)]\tLoss: 0.151852\n",
      "Step: 7916 Train Epoch: 33 [40960/60000 (68.1%)]\tLoss: 0.213799\n",
      "Step: 7926 Train Epoch: 33 [43520/60000 (72.3%)]\tLoss: 0.174187\n",
      "Step: 7936 Train Epoch: 33 [46080/60000 (76.6%)]\tLoss: 0.168509\n",
      "Step: 7946 Train Epoch: 33 [48640/60000 (80.9%)]\tLoss: 0.211523\n",
      "Step: 7956 Train Epoch: 33 [51200/60000 (85.1%)]\tLoss: 0.182994\n",
      "Step: 7966 Train Epoch: 33 [53760/60000 (89.4%)]\tLoss: 0.210296\n",
      "Step: 7976 Train Epoch: 33 [56320/60000 (93.6%)]\tLoss: 0.127829\n",
      "Step: 7986 Train Epoch: 33 [58880/60000 (97.9%)]\tLoss: 0.133362\n",
      "\n",
      "Test set: Average loss: 0.3749, Accuracy: 8702/10000 (87.0200%)\n",
      "\n",
      "Start epoch 34/50...\n",
      "Step: 7991 Train Epoch: 34 [0/60000 (0.0%)]\tLoss: 0.172539\n",
      "Step: 8001 Train Epoch: 34 [2560/60000 (4.3%)]\tLoss: 0.249206\n",
      "Step: 8011 Train Epoch: 34 [5120/60000 (8.5%)]\tLoss: 0.173481\n",
      "Step: 8021 Train Epoch: 34 [7680/60000 (12.8%)]\tLoss: 0.238453\n",
      "Step: 8031 Train Epoch: 34 [10240/60000 (17.0%)]\tLoss: 0.179440\n",
      "Step: 8041 Train Epoch: 34 [12800/60000 (21.3%)]\tLoss: 0.173361\n",
      "Step: 8051 Train Epoch: 34 [15360/60000 (25.5%)]\tLoss: 0.191769\n",
      "Step: 8061 Train Epoch: 34 [17920/60000 (29.8%)]\tLoss: 0.182432\n",
      "Step: 8071 Train Epoch: 34 [20480/60000 (34.0%)]\tLoss: 0.128380\n",
      "Step: 8081 Train Epoch: 34 [23040/60000 (38.3%)]\tLoss: 0.178299\n",
      "Step: 8091 Train Epoch: 34 [25600/60000 (42.6%)]\tLoss: 0.180606\n",
      "Step: 8101 Train Epoch: 34 [28160/60000 (46.8%)]\tLoss: 0.162198\n",
      "Step: 8111 Train Epoch: 34 [30720/60000 (51.1%)]\tLoss: 0.194644\n",
      "Step: 8121 Train Epoch: 34 [33280/60000 (55.3%)]\tLoss: 0.217574\n",
      "Step: 8131 Train Epoch: 34 [35840/60000 (59.6%)]\tLoss: 0.148484\n",
      "Step: 8141 Train Epoch: 34 [38400/60000 (63.8%)]\tLoss: 0.172932\n",
      "Step: 8151 Train Epoch: 34 [40960/60000 (68.1%)]\tLoss: 0.142484\n",
      "Step: 8161 Train Epoch: 34 [43520/60000 (72.3%)]\tLoss: 0.208585\n",
      "Step: 8171 Train Epoch: 34 [46080/60000 (76.6%)]\tLoss: 0.168505\n",
      "Step: 8181 Train Epoch: 34 [48640/60000 (80.9%)]\tLoss: 0.160517\n",
      "Step: 8191 Train Epoch: 34 [51200/60000 (85.1%)]\tLoss: 0.242076\n",
      "Step: 8201 Train Epoch: 34 [53760/60000 (89.4%)]\tLoss: 0.176914\n",
      "Step: 8211 Train Epoch: 34 [56320/60000 (93.6%)]\tLoss: 0.223568\n",
      "Step: 8221 Train Epoch: 34 [58880/60000 (97.9%)]\tLoss: 0.195617\n",
      "\n",
      "Test set: Average loss: 0.2987, Accuracy: 8919/10000 (89.1900%)\n",
      "\n",
      "Start epoch 35/50...\n",
      "Step: 8226 Train Epoch: 35 [0/60000 (0.0%)]\tLoss: 0.168977\n",
      "Step: 8236 Train Epoch: 35 [2560/60000 (4.3%)]\tLoss: 0.224663\n",
      "Step: 8246 Train Epoch: 35 [5120/60000 (8.5%)]\tLoss: 0.190248\n",
      "Step: 8256 Train Epoch: 35 [7680/60000 (12.8%)]\tLoss: 0.218562\n",
      "Step: 8266 Train Epoch: 35 [10240/60000 (17.0%)]\tLoss: 0.130890\n",
      "Step: 8276 Train Epoch: 35 [12800/60000 (21.3%)]\tLoss: 0.137028\n",
      "Step: 8286 Train Epoch: 35 [15360/60000 (25.5%)]\tLoss: 0.144617\n",
      "Step: 8296 Train Epoch: 35 [17920/60000 (29.8%)]\tLoss: 0.181306\n",
      "Step: 8306 Train Epoch: 35 [20480/60000 (34.0%)]\tLoss: 0.132135\n",
      "Step: 8316 Train Epoch: 35 [23040/60000 (38.3%)]\tLoss: 0.146453\n",
      "Step: 8326 Train Epoch: 35 [25600/60000 (42.6%)]\tLoss: 0.201660\n",
      "Step: 8336 Train Epoch: 35 [28160/60000 (46.8%)]\tLoss: 0.189508\n",
      "Step: 8346 Train Epoch: 35 [30720/60000 (51.1%)]\tLoss: 0.186025\n",
      "Step: 8356 Train Epoch: 35 [33280/60000 (55.3%)]\tLoss: 0.151722\n",
      "Step: 8366 Train Epoch: 35 [35840/60000 (59.6%)]\tLoss: 0.206628\n",
      "Step: 8376 Train Epoch: 35 [38400/60000 (63.8%)]\tLoss: 0.122622\n",
      "Step: 8386 Train Epoch: 35 [40960/60000 (68.1%)]\tLoss: 0.154140\n",
      "Step: 8396 Train Epoch: 35 [43520/60000 (72.3%)]\tLoss: 0.172575\n",
      "Step: 8406 Train Epoch: 35 [46080/60000 (76.6%)]\tLoss: 0.261271\n",
      "Step: 8416 Train Epoch: 35 [48640/60000 (80.9%)]\tLoss: 0.203028\n",
      "Step: 8426 Train Epoch: 35 [51200/60000 (85.1%)]\tLoss: 0.216941\n",
      "Step: 8436 Train Epoch: 35 [53760/60000 (89.4%)]\tLoss: 0.235043\n",
      "Step: 8446 Train Epoch: 35 [56320/60000 (93.6%)]\tLoss: 0.205084\n",
      "Step: 8456 Train Epoch: 35 [58880/60000 (97.9%)]\tLoss: 0.148587\n",
      "\n",
      "Test set: Average loss: 0.2697, Accuracy: 9062/10000 (90.6200%)\n",
      "\n",
      "Start epoch 36/50...\n",
      "Step: 8461 Train Epoch: 36 [0/60000 (0.0%)]\tLoss: 0.163285\n",
      "Step: 8471 Train Epoch: 36 [2560/60000 (4.3%)]\tLoss: 0.174130\n",
      "Step: 8481 Train Epoch: 36 [5120/60000 (8.5%)]\tLoss: 0.103843\n",
      "Step: 8491 Train Epoch: 36 [7680/60000 (12.8%)]\tLoss: 0.128829\n",
      "Step: 8501 Train Epoch: 36 [10240/60000 (17.0%)]\tLoss: 0.129761\n",
      "Step: 8511 Train Epoch: 36 [12800/60000 (21.3%)]\tLoss: 0.144822\n",
      "Step: 8521 Train Epoch: 36 [15360/60000 (25.5%)]\tLoss: 0.125528\n",
      "Step: 8531 Train Epoch: 36 [17920/60000 (29.8%)]\tLoss: 0.145847\n",
      "Step: 8541 Train Epoch: 36 [20480/60000 (34.0%)]\tLoss: 0.244126\n",
      "Step: 8551 Train Epoch: 36 [23040/60000 (38.3%)]\tLoss: 0.178837\n",
      "Step: 8561 Train Epoch: 36 [25600/60000 (42.6%)]\tLoss: 0.240475\n",
      "Step: 8571 Train Epoch: 36 [28160/60000 (46.8%)]\tLoss: 0.173762\n",
      "Step: 8581 Train Epoch: 36 [30720/60000 (51.1%)]\tLoss: 0.142230\n",
      "Step: 8591 Train Epoch: 36 [33280/60000 (55.3%)]\tLoss: 0.228662\n",
      "Step: 8601 Train Epoch: 36 [35840/60000 (59.6%)]\tLoss: 0.249871\n",
      "Step: 8611 Train Epoch: 36 [38400/60000 (63.8%)]\tLoss: 0.169981\n",
      "Step: 8621 Train Epoch: 36 [40960/60000 (68.1%)]\tLoss: 0.218470\n",
      "Step: 8631 Train Epoch: 36 [43520/60000 (72.3%)]\tLoss: 0.166136\n",
      "Step: 8641 Train Epoch: 36 [46080/60000 (76.6%)]\tLoss: 0.210391\n",
      "Step: 8651 Train Epoch: 36 [48640/60000 (80.9%)]\tLoss: 0.213454\n",
      "Step: 8661 Train Epoch: 36 [51200/60000 (85.1%)]\tLoss: 0.114549\n",
      "Step: 8671 Train Epoch: 36 [53760/60000 (89.4%)]\tLoss: 0.125119\n",
      "Step: 8681 Train Epoch: 36 [56320/60000 (93.6%)]\tLoss: 0.132798\n",
      "Step: 8691 Train Epoch: 36 [58880/60000 (97.9%)]\tLoss: 0.188168\n",
      "\n",
      "Test set: Average loss: 0.2610, Accuracy: 9082/10000 (90.8200%)\n",
      "\n",
      "Start epoch 37/50...\n",
      "Step: 8696 Train Epoch: 37 [0/60000 (0.0%)]\tLoss: 0.133848\n",
      "Step: 8706 Train Epoch: 37 [2560/60000 (4.3%)]\tLoss: 0.171627\n",
      "Step: 8716 Train Epoch: 37 [5120/60000 (8.5%)]\tLoss: 0.145802\n",
      "Step: 8726 Train Epoch: 37 [7680/60000 (12.8%)]\tLoss: 0.157875\n",
      "Step: 8736 Train Epoch: 37 [10240/60000 (17.0%)]\tLoss: 0.204271\n",
      "Step: 8746 Train Epoch: 37 [12800/60000 (21.3%)]\tLoss: 0.151168\n",
      "Step: 8756 Train Epoch: 37 [15360/60000 (25.5%)]\tLoss: 0.134903\n",
      "Step: 8766 Train Epoch: 37 [17920/60000 (29.8%)]\tLoss: 0.142218\n",
      "Step: 8776 Train Epoch: 37 [20480/60000 (34.0%)]\tLoss: 0.131281\n",
      "Step: 8786 Train Epoch: 37 [23040/60000 (38.3%)]\tLoss: 0.160923\n",
      "Step: 8796 Train Epoch: 37 [25600/60000 (42.6%)]\tLoss: 0.186267\n",
      "Step: 8806 Train Epoch: 37 [28160/60000 (46.8%)]\tLoss: 0.262794\n",
      "Step: 8816 Train Epoch: 37 [30720/60000 (51.1%)]\tLoss: 0.211900\n",
      "Step: 8826 Train Epoch: 37 [33280/60000 (55.3%)]\tLoss: 0.217064\n",
      "Step: 8836 Train Epoch: 37 [35840/60000 (59.6%)]\tLoss: 0.170943\n",
      "Step: 8846 Train Epoch: 37 [38400/60000 (63.8%)]\tLoss: 0.180533\n",
      "Step: 8856 Train Epoch: 37 [40960/60000 (68.1%)]\tLoss: 0.198812\n",
      "Step: 8866 Train Epoch: 37 [43520/60000 (72.3%)]\tLoss: 0.135183\n",
      "Step: 8876 Train Epoch: 37 [46080/60000 (76.6%)]\tLoss: 0.190586\n",
      "Step: 8886 Train Epoch: 37 [48640/60000 (80.9%)]\tLoss: 0.163244\n",
      "Step: 8896 Train Epoch: 37 [51200/60000 (85.1%)]\tLoss: 0.158656\n",
      "Step: 8906 Train Epoch: 37 [53760/60000 (89.4%)]\tLoss: 0.205231\n",
      "Step: 8916 Train Epoch: 37 [56320/60000 (93.6%)]\tLoss: 0.145864\n",
      "Step: 8926 Train Epoch: 37 [58880/60000 (97.9%)]\tLoss: 0.153873\n",
      "\n",
      "Test set: Average loss: 0.2525, Accuracy: 9127/10000 (91.2700%)\n",
      "\n",
      "Start epoch 38/50...\n",
      "Step: 8931 Train Epoch: 38 [0/60000 (0.0%)]\tLoss: 0.122833\n",
      "Step: 8941 Train Epoch: 38 [2560/60000 (4.3%)]\tLoss: 0.127901\n",
      "Step: 8951 Train Epoch: 38 [5120/60000 (8.5%)]\tLoss: 0.121128\n",
      "Step: 8961 Train Epoch: 38 [7680/60000 (12.8%)]\tLoss: 0.177935\n",
      "Step: 8971 Train Epoch: 38 [10240/60000 (17.0%)]\tLoss: 0.185874\n",
      "Step: 8981 Train Epoch: 38 [12800/60000 (21.3%)]\tLoss: 0.162163\n",
      "Step: 8991 Train Epoch: 38 [15360/60000 (25.5%)]\tLoss: 0.208001\n",
      "Step: 9001 Train Epoch: 38 [17920/60000 (29.8%)]\tLoss: 0.203475\n",
      "Step: 9011 Train Epoch: 38 [20480/60000 (34.0%)]\tLoss: 0.173556\n",
      "Step: 9021 Train Epoch: 38 [23040/60000 (38.3%)]\tLoss: 0.231859\n",
      "Step: 9031 Train Epoch: 38 [25600/60000 (42.6%)]\tLoss: 0.187384\n",
      "Step: 9041 Train Epoch: 38 [28160/60000 (46.8%)]\tLoss: 0.164831\n",
      "Step: 9051 Train Epoch: 38 [30720/60000 (51.1%)]\tLoss: 0.158800\n",
      "Step: 9061 Train Epoch: 38 [33280/60000 (55.3%)]\tLoss: 0.197628\n",
      "Step: 9071 Train Epoch: 38 [35840/60000 (59.6%)]\tLoss: 0.132663\n",
      "Step: 9081 Train Epoch: 38 [38400/60000 (63.8%)]\tLoss: 0.144429\n",
      "Step: 9091 Train Epoch: 38 [40960/60000 (68.1%)]\tLoss: 0.139811\n",
      "Step: 9101 Train Epoch: 38 [43520/60000 (72.3%)]\tLoss: 0.168655\n",
      "Step: 9111 Train Epoch: 38 [46080/60000 (76.6%)]\tLoss: 0.149966\n",
      "Step: 9121 Train Epoch: 38 [48640/60000 (80.9%)]\tLoss: 0.122098\n",
      "Step: 9131 Train Epoch: 38 [51200/60000 (85.1%)]\tLoss: 0.172799\n",
      "Step: 9141 Train Epoch: 38 [53760/60000 (89.4%)]\tLoss: 0.122111\n",
      "Step: 9151 Train Epoch: 38 [56320/60000 (93.6%)]\tLoss: 0.128777\n",
      "Step: 9161 Train Epoch: 38 [58880/60000 (97.9%)]\tLoss: 0.308272\n",
      "\n",
      "Test set: Average loss: 0.3055, Accuracy: 9025/10000 (90.2500%)\n",
      "\n",
      "Start epoch 39/50...\n",
      "Step: 9166 Train Epoch: 39 [0/60000 (0.0%)]\tLoss: 0.170833\n",
      "Step: 9176 Train Epoch: 39 [2560/60000 (4.3%)]\tLoss: 0.167576\n",
      "Step: 9186 Train Epoch: 39 [5120/60000 (8.5%)]\tLoss: 0.172961\n",
      "Step: 9196 Train Epoch: 39 [7680/60000 (12.8%)]\tLoss: 0.240105\n",
      "Step: 9206 Train Epoch: 39 [10240/60000 (17.0%)]\tLoss: 0.225633\n",
      "Step: 9216 Train Epoch: 39 [12800/60000 (21.3%)]\tLoss: 0.198238\n",
      "Step: 9226 Train Epoch: 39 [15360/60000 (25.5%)]\tLoss: 0.150884\n",
      "Step: 9236 Train Epoch: 39 [17920/60000 (29.8%)]\tLoss: 0.202909\n",
      "Step: 9246 Train Epoch: 39 [20480/60000 (34.0%)]\tLoss: 0.140416\n",
      "Step: 9256 Train Epoch: 39 [23040/60000 (38.3%)]\tLoss: 0.224379\n",
      "Step: 9266 Train Epoch: 39 [25600/60000 (42.6%)]\tLoss: 0.198480\n",
      "Step: 9276 Train Epoch: 39 [28160/60000 (46.8%)]\tLoss: 0.140056\n",
      "Step: 9286 Train Epoch: 39 [30720/60000 (51.1%)]\tLoss: 0.128206\n",
      "Step: 9296 Train Epoch: 39 [33280/60000 (55.3%)]\tLoss: 0.166442\n",
      "Step: 9306 Train Epoch: 39 [35840/60000 (59.6%)]\tLoss: 0.121564\n",
      "Step: 9316 Train Epoch: 39 [38400/60000 (63.8%)]\tLoss: 0.145496\n",
      "Step: 9326 Train Epoch: 39 [40960/60000 (68.1%)]\tLoss: 0.194524\n",
      "Step: 9336 Train Epoch: 39 [43520/60000 (72.3%)]\tLoss: 0.159176\n",
      "Step: 9346 Train Epoch: 39 [46080/60000 (76.6%)]\tLoss: 0.209395\n",
      "Step: 9356 Train Epoch: 39 [48640/60000 (80.9%)]\tLoss: 0.184951\n",
      "Step: 9366 Train Epoch: 39 [51200/60000 (85.1%)]\tLoss: 0.166804\n",
      "Step: 9376 Train Epoch: 39 [53760/60000 (89.4%)]\tLoss: 0.194919\n",
      "Step: 9386 Train Epoch: 39 [56320/60000 (93.6%)]\tLoss: 0.200351\n",
      "Step: 9396 Train Epoch: 39 [58880/60000 (97.9%)]\tLoss: 0.190096\n",
      "\n",
      "Test set: Average loss: 0.3109, Accuracy: 8997/10000 (89.9700%)\n",
      "\n",
      "Start epoch 40/50...\n",
      "Step: 9401 Train Epoch: 40 [0/60000 (0.0%)]\tLoss: 0.223238\n",
      "Step: 9411 Train Epoch: 40 [2560/60000 (4.3%)]\tLoss: 0.182583\n",
      "Step: 9421 Train Epoch: 40 [5120/60000 (8.5%)]\tLoss: 0.176709\n",
      "Step: 9431 Train Epoch: 40 [7680/60000 (12.8%)]\tLoss: 0.120883\n",
      "Step: 9441 Train Epoch: 40 [10240/60000 (17.0%)]\tLoss: 0.179313\n",
      "Step: 9451 Train Epoch: 40 [12800/60000 (21.3%)]\tLoss: 0.196332\n",
      "Step: 9461 Train Epoch: 40 [15360/60000 (25.5%)]\tLoss: 0.166443\n",
      "Step: 9471 Train Epoch: 40 [17920/60000 (29.8%)]\tLoss: 0.133031\n",
      "Step: 9481 Train Epoch: 40 [20480/60000 (34.0%)]\tLoss: 0.113376\n",
      "Step: 9491 Train Epoch: 40 [23040/60000 (38.3%)]\tLoss: 0.145973\n",
      "Step: 9501 Train Epoch: 40 [25600/60000 (42.6%)]\tLoss: 0.145448\n",
      "Step: 9511 Train Epoch: 40 [28160/60000 (46.8%)]\tLoss: 0.122344\n",
      "Step: 9521 Train Epoch: 40 [30720/60000 (51.1%)]\tLoss: 0.109966\n",
      "Step: 9531 Train Epoch: 40 [33280/60000 (55.3%)]\tLoss: 0.140567\n",
      "Step: 9541 Train Epoch: 40 [35840/60000 (59.6%)]\tLoss: 0.141078\n",
      "Step: 9551 Train Epoch: 40 [38400/60000 (63.8%)]\tLoss: 0.146160\n",
      "Step: 9561 Train Epoch: 40 [40960/60000 (68.1%)]\tLoss: 0.113822\n",
      "Step: 9571 Train Epoch: 40 [43520/60000 (72.3%)]\tLoss: 0.141592\n",
      "Step: 9581 Train Epoch: 40 [46080/60000 (76.6%)]\tLoss: 0.165793\n",
      "Step: 9591 Train Epoch: 40 [48640/60000 (80.9%)]\tLoss: 0.235065\n",
      "Step: 9601 Train Epoch: 40 [51200/60000 (85.1%)]\tLoss: 0.160920\n",
      "Step: 9611 Train Epoch: 40 [53760/60000 (89.4%)]\tLoss: 0.272845\n",
      "Step: 9621 Train Epoch: 40 [56320/60000 (93.6%)]\tLoss: 0.221004\n",
      "Step: 9631 Train Epoch: 40 [58880/60000 (97.9%)]\tLoss: 0.126828\n",
      "\n",
      "Test set: Average loss: 0.2873, Accuracy: 9053/10000 (90.5300%)\n",
      "\n",
      "Start epoch 41/50...\n",
      "Step: 9636 Train Epoch: 41 [0/60000 (0.0%)]\tLoss: 0.125381\n",
      "Step: 9646 Train Epoch: 41 [2560/60000 (4.3%)]\tLoss: 0.122042\n",
      "Step: 9656 Train Epoch: 41 [5120/60000 (8.5%)]\tLoss: 0.126613\n",
      "Step: 9666 Train Epoch: 41 [7680/60000 (12.8%)]\tLoss: 0.142868\n",
      "Step: 9676 Train Epoch: 41 [10240/60000 (17.0%)]\tLoss: 0.163310\n",
      "Step: 9686 Train Epoch: 41 [12800/60000 (21.3%)]\tLoss: 0.108720\n",
      "Step: 9696 Train Epoch: 41 [15360/60000 (25.5%)]\tLoss: 0.111963\n",
      "Step: 9706 Train Epoch: 41 [17920/60000 (29.8%)]\tLoss: 0.111748\n",
      "Step: 9716 Train Epoch: 41 [20480/60000 (34.0%)]\tLoss: 0.141758\n",
      "Step: 9726 Train Epoch: 41 [23040/60000 (38.3%)]\tLoss: 0.111189\n",
      "Step: 9736 Train Epoch: 41 [25600/60000 (42.6%)]\tLoss: 0.124682\n",
      "Step: 9746 Train Epoch: 41 [28160/60000 (46.8%)]\tLoss: 0.108621\n",
      "Step: 9756 Train Epoch: 41 [30720/60000 (51.1%)]\tLoss: 0.146886\n",
      "Step: 9766 Train Epoch: 41 [33280/60000 (55.3%)]\tLoss: 0.190794\n",
      "Step: 9776 Train Epoch: 41 [35840/60000 (59.6%)]\tLoss: 0.146017\n",
      "Step: 9786 Train Epoch: 41 [38400/60000 (63.8%)]\tLoss: 0.236444\n",
      "Step: 9796 Train Epoch: 41 [40960/60000 (68.1%)]\tLoss: 0.209045\n",
      "Step: 9806 Train Epoch: 41 [43520/60000 (72.3%)]\tLoss: 0.144361\n",
      "Step: 9816 Train Epoch: 41 [46080/60000 (76.6%)]\tLoss: 0.177040\n",
      "Step: 9826 Train Epoch: 41 [48640/60000 (80.9%)]\tLoss: 0.161854\n",
      "Step: 9836 Train Epoch: 41 [51200/60000 (85.1%)]\tLoss: 0.150005\n",
      "Step: 9846 Train Epoch: 41 [53760/60000 (89.4%)]\tLoss: 0.176197\n",
      "Step: 9856 Train Epoch: 41 [56320/60000 (93.6%)]\tLoss: 0.192980\n",
      "Step: 9866 Train Epoch: 41 [58880/60000 (97.9%)]\tLoss: 0.189276\n",
      "\n",
      "Test set: Average loss: 0.2798, Accuracy: 9113/10000 (91.1300%)\n",
      "\n",
      "Start epoch 42/50...\n",
      "Step: 9871 Train Epoch: 42 [0/60000 (0.0%)]\tLoss: 0.121567\n",
      "Step: 9881 Train Epoch: 42 [2560/60000 (4.3%)]\tLoss: 0.214755\n",
      "Step: 9891 Train Epoch: 42 [5120/60000 (8.5%)]\tLoss: 0.120797\n",
      "Step: 9901 Train Epoch: 42 [7680/60000 (12.8%)]\tLoss: 0.164661\n",
      "Step: 9911 Train Epoch: 42 [10240/60000 (17.0%)]\tLoss: 0.149762\n",
      "Step: 9921 Train Epoch: 42 [12800/60000 (21.3%)]\tLoss: 0.100742\n",
      "Step: 9931 Train Epoch: 42 [15360/60000 (25.5%)]\tLoss: 0.099452\n",
      "Step: 9941 Train Epoch: 42 [17920/60000 (29.8%)]\tLoss: 0.134552\n",
      "Step: 9951 Train Epoch: 42 [20480/60000 (34.0%)]\tLoss: 0.105466\n",
      "Step: 9961 Train Epoch: 42 [23040/60000 (38.3%)]\tLoss: 0.110328\n",
      "Step: 9971 Train Epoch: 42 [25600/60000 (42.6%)]\tLoss: 0.124952\n",
      "Step: 9981 Train Epoch: 42 [28160/60000 (46.8%)]\tLoss: 0.160195\n",
      "Step: 9991 Train Epoch: 42 [30720/60000 (51.1%)]\tLoss: 0.159070\n",
      "Step: 10001 Train Epoch: 42 [33280/60000 (55.3%)]\tLoss: 0.251429\n",
      "Step: 10011 Train Epoch: 42 [35840/60000 (59.6%)]\tLoss: 0.166063\n",
      "Step: 10021 Train Epoch: 42 [38400/60000 (63.8%)]\tLoss: 0.202365\n",
      "Step: 10031 Train Epoch: 42 [40960/60000 (68.1%)]\tLoss: 0.226492\n",
      "Step: 10041 Train Epoch: 42 [43520/60000 (72.3%)]\tLoss: 0.177089\n",
      "Step: 10051 Train Epoch: 42 [46080/60000 (76.6%)]\tLoss: 0.205298\n",
      "Step: 10061 Train Epoch: 42 [48640/60000 (80.9%)]\tLoss: 0.180379\n",
      "Step: 10071 Train Epoch: 42 [51200/60000 (85.1%)]\tLoss: 0.197585\n",
      "Step: 10081 Train Epoch: 42 [53760/60000 (89.4%)]\tLoss: 0.133381\n",
      "Step: 10091 Train Epoch: 42 [56320/60000 (93.6%)]\tLoss: 0.132377\n",
      "Step: 10101 Train Epoch: 42 [58880/60000 (97.9%)]\tLoss: 0.110459\n",
      "\n",
      "Test set: Average loss: 0.2621, Accuracy: 9132/10000 (91.3200%)\n",
      "\n",
      "Start epoch 43/50...\n",
      "Step: 10106 Train Epoch: 43 [0/60000 (0.0%)]\tLoss: 0.146870\n",
      "Step: 10116 Train Epoch: 43 [2560/60000 (4.3%)]\tLoss: 0.153596\n",
      "Step: 10126 Train Epoch: 43 [5120/60000 (8.5%)]\tLoss: 0.134811\n",
      "Step: 10136 Train Epoch: 43 [7680/60000 (12.8%)]\tLoss: 0.134486\n",
      "Step: 10146 Train Epoch: 43 [10240/60000 (17.0%)]\tLoss: 0.103169\n",
      "Step: 10156 Train Epoch: 43 [12800/60000 (21.3%)]\tLoss: 0.119353\n",
      "Step: 10166 Train Epoch: 43 [15360/60000 (25.5%)]\tLoss: 0.117828\n",
      "Step: 10176 Train Epoch: 43 [17920/60000 (29.8%)]\tLoss: 0.211545\n",
      "Step: 10186 Train Epoch: 43 [20480/60000 (34.0%)]\tLoss: 0.128451\n",
      "Step: 10196 Train Epoch: 43 [23040/60000 (38.3%)]\tLoss: 0.164060\n",
      "Step: 10206 Train Epoch: 43 [25600/60000 (42.6%)]\tLoss: 0.236190\n",
      "Step: 10216 Train Epoch: 43 [28160/60000 (46.8%)]\tLoss: 0.199078\n",
      "Step: 10226 Train Epoch: 43 [30720/60000 (51.1%)]\tLoss: 0.236108\n",
      "Step: 10236 Train Epoch: 43 [33280/60000 (55.3%)]\tLoss: 0.193074\n",
      "Step: 10246 Train Epoch: 43 [35840/60000 (59.6%)]\tLoss: 0.173943\n",
      "Step: 10256 Train Epoch: 43 [38400/60000 (63.8%)]\tLoss: 0.133370\n",
      "Step: 10266 Train Epoch: 43 [40960/60000 (68.1%)]\tLoss: 0.180120\n",
      "Step: 10276 Train Epoch: 43 [43520/60000 (72.3%)]\tLoss: 0.172895\n",
      "Step: 10286 Train Epoch: 43 [46080/60000 (76.6%)]\tLoss: 0.153993\n",
      "Step: 10296 Train Epoch: 43 [48640/60000 (80.9%)]\tLoss: 0.129160\n",
      "Step: 10306 Train Epoch: 43 [51200/60000 (85.1%)]\tLoss: 0.118531\n",
      "Step: 10316 Train Epoch: 43 [53760/60000 (89.4%)]\tLoss: 0.133540\n",
      "Step: 10326 Train Epoch: 43 [56320/60000 (93.6%)]\tLoss: 0.139660\n",
      "Step: 10336 Train Epoch: 43 [58880/60000 (97.9%)]\tLoss: 0.130593\n",
      "\n",
      "Test set: Average loss: 0.2639, Accuracy: 9169/10000 (91.6900%)\n",
      "\n",
      "Start epoch 44/50...\n",
      "Step: 10341 Train Epoch: 44 [0/60000 (0.0%)]\tLoss: 0.137646\n",
      "Step: 10351 Train Epoch: 44 [2560/60000 (4.3%)]\tLoss: 0.120792\n",
      "Step: 10361 Train Epoch: 44 [5120/60000 (8.5%)]\tLoss: 0.122321\n",
      "Step: 10371 Train Epoch: 44 [7680/60000 (12.8%)]\tLoss: 0.132938\n",
      "Step: 10381 Train Epoch: 44 [10240/60000 (17.0%)]\tLoss: 0.157875\n",
      "Step: 10391 Train Epoch: 44 [12800/60000 (21.3%)]\tLoss: 0.196504\n",
      "Step: 10401 Train Epoch: 44 [15360/60000 (25.5%)]\tLoss: 0.143818\n",
      "Step: 10411 Train Epoch: 44 [17920/60000 (29.8%)]\tLoss: 0.247525\n",
      "Step: 10421 Train Epoch: 44 [20480/60000 (34.0%)]\tLoss: 0.220031\n",
      "Step: 10431 Train Epoch: 44 [23040/60000 (38.3%)]\tLoss: 0.202836\n",
      "Step: 10441 Train Epoch: 44 [25600/60000 (42.6%)]\tLoss: 0.215558\n",
      "Step: 10451 Train Epoch: 44 [28160/60000 (46.8%)]\tLoss: 0.139392\n",
      "Step: 10461 Train Epoch: 44 [30720/60000 (51.1%)]\tLoss: 0.228949\n",
      "Step: 10471 Train Epoch: 44 [33280/60000 (55.3%)]\tLoss: 0.164711\n",
      "Step: 10481 Train Epoch: 44 [35840/60000 (59.6%)]\tLoss: 0.176261\n",
      "Step: 10491 Train Epoch: 44 [38400/60000 (63.8%)]\tLoss: 0.169023\n",
      "Step: 10501 Train Epoch: 44 [40960/60000 (68.1%)]\tLoss: 0.141616\n",
      "Step: 10511 Train Epoch: 44 [43520/60000 (72.3%)]\tLoss: 0.136504\n",
      "Step: 10521 Train Epoch: 44 [46080/60000 (76.6%)]\tLoss: 0.140836\n",
      "Step: 10531 Train Epoch: 44 [48640/60000 (80.9%)]\tLoss: 0.104270\n",
      "Step: 10541 Train Epoch: 44 [51200/60000 (85.1%)]\tLoss: 0.169767\n",
      "Step: 10551 Train Epoch: 44 [53760/60000 (89.4%)]\tLoss: 0.131211\n",
      "Step: 10561 Train Epoch: 44 [56320/60000 (93.6%)]\tLoss: 0.172121\n",
      "Step: 10571 Train Epoch: 44 [58880/60000 (97.9%)]\tLoss: 0.127401\n",
      "\n",
      "Test set: Average loss: 0.3035, Accuracy: 8998/10000 (89.9800%)\n",
      "\n",
      "Start epoch 45/50...\n",
      "Step: 10576 Train Epoch: 45 [0/60000 (0.0%)]\tLoss: 0.166392\n",
      "Step: 10586 Train Epoch: 45 [2560/60000 (4.3%)]\tLoss: 0.175252\n",
      "Step: 10596 Train Epoch: 45 [5120/60000 (8.5%)]\tLoss: 0.202335\n",
      "Step: 10606 Train Epoch: 45 [7680/60000 (12.8%)]\tLoss: 0.194798\n",
      "Step: 10616 Train Epoch: 45 [10240/60000 (17.0%)]\tLoss: 0.150326\n",
      "Step: 10626 Train Epoch: 45 [12800/60000 (21.3%)]\tLoss: 0.133688\n",
      "Step: 10636 Train Epoch: 45 [15360/60000 (25.5%)]\tLoss: 0.125395\n",
      "Step: 10646 Train Epoch: 45 [17920/60000 (29.8%)]\tLoss: 0.162384\n",
      "Step: 10656 Train Epoch: 45 [20480/60000 (34.0%)]\tLoss: 0.174637\n",
      "Step: 10666 Train Epoch: 45 [23040/60000 (38.3%)]\tLoss: 0.134298\n",
      "Step: 10676 Train Epoch: 45 [25600/60000 (42.6%)]\tLoss: 0.157252\n",
      "Step: 10686 Train Epoch: 45 [28160/60000 (46.8%)]\tLoss: 0.152572\n",
      "Step: 10696 Train Epoch: 45 [30720/60000 (51.1%)]\tLoss: 0.128910\n",
      "Step: 10706 Train Epoch: 45 [33280/60000 (55.3%)]\tLoss: 0.124129\n",
      "Step: 10716 Train Epoch: 45 [35840/60000 (59.6%)]\tLoss: 0.122587\n",
      "Step: 10726 Train Epoch: 45 [38400/60000 (63.8%)]\tLoss: 0.126009\n",
      "Step: 10736 Train Epoch: 45 [40960/60000 (68.1%)]\tLoss: 0.099893\n",
      "Step: 10746 Train Epoch: 45 [43520/60000 (72.3%)]\tLoss: 0.105725\n",
      "Step: 10756 Train Epoch: 45 [46080/60000 (76.6%)]\tLoss: 0.120954\n",
      "Step: 10766 Train Epoch: 45 [48640/60000 (80.9%)]\tLoss: 0.172484\n",
      "Step: 10776 Train Epoch: 45 [51200/60000 (85.1%)]\tLoss: 0.150274\n",
      "Step: 10786 Train Epoch: 45 [53760/60000 (89.4%)]\tLoss: 0.241622\n",
      "Step: 10796 Train Epoch: 45 [56320/60000 (93.6%)]\tLoss: 0.214888\n",
      "Step: 10806 Train Epoch: 45 [58880/60000 (97.9%)]\tLoss: 0.293498\n",
      "\n",
      "Test set: Average loss: 0.2942, Accuracy: 9034/10000 (90.3400%)\n",
      "\n",
      "Start epoch 46/50...\n",
      "Step: 10811 Train Epoch: 46 [0/60000 (0.0%)]\tLoss: 0.137697\n",
      "Step: 10821 Train Epoch: 46 [2560/60000 (4.3%)]\tLoss: 0.132451\n",
      "Step: 10831 Train Epoch: 46 [5120/60000 (8.5%)]\tLoss: 0.143148\n",
      "Step: 10841 Train Epoch: 46 [7680/60000 (12.8%)]\tLoss: 0.155564\n",
      "Step: 10851 Train Epoch: 46 [10240/60000 (17.0%)]\tLoss: 0.100098\n",
      "Step: 10861 Train Epoch: 46 [12800/60000 (21.3%)]\tLoss: 0.135162\n",
      "Step: 10871 Train Epoch: 46 [15360/60000 (25.5%)]\tLoss: 0.146396\n",
      "Step: 10881 Train Epoch: 46 [17920/60000 (29.8%)]\tLoss: 0.141642\n",
      "Step: 10891 Train Epoch: 46 [20480/60000 (34.0%)]\tLoss: 0.119149\n",
      "Step: 10901 Train Epoch: 46 [23040/60000 (38.3%)]\tLoss: 0.143659\n",
      "Step: 10911 Train Epoch: 46 [25600/60000 (42.6%)]\tLoss: 0.141232\n",
      "Step: 10921 Train Epoch: 46 [28160/60000 (46.8%)]\tLoss: 0.167560\n",
      "Step: 10931 Train Epoch: 46 [30720/60000 (51.1%)]\tLoss: 0.140578\n",
      "Step: 10941 Train Epoch: 46 [33280/60000 (55.3%)]\tLoss: 0.092294\n",
      "Step: 10951 Train Epoch: 46 [35840/60000 (59.6%)]\tLoss: 0.119567\n",
      "Step: 10961 Train Epoch: 46 [38400/60000 (63.8%)]\tLoss: 0.167909\n",
      "Step: 10971 Train Epoch: 46 [40960/60000 (68.1%)]\tLoss: 0.165868\n",
      "Step: 10981 Train Epoch: 46 [43520/60000 (72.3%)]\tLoss: 0.207174\n",
      "Step: 10991 Train Epoch: 46 [46080/60000 (76.6%)]\tLoss: 0.185856\n",
      "Step: 11001 Train Epoch: 46 [48640/60000 (80.9%)]\tLoss: 0.201735\n",
      "Step: 11011 Train Epoch: 46 [51200/60000 (85.1%)]\tLoss: 0.232313\n",
      "Step: 11021 Train Epoch: 46 [53760/60000 (89.4%)]\tLoss: 0.196680\n",
      "Step: 11031 Train Epoch: 46 [56320/60000 (93.6%)]\tLoss: 0.205849\n",
      "Step: 11041 Train Epoch: 46 [58880/60000 (97.9%)]\tLoss: 0.137643\n",
      "\n",
      "Test set: Average loss: 0.3078, Accuracy: 9047/10000 (90.4700%)\n",
      "\n",
      "Start epoch 47/50...\n",
      "Step: 11046 Train Epoch: 47 [0/60000 (0.0%)]\tLoss: 0.130558\n",
      "Step: 11056 Train Epoch: 47 [2560/60000 (4.3%)]\tLoss: 0.124278\n",
      "Step: 11066 Train Epoch: 47 [5120/60000 (8.5%)]\tLoss: 0.166688\n",
      "Step: 11076 Train Epoch: 47 [7680/60000 (12.8%)]\tLoss: 0.148246\n",
      "Step: 11086 Train Epoch: 47 [10240/60000 (17.0%)]\tLoss: 0.114402\n",
      "Step: 11096 Train Epoch: 47 [12800/60000 (21.3%)]\tLoss: 0.141860\n",
      "Step: 11106 Train Epoch: 47 [15360/60000 (25.5%)]\tLoss: 0.133844\n",
      "Step: 11116 Train Epoch: 47 [17920/60000 (29.8%)]\tLoss: 0.125800\n",
      "Step: 11126 Train Epoch: 47 [20480/60000 (34.0%)]\tLoss: 0.085516\n",
      "Step: 11136 Train Epoch: 47 [23040/60000 (38.3%)]\tLoss: 0.138671\n",
      "Step: 11146 Train Epoch: 47 [25600/60000 (42.6%)]\tLoss: 0.114091\n",
      "Step: 11156 Train Epoch: 47 [28160/60000 (46.8%)]\tLoss: 0.115455\n",
      "Step: 11166 Train Epoch: 47 [30720/60000 (51.1%)]\tLoss: 0.104162\n",
      "Step: 11176 Train Epoch: 47 [33280/60000 (55.3%)]\tLoss: 0.171398\n",
      "Step: 11186 Train Epoch: 47 [35840/60000 (59.6%)]\tLoss: 0.159077\n",
      "Step: 11196 Train Epoch: 47 [38400/60000 (63.8%)]\tLoss: 0.176572\n",
      "Step: 11206 Train Epoch: 47 [40960/60000 (68.1%)]\tLoss: 0.157823\n",
      "Step: 11216 Train Epoch: 47 [43520/60000 (72.3%)]\tLoss: 0.220569\n",
      "Step: 11226 Train Epoch: 47 [46080/60000 (76.6%)]\tLoss: 0.218423\n",
      "Step: 11236 Train Epoch: 47 [48640/60000 (80.9%)]\tLoss: 0.149564\n",
      "Step: 11246 Train Epoch: 47 [51200/60000 (85.1%)]\tLoss: 0.247804\n",
      "Step: 11256 Train Epoch: 47 [53760/60000 (89.4%)]\tLoss: 0.134033\n",
      "Step: 11266 Train Epoch: 47 [56320/60000 (93.6%)]\tLoss: 0.188686\n",
      "Step: 11276 Train Epoch: 47 [58880/60000 (97.9%)]\tLoss: 0.118823\n",
      "\n",
      "Test set: Average loss: 0.2781, Accuracy: 9126/10000 (91.2600%)\n",
      "\n",
      "Start epoch 48/50...\n",
      "Step: 11281 Train Epoch: 48 [0/60000 (0.0%)]\tLoss: 0.093910\n",
      "Step: 11291 Train Epoch: 48 [2560/60000 (4.3%)]\tLoss: 0.118266\n",
      "Step: 11301 Train Epoch: 48 [5120/60000 (8.5%)]\tLoss: 0.116254\n",
      "Step: 11311 Train Epoch: 48 [7680/60000 (12.8%)]\tLoss: 0.107919\n",
      "Step: 11321 Train Epoch: 48 [10240/60000 (17.0%)]\tLoss: 0.104919\n",
      "Step: 11331 Train Epoch: 48 [12800/60000 (21.3%)]\tLoss: 0.098934\n",
      "Step: 11341 Train Epoch: 48 [15360/60000 (25.5%)]\tLoss: 0.090866\n",
      "Step: 11351 Train Epoch: 48 [17920/60000 (29.8%)]\tLoss: 0.100549\n",
      "Step: 11361 Train Epoch: 48 [20480/60000 (34.0%)]\tLoss: 0.140436\n",
      "Step: 11371 Train Epoch: 48 [23040/60000 (38.3%)]\tLoss: 0.125356\n",
      "Step: 11381 Train Epoch: 48 [25600/60000 (42.6%)]\tLoss: 0.255759\n",
      "Step: 11391 Train Epoch: 48 [28160/60000 (46.8%)]\tLoss: 0.119609\n",
      "Step: 11401 Train Epoch: 48 [30720/60000 (51.1%)]\tLoss: 0.154955\n",
      "Step: 11411 Train Epoch: 48 [33280/60000 (55.3%)]\tLoss: 0.203765\n",
      "Step: 11421 Train Epoch: 48 [35840/60000 (59.6%)]\tLoss: 0.229952\n",
      "Step: 11431 Train Epoch: 48 [38400/60000 (63.8%)]\tLoss: 0.196112\n",
      "Step: 11441 Train Epoch: 48 [40960/60000 (68.1%)]\tLoss: 0.163394\n",
      "Step: 11451 Train Epoch: 48 [43520/60000 (72.3%)]\tLoss: 0.201959\n",
      "Step: 11461 Train Epoch: 48 [46080/60000 (76.6%)]\tLoss: 0.146506\n",
      "Step: 11471 Train Epoch: 48 [48640/60000 (80.9%)]\tLoss: 0.162678\n",
      "Step: 11481 Train Epoch: 48 [51200/60000 (85.1%)]\tLoss: 0.132350\n",
      "Step: 11491 Train Epoch: 48 [53760/60000 (89.4%)]\tLoss: 0.141872\n",
      "Step: 11501 Train Epoch: 48 [56320/60000 (93.6%)]\tLoss: 0.157532\n",
      "Step: 11511 Train Epoch: 48 [58880/60000 (97.9%)]\tLoss: 0.125561\n",
      "\n",
      "Test set: Average loss: 0.2757, Accuracy: 9138/10000 (91.3800%)\n",
      "\n",
      "Start epoch 49/50...\n",
      "Step: 11516 Train Epoch: 49 [0/60000 (0.0%)]\tLoss: 0.099866\n",
      "Step: 11526 Train Epoch: 49 [2560/60000 (4.3%)]\tLoss: 0.099543\n",
      "Step: 11536 Train Epoch: 49 [5120/60000 (8.5%)]\tLoss: 0.124572\n",
      "Step: 11546 Train Epoch: 49 [7680/60000 (12.8%)]\tLoss: 0.166290\n",
      "Step: 11556 Train Epoch: 49 [10240/60000 (17.0%)]\tLoss: 0.127154\n",
      "Step: 11566 Train Epoch: 49 [12800/60000 (21.3%)]\tLoss: 0.097691\n",
      "Step: 11576 Train Epoch: 49 [15360/60000 (25.5%)]\tLoss: 0.134951\n",
      "Step: 11586 Train Epoch: 49 [17920/60000 (29.8%)]\tLoss: 0.138725\n",
      "Step: 11596 Train Epoch: 49 [20480/60000 (34.0%)]\tLoss: 0.180783\n",
      "Step: 11606 Train Epoch: 49 [23040/60000 (38.3%)]\tLoss: 0.169516\n",
      "Step: 11616 Train Epoch: 49 [25600/60000 (42.6%)]\tLoss: 0.161954\n",
      "Step: 11626 Train Epoch: 49 [28160/60000 (46.8%)]\tLoss: 0.138699\n",
      "Step: 11636 Train Epoch: 49 [30720/60000 (51.1%)]\tLoss: 0.146190\n",
      "Step: 11646 Train Epoch: 49 [33280/60000 (55.3%)]\tLoss: 0.186479\n",
      "Step: 11656 Train Epoch: 49 [35840/60000 (59.6%)]\tLoss: 0.152175\n",
      "Step: 11666 Train Epoch: 49 [38400/60000 (63.8%)]\tLoss: 0.178574\n",
      "Step: 11676 Train Epoch: 49 [40960/60000 (68.1%)]\tLoss: 0.139041\n",
      "Step: 11686 Train Epoch: 49 [43520/60000 (72.3%)]\tLoss: 0.185501\n",
      "Step: 11696 Train Epoch: 49 [46080/60000 (76.6%)]\tLoss: 0.131433\n",
      "Step: 11706 Train Epoch: 49 [48640/60000 (80.9%)]\tLoss: 0.156917\n",
      "Step: 11716 Train Epoch: 49 [51200/60000 (85.1%)]\tLoss: 0.112985\n",
      "Step: 11726 Train Epoch: 49 [53760/60000 (89.4%)]\tLoss: 0.152372\n",
      "Step: 11736 Train Epoch: 49 [56320/60000 (93.6%)]\tLoss: 0.127753\n",
      "Step: 11746 Train Epoch: 49 [58880/60000 (97.9%)]\tLoss: 0.126685\n",
      "\n",
      "Test set: Average loss: 0.2825, Accuracy: 9122/10000 (91.2200%)\n",
      "\n",
      "Best accuracy: 0.9169\n",
      "Best accuracy: 0.9169\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Module.load_state_dict() missing 1 required positional argument: 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laeti\\SHK_NODE\\filter_sparsity\\polar_ns\\train.py:470\u001b[0m, in \u001b[0;36mfit_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    467\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(best_prec1))    \n\u001b[1;32m--> 470\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Module.load_state_dict() missing 1 required positional argument: 'state_dict'"
     ]
    }
   ],
   "source": [
    "fit_model(config_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_prune = {\n",
    "    'model' : './checkpoints/model_best.pth.tar',\n",
    "    'batch_size': 256, \n",
    "    'test_batch_size' : 256,\n",
    "    'no_cuda': True, \n",
    "    'pruning_strategy' : 'grad', \n",
    "    'prune_mode' : 'default', \n",
    "    'save' : './checkpoints/',\n",
    "    'gate' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading the model...\n",
      "=> Epoch: 44, Acc.: 0.9169\n",
      "LeNet5 make_layers: feature cfg [6, 'A', 16, 'A']\n",
      "[1.]\n",
      "[ True False  True  True  True  True]\n",
      "Pruning finished. cfg:\n",
      "[5, 'A', 13, 'A']\n",
      "Sanity check: checking if pruned model is as same as sparse model\n",
      "Max diff between Sparse model and Pruned model: 9.5367431640625e-07\n",
      "\n",
      "LeNet5 make_layers: feature cfg [5, 'A', 13, 'A']\n",
      "Sanity check: checking if pruned model is as same as saved model\n",
      "Max diff between Saved model and Pruned model: 0.0\n",
      "\n",
      "LeNet5 make_layers: feature cfg [6, 'A', 16, 'A']\n",
      "Unpruned FLOPs: 416,520.0\n",
      "Saved FLOPs: 310,420.0\n",
      "FLOPs ratio: 0.7452703351579756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laeti\\SHK_NODE\\filter_sparsity\\polar_ns\\prune.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint: Dict[str, Any] = torch.load(config.get('model'))\n"
     ]
    }
   ],
   "source": [
    "main(config_prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_finetune = {\n",
    "    #'config' : [6, 'A', 16, 'A'],\n",
    "    'cuda' : False, \n",
    "    'no_cuda' : True, \n",
    "    'loss' : 'zol', \n",
    "    'lbd' : 0.0001, \n",
    "    's' : 0.0001, \n",
    "    'alpha' : 1, \n",
    "    't' : 50,\n",
    "    'epochs' : 50, \n",
    "    'batch_size' : 256, \n",
    "    'test_batch_size' : 256,\n",
    "    'max_epoch' : None, \n",
    "    'lr' : 0.15, \n",
    "    'momentum' : 0.9, \n",
    "    'weight_decay': 0.0, \n",
    "    'seed' : 1234, \n",
    "    'log_interval' : 10,\n",
    "    'gate' : False, \n",
    "    'flops_weighted' : False,\n",
    "    'bn_wd' : True, \n",
    "    'resume' : None,\n",
    "    'arch' : 'leNet', \n",
    "    'refine' : './checkpoints/pruned_grad.pth.tar',\n",
    "    'save' : './checkpoints/', \n",
    "    'backup' : './backup/', \n",
    "    'log' : './events/',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5 make_layers: feature cfg [5, 'A', 13, 'A']\n",
      "Testing the loaded model...\n",
      "\n",
      "Test set: Average loss: 0.2639, Accuracy: 9169/10000 (91.7%)\n",
      "\n",
      "LeNet5 make_layers: feature cfg [6, 'A', 16, 'A']\n",
      "FLOPs remains 0.7452703351579756\n",
      "Weight decay param: parameter name feature.0.conv.weight\n",
      "Weight decay param: parameter name feature.0.batch_norm.weight\n",
      "Weight decay param: parameter name feature.0.batch_norm.bias\n",
      "Weight decay param: parameter name feature.2.conv.weight\n",
      "Weight decay param: parameter name feature.2.batch_norm.weight\n",
      "Weight decay param: parameter name feature.2.batch_norm.bias\n",
      "Weight decay param: parameter name classifier.0.weight\n",
      "Weight decay param: parameter name classifier.0.bias\n",
      "Weight decay param: parameter name classifier.2.weight\n",
      "Weight decay param: parameter name classifier.2.bias\n",
      "Weight decay param: parameter name classifier.4.weight\n",
      "Weight decay param: parameter name classifier.4.bias\n",
      "Train Epoch: 0 [0/60000 (0.0%)]\tLoss: 0.074430\n",
      "Train Epoch: 0 [2560/60000 (4.3%)]\tLoss: 0.088945\n",
      "Train Epoch: 0 [5120/60000 (8.5%)]\tLoss: 0.115343\n",
      "Train Epoch: 0 [7680/60000 (12.8%)]\tLoss: 0.126117\n",
      "Train Epoch: 0 [10240/60000 (17.0%)]\tLoss: 0.099347\n",
      "Train Epoch: 0 [12800/60000 (21.3%)]\tLoss: 0.095601\n",
      "Train Epoch: 0 [15360/60000 (25.5%)]\tLoss: 0.085737\n",
      "Train Epoch: 0 [17920/60000 (29.8%)]\tLoss: 0.124281\n",
      "Train Epoch: 0 [20480/60000 (34.0%)]\tLoss: 0.081870\n",
      "Train Epoch: 0 [23040/60000 (38.3%)]\tLoss: 0.108707\n",
      "Train Epoch: 0 [25600/60000 (42.6%)]\tLoss: 0.173713\n",
      "Train Epoch: 0 [28160/60000 (46.8%)]\tLoss: 0.062329\n",
      "Train Epoch: 0 [30720/60000 (51.1%)]\tLoss: 0.071486\n",
      "Train Epoch: 0 [33280/60000 (55.3%)]\tLoss: 0.094872\n",
      "Train Epoch: 0 [35840/60000 (59.6%)]\tLoss: 0.069313\n",
      "Train Epoch: 0 [38400/60000 (63.8%)]\tLoss: 0.085454\n",
      "Train Epoch: 0 [40960/60000 (68.1%)]\tLoss: 0.144821\n",
      "Train Epoch: 0 [43520/60000 (72.3%)]\tLoss: 0.135748\n",
      "Train Epoch: 0 [46080/60000 (76.6%)]\tLoss: 0.241695\n",
      "Train Epoch: 0 [48640/60000 (80.9%)]\tLoss: 0.180355\n",
      "Train Epoch: 0 [51200/60000 (85.1%)]\tLoss: 0.126710\n",
      "Train Epoch: 0 [53760/60000 (89.4%)]\tLoss: 0.104928\n",
      "Train Epoch: 0 [56320/60000 (93.6%)]\tLoss: 0.213699\n",
      "Train Epoch: 0 [58880/60000 (97.9%)]\tLoss: 0.157513\n",
      "\n",
      "Test set: Average loss: 0.3213, Accuracy: 8997/10000 (90.0%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0.0%)]\tLoss: 0.103529\n",
      "Train Epoch: 1 [2560/60000 (4.3%)]\tLoss: 0.140850\n",
      "Train Epoch: 1 [5120/60000 (8.5%)]\tLoss: 0.094339\n",
      "Train Epoch: 1 [7680/60000 (12.8%)]\tLoss: 0.097297\n",
      "Train Epoch: 1 [10240/60000 (17.0%)]\tLoss: 0.080104\n",
      "Train Epoch: 1 [12800/60000 (21.3%)]\tLoss: 0.113793\n",
      "Train Epoch: 1 [15360/60000 (25.5%)]\tLoss: 0.089427\n",
      "Train Epoch: 1 [17920/60000 (29.8%)]\tLoss: 0.075628\n",
      "Train Epoch: 1 [20480/60000 (34.0%)]\tLoss: 0.109233\n",
      "Train Epoch: 1 [23040/60000 (38.3%)]\tLoss: 0.090999\n",
      "Train Epoch: 1 [25600/60000 (42.6%)]\tLoss: 0.103944\n",
      "Train Epoch: 1 [28160/60000 (46.8%)]\tLoss: 0.108164\n",
      "Train Epoch: 1 [30720/60000 (51.1%)]\tLoss: 0.092927\n",
      "Train Epoch: 1 [33280/60000 (55.3%)]\tLoss: 0.080377\n",
      "Train Epoch: 1 [35840/60000 (59.6%)]\tLoss: 0.138626\n",
      "Train Epoch: 1 [38400/60000 (63.8%)]\tLoss: 0.139484\n",
      "Train Epoch: 1 [40960/60000 (68.1%)]\tLoss: 0.130727\n",
      "Train Epoch: 1 [43520/60000 (72.3%)]\tLoss: 0.209040\n",
      "Train Epoch: 1 [46080/60000 (76.6%)]\tLoss: 0.171609\n",
      "Train Epoch: 1 [48640/60000 (80.9%)]\tLoss: 0.150868\n",
      "Train Epoch: 1 [51200/60000 (85.1%)]\tLoss: 0.126512\n",
      "Train Epoch: 1 [53760/60000 (89.4%)]\tLoss: 0.148646\n",
      "Train Epoch: 1 [56320/60000 (93.6%)]\tLoss: 0.143210\n",
      "Train Epoch: 1 [58880/60000 (97.9%)]\tLoss: 0.114942\n",
      "\n",
      "Test set: Average loss: 0.2891, Accuracy: 9088/10000 (90.9%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0.0%)]\tLoss: 0.104843\n",
      "Train Epoch: 2 [2560/60000 (4.3%)]\tLoss: 0.118987\n",
      "Train Epoch: 2 [5120/60000 (8.5%)]\tLoss: 0.121270\n",
      "Train Epoch: 2 [7680/60000 (12.8%)]\tLoss: 0.103895\n",
      "Train Epoch: 2 [10240/60000 (17.0%)]\tLoss: 0.101049\n",
      "Train Epoch: 2 [12800/60000 (21.3%)]\tLoss: 0.073682\n",
      "Train Epoch: 2 [15360/60000 (25.5%)]\tLoss: 0.101462\n",
      "Train Epoch: 2 [17920/60000 (29.8%)]\tLoss: 0.081436\n",
      "Train Epoch: 2 [20480/60000 (34.0%)]\tLoss: 0.101216\n",
      "Train Epoch: 2 [23040/60000 (38.3%)]\tLoss: 0.092424\n",
      "Train Epoch: 2 [25600/60000 (42.6%)]\tLoss: 0.121339\n",
      "Train Epoch: 2 [28160/60000 (46.8%)]\tLoss: 0.154937\n",
      "Train Epoch: 2 [30720/60000 (51.1%)]\tLoss: 0.200854\n",
      "Train Epoch: 2 [33280/60000 (55.3%)]\tLoss: 0.148143\n",
      "Train Epoch: 2 [35840/60000 (59.6%)]\tLoss: 0.133133\n",
      "Train Epoch: 2 [38400/60000 (63.8%)]\tLoss: 0.174546\n",
      "Train Epoch: 2 [40960/60000 (68.1%)]\tLoss: 0.101165\n",
      "Train Epoch: 2 [43520/60000 (72.3%)]\tLoss: 0.118802\n",
      "Train Epoch: 2 [46080/60000 (76.6%)]\tLoss: 0.112481\n",
      "Train Epoch: 2 [48640/60000 (80.9%)]\tLoss: 0.160542\n",
      "Train Epoch: 2 [51200/60000 (85.1%)]\tLoss: 0.135872\n",
      "Train Epoch: 2 [53760/60000 (89.4%)]\tLoss: 0.078699\n",
      "Train Epoch: 2 [56320/60000 (93.6%)]\tLoss: 0.065304\n",
      "Train Epoch: 2 [58880/60000 (97.9%)]\tLoss: 0.068914\n",
      "\n",
      "Test set: Average loss: 0.2920, Accuracy: 9133/10000 (91.3%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0.0%)]\tLoss: 0.113901\n",
      "Train Epoch: 3 [2560/60000 (4.3%)]\tLoss: 0.080526\n",
      "Train Epoch: 3 [5120/60000 (8.5%)]\tLoss: 0.101902\n",
      "Train Epoch: 3 [7680/60000 (12.8%)]\tLoss: 0.114542\n",
      "Train Epoch: 3 [10240/60000 (17.0%)]\tLoss: 0.083143\n",
      "Train Epoch: 3 [12800/60000 (21.3%)]\tLoss: 0.100067\n",
      "Train Epoch: 3 [15360/60000 (25.5%)]\tLoss: 0.122537\n",
      "Train Epoch: 3 [17920/60000 (29.8%)]\tLoss: 0.110329\n",
      "Train Epoch: 3 [20480/60000 (34.0%)]\tLoss: 0.173968\n",
      "Train Epoch: 3 [23040/60000 (38.3%)]\tLoss: 0.193907\n",
      "Train Epoch: 3 [25600/60000 (42.6%)]\tLoss: 0.164418\n",
      "Train Epoch: 3 [28160/60000 (46.8%)]\tLoss: 0.157418\n",
      "Train Epoch: 3 [30720/60000 (51.1%)]\tLoss: 0.106183\n",
      "Train Epoch: 3 [33280/60000 (55.3%)]\tLoss: 0.076284\n",
      "Train Epoch: 3 [35840/60000 (59.6%)]\tLoss: 0.114212\n",
      "Train Epoch: 3 [38400/60000 (63.8%)]\tLoss: 0.148935\n",
      "Train Epoch: 3 [40960/60000 (68.1%)]\tLoss: 0.099933\n",
      "Train Epoch: 3 [43520/60000 (72.3%)]\tLoss: 0.148722\n",
      "Train Epoch: 3 [46080/60000 (76.6%)]\tLoss: 0.123076\n",
      "Train Epoch: 3 [48640/60000 (80.9%)]\tLoss: 0.098639\n",
      "Train Epoch: 3 [51200/60000 (85.1%)]\tLoss: 0.066195\n",
      "Train Epoch: 3 [53760/60000 (89.4%)]\tLoss: 0.111154\n",
      "Train Epoch: 3 [56320/60000 (93.6%)]\tLoss: 0.116073\n",
      "Train Epoch: 3 [58880/60000 (97.9%)]\tLoss: 0.130574\n",
      "\n",
      "Test set: Average loss: 0.2969, Accuracy: 9112/10000 (91.1%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0.0%)]\tLoss: 0.086233\n",
      "Train Epoch: 4 [2560/60000 (4.3%)]\tLoss: 0.086841\n",
      "Train Epoch: 4 [5120/60000 (8.5%)]\tLoss: 0.177212\n",
      "Train Epoch: 4 [7680/60000 (12.8%)]\tLoss: 0.070028\n",
      "Train Epoch: 4 [10240/60000 (17.0%)]\tLoss: 0.131308\n",
      "Train Epoch: 4 [12800/60000 (21.3%)]\tLoss: 0.111597\n",
      "Train Epoch: 4 [15360/60000 (25.5%)]\tLoss: 0.132247\n",
      "Train Epoch: 4 [17920/60000 (29.8%)]\tLoss: 0.147450\n",
      "Train Epoch: 4 [20480/60000 (34.0%)]\tLoss: 0.210617\n",
      "Train Epoch: 4 [23040/60000 (38.3%)]\tLoss: 0.100224\n",
      "Train Epoch: 4 [25600/60000 (42.6%)]\tLoss: 0.121901\n",
      "Train Epoch: 4 [28160/60000 (46.8%)]\tLoss: 0.143200\n",
      "Train Epoch: 4 [30720/60000 (51.1%)]\tLoss: 0.087874\n",
      "Train Epoch: 4 [33280/60000 (55.3%)]\tLoss: 0.125476\n",
      "Train Epoch: 4 [35840/60000 (59.6%)]\tLoss: 0.120246\n",
      "Train Epoch: 4 [38400/60000 (63.8%)]\tLoss: 0.075511\n",
      "Train Epoch: 4 [40960/60000 (68.1%)]\tLoss: 0.113809\n",
      "Train Epoch: 4 [43520/60000 (72.3%)]\tLoss: 0.077678\n",
      "Train Epoch: 4 [46080/60000 (76.6%)]\tLoss: 0.063996\n",
      "Train Epoch: 4 [48640/60000 (80.9%)]\tLoss: 0.083082\n",
      "Train Epoch: 4 [51200/60000 (85.1%)]\tLoss: 0.083110\n",
      "Train Epoch: 4 [53760/60000 (89.4%)]\tLoss: 0.103166\n",
      "Train Epoch: 4 [56320/60000 (93.6%)]\tLoss: 0.163778\n",
      "Train Epoch: 4 [58880/60000 (97.9%)]\tLoss: 0.114222\n",
      "\n",
      "Test set: Average loss: 0.3291, Accuracy: 9006/10000 (90.1%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0.0%)]\tLoss: 0.110424\n",
      "Train Epoch: 5 [2560/60000 (4.3%)]\tLoss: 0.182899\n",
      "Train Epoch: 5 [5120/60000 (8.5%)]\tLoss: 0.130133\n",
      "Train Epoch: 5 [7680/60000 (12.8%)]\tLoss: 0.135394\n",
      "Train Epoch: 5 [10240/60000 (17.0%)]\tLoss: 0.058399\n",
      "Train Epoch: 5 [12800/60000 (21.3%)]\tLoss: 0.169970\n",
      "Train Epoch: 5 [15360/60000 (25.5%)]\tLoss: 0.098010\n",
      "Train Epoch: 5 [17920/60000 (29.8%)]\tLoss: 0.083839\n",
      "Train Epoch: 5 [20480/60000 (34.0%)]\tLoss: 0.112077\n",
      "Train Epoch: 5 [23040/60000 (38.3%)]\tLoss: 0.057952\n",
      "Train Epoch: 5 [25600/60000 (42.6%)]\tLoss: 0.066607\n",
      "Train Epoch: 5 [28160/60000 (46.8%)]\tLoss: 0.153315\n",
      "Train Epoch: 5 [30720/60000 (51.1%)]\tLoss: 0.091049\n",
      "Train Epoch: 5 [33280/60000 (55.3%)]\tLoss: 0.088093\n",
      "Train Epoch: 5 [35840/60000 (59.6%)]\tLoss: 0.081954\n",
      "Train Epoch: 5 [38400/60000 (63.8%)]\tLoss: 0.096856\n",
      "Train Epoch: 5 [40960/60000 (68.1%)]\tLoss: 0.102048\n",
      "Train Epoch: 5 [43520/60000 (72.3%)]\tLoss: 0.106819\n",
      "Train Epoch: 5 [46080/60000 (76.6%)]\tLoss: 0.076738\n",
      "Train Epoch: 5 [48640/60000 (80.9%)]\tLoss: 0.093256\n",
      "Train Epoch: 5 [51200/60000 (85.1%)]\tLoss: 0.120860\n",
      "Train Epoch: 5 [53760/60000 (89.4%)]\tLoss: 0.074847\n",
      "Train Epoch: 5 [56320/60000 (93.6%)]\tLoss: 0.097328\n",
      "Train Epoch: 5 [58880/60000 (97.9%)]\tLoss: 0.225336\n",
      "\n",
      "Test set: Average loss: 0.3527, Accuracy: 8939/10000 (89.4%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0.0%)]\tLoss: 0.129125\n",
      "Train Epoch: 6 [2560/60000 (4.3%)]\tLoss: 0.178228\n",
      "Train Epoch: 6 [5120/60000 (8.5%)]\tLoss: 0.121913\n",
      "Train Epoch: 6 [7680/60000 (12.8%)]\tLoss: 0.113026\n",
      "Train Epoch: 6 [10240/60000 (17.0%)]\tLoss: 0.168976\n",
      "Train Epoch: 6 [12800/60000 (21.3%)]\tLoss: 0.121532\n",
      "Train Epoch: 6 [15360/60000 (25.5%)]\tLoss: 0.120815\n",
      "Train Epoch: 6 [17920/60000 (29.8%)]\tLoss: 0.178058\n",
      "Train Epoch: 6 [20480/60000 (34.0%)]\tLoss: 0.077519\n",
      "Train Epoch: 6 [23040/60000 (38.3%)]\tLoss: 0.057765\n",
      "Train Epoch: 6 [25600/60000 (42.6%)]\tLoss: 0.094861\n",
      "Train Epoch: 6 [28160/60000 (46.8%)]\tLoss: 0.100312\n",
      "Train Epoch: 6 [30720/60000 (51.1%)]\tLoss: 0.136194\n",
      "Train Epoch: 6 [33280/60000 (55.3%)]\tLoss: 0.098962\n",
      "Train Epoch: 6 [35840/60000 (59.6%)]\tLoss: 0.090935\n",
      "Train Epoch: 6 [38400/60000 (63.8%)]\tLoss: 0.093444\n",
      "Train Epoch: 6 [40960/60000 (68.1%)]\tLoss: 0.125682\n",
      "Train Epoch: 6 [43520/60000 (72.3%)]\tLoss: 0.117449\n",
      "Train Epoch: 6 [46080/60000 (76.6%)]\tLoss: 0.147389\n",
      "Train Epoch: 6 [48640/60000 (80.9%)]\tLoss: 0.138978\n",
      "Train Epoch: 6 [51200/60000 (85.1%)]\tLoss: 0.139106\n",
      "Train Epoch: 6 [53760/60000 (89.4%)]\tLoss: 0.088464\n",
      "Train Epoch: 6 [56320/60000 (93.6%)]\tLoss: 0.230634\n",
      "Train Epoch: 6 [58880/60000 (97.9%)]\tLoss: 0.145716\n",
      "\n",
      "Test set: Average loss: 0.3141, Accuracy: 9052/10000 (90.5%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0.0%)]\tLoss: 0.127050\n",
      "Train Epoch: 7 [2560/60000 (4.3%)]\tLoss: 0.142369\n",
      "Train Epoch: 7 [5120/60000 (8.5%)]\tLoss: 0.108528\n",
      "Train Epoch: 7 [7680/60000 (12.8%)]\tLoss: 0.125807\n",
      "Train Epoch: 7 [10240/60000 (17.0%)]\tLoss: 0.073445\n",
      "Train Epoch: 7 [12800/60000 (21.3%)]\tLoss: 0.146605\n",
      "Train Epoch: 7 [15360/60000 (25.5%)]\tLoss: 0.108946\n",
      "Train Epoch: 7 [17920/60000 (29.8%)]\tLoss: 0.085759\n",
      "Train Epoch: 7 [20480/60000 (34.0%)]\tLoss: 0.117832\n",
      "Train Epoch: 7 [23040/60000 (38.3%)]\tLoss: 0.078375\n",
      "Train Epoch: 7 [25600/60000 (42.6%)]\tLoss: 0.086130\n",
      "Train Epoch: 7 [28160/60000 (46.8%)]\tLoss: 0.062233\n",
      "Train Epoch: 7 [30720/60000 (51.1%)]\tLoss: 0.096142\n",
      "Train Epoch: 7 [33280/60000 (55.3%)]\tLoss: 0.200092\n",
      "Train Epoch: 7 [35840/60000 (59.6%)]\tLoss: 0.081098\n",
      "Train Epoch: 7 [38400/60000 (63.8%)]\tLoss: 0.126626\n",
      "Train Epoch: 7 [40960/60000 (68.1%)]\tLoss: 0.106863\n",
      "Train Epoch: 7 [43520/60000 (72.3%)]\tLoss: 0.150016\n",
      "Train Epoch: 7 [46080/60000 (76.6%)]\tLoss: 0.184823\n",
      "Train Epoch: 7 [48640/60000 (80.9%)]\tLoss: 0.113402\n",
      "Train Epoch: 7 [51200/60000 (85.1%)]\tLoss: 0.114278\n",
      "Train Epoch: 7 [53760/60000 (89.4%)]\tLoss: 0.137038\n",
      "Train Epoch: 7 [56320/60000 (93.6%)]\tLoss: 0.076709\n",
      "Train Epoch: 7 [58880/60000 (97.9%)]\tLoss: 0.079115\n",
      "\n",
      "Test set: Average loss: 0.3086, Accuracy: 9108/10000 (91.1%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0.0%)]\tLoss: 0.103637\n",
      "Train Epoch: 8 [2560/60000 (4.3%)]\tLoss: 0.068229\n",
      "Train Epoch: 8 [5120/60000 (8.5%)]\tLoss: 0.046934\n",
      "Train Epoch: 8 [7680/60000 (12.8%)]\tLoss: 0.077902\n",
      "Train Epoch: 8 [10240/60000 (17.0%)]\tLoss: 0.097901\n",
      "Train Epoch: 8 [12800/60000 (21.3%)]\tLoss: 0.052813\n",
      "Train Epoch: 8 [15360/60000 (25.5%)]\tLoss: 0.104106\n",
      "Train Epoch: 8 [17920/60000 (29.8%)]\tLoss: 0.065041\n",
      "Train Epoch: 8 [20480/60000 (34.0%)]\tLoss: 0.086738\n",
      "Train Epoch: 8 [23040/60000 (38.3%)]\tLoss: 0.080145\n",
      "Train Epoch: 8 [25600/60000 (42.6%)]\tLoss: 0.111238\n",
      "Train Epoch: 8 [28160/60000 (46.8%)]\tLoss: 0.115271\n",
      "Train Epoch: 8 [30720/60000 (51.1%)]\tLoss: 0.084734\n",
      "Train Epoch: 8 [33280/60000 (55.3%)]\tLoss: 0.135964\n",
      "Train Epoch: 8 [35840/60000 (59.6%)]\tLoss: 0.139233\n",
      "Train Epoch: 8 [38400/60000 (63.8%)]\tLoss: 0.127032\n",
      "Train Epoch: 8 [40960/60000 (68.1%)]\tLoss: 0.114079\n",
      "Train Epoch: 8 [43520/60000 (72.3%)]\tLoss: 0.136984\n",
      "Train Epoch: 8 [46080/60000 (76.6%)]\tLoss: 0.080326\n",
      "Train Epoch: 8 [48640/60000 (80.9%)]\tLoss: 0.122905\n",
      "Train Epoch: 8 [51200/60000 (85.1%)]\tLoss: 0.119115\n",
      "Train Epoch: 8 [53760/60000 (89.4%)]\tLoss: 0.131119\n",
      "Train Epoch: 8 [56320/60000 (93.6%)]\tLoss: 0.081323\n",
      "Train Epoch: 8 [58880/60000 (97.9%)]\tLoss: 0.098519\n",
      "\n",
      "Test set: Average loss: 0.3082, Accuracy: 9103/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0.0%)]\tLoss: 0.100676\n",
      "Train Epoch: 9 [2560/60000 (4.3%)]\tLoss: 0.095827\n",
      "Train Epoch: 9 [5120/60000 (8.5%)]\tLoss: 0.119869\n",
      "Train Epoch: 9 [7680/60000 (12.8%)]\tLoss: 0.077512\n",
      "Train Epoch: 9 [10240/60000 (17.0%)]\tLoss: 0.098955\n",
      "Train Epoch: 9 [12800/60000 (21.3%)]\tLoss: 0.100884\n",
      "Train Epoch: 9 [15360/60000 (25.5%)]\tLoss: 0.099717\n",
      "Train Epoch: 9 [17920/60000 (29.8%)]\tLoss: 0.094426\n",
      "Train Epoch: 9 [20480/60000 (34.0%)]\tLoss: 0.173584\n",
      "Train Epoch: 9 [23040/60000 (38.3%)]\tLoss: 0.118140\n",
      "Train Epoch: 9 [25600/60000 (42.6%)]\tLoss: 0.127645\n",
      "Train Epoch: 9 [28160/60000 (46.8%)]\tLoss: 0.082991\n",
      "Train Epoch: 9 [30720/60000 (51.1%)]\tLoss: 0.146830\n",
      "Train Epoch: 9 [33280/60000 (55.3%)]\tLoss: 0.089404\n",
      "Train Epoch: 9 [35840/60000 (59.6%)]\tLoss: 0.126367\n",
      "Train Epoch: 9 [38400/60000 (63.8%)]\tLoss: 0.087013\n",
      "Train Epoch: 9 [40960/60000 (68.1%)]\tLoss: 0.100778\n",
      "Train Epoch: 9 [43520/60000 (72.3%)]\tLoss: 0.092588\n",
      "Train Epoch: 9 [46080/60000 (76.6%)]\tLoss: 0.064152\n",
      "Train Epoch: 9 [48640/60000 (80.9%)]\tLoss: 0.127945\n",
      "Train Epoch: 9 [51200/60000 (85.1%)]\tLoss: 0.079091\n",
      "Train Epoch: 9 [53760/60000 (89.4%)]\tLoss: 0.100236\n",
      "Train Epoch: 9 [56320/60000 (93.6%)]\tLoss: 0.111252\n",
      "Train Epoch: 9 [58880/60000 (97.9%)]\tLoss: 0.084304\n",
      "\n",
      "Test set: Average loss: 0.3207, Accuracy: 9098/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0.0%)]\tLoss: 0.064785\n",
      "Train Epoch: 10 [2560/60000 (4.3%)]\tLoss: 0.121227\n",
      "Train Epoch: 10 [5120/60000 (8.5%)]\tLoss: 0.066447\n",
      "Train Epoch: 10 [7680/60000 (12.8%)]\tLoss: 0.192129\n",
      "Train Epoch: 10 [10240/60000 (17.0%)]\tLoss: 0.059226\n",
      "Train Epoch: 10 [12800/60000 (21.3%)]\tLoss: 0.086175\n",
      "Train Epoch: 10 [15360/60000 (25.5%)]\tLoss: 0.105829\n",
      "Train Epoch: 10 [17920/60000 (29.8%)]\tLoss: 0.173519\n",
      "Train Epoch: 10 [20480/60000 (34.0%)]\tLoss: 0.136712\n",
      "Train Epoch: 10 [23040/60000 (38.3%)]\tLoss: 0.102816\n",
      "Train Epoch: 10 [25600/60000 (42.6%)]\tLoss: 0.193750\n",
      "Train Epoch: 10 [28160/60000 (46.8%)]\tLoss: 0.066085\n",
      "Train Epoch: 10 [30720/60000 (51.1%)]\tLoss: 0.078102\n",
      "Train Epoch: 10 [33280/60000 (55.3%)]\tLoss: 0.071567\n",
      "Train Epoch: 10 [35840/60000 (59.6%)]\tLoss: 0.093196\n",
      "Train Epoch: 10 [38400/60000 (63.8%)]\tLoss: 0.200500\n",
      "Train Epoch: 10 [40960/60000 (68.1%)]\tLoss: 0.079081\n",
      "Train Epoch: 10 [43520/60000 (72.3%)]\tLoss: 0.169412\n",
      "Train Epoch: 10 [46080/60000 (76.6%)]\tLoss: 0.083742\n",
      "Train Epoch: 10 [48640/60000 (80.9%)]\tLoss: 0.070277\n",
      "Train Epoch: 10 [51200/60000 (85.1%)]\tLoss: 0.104344\n",
      "Train Epoch: 10 [53760/60000 (89.4%)]\tLoss: 0.136686\n",
      "Train Epoch: 10 [56320/60000 (93.6%)]\tLoss: 0.080290\n",
      "Train Epoch: 10 [58880/60000 (97.9%)]\tLoss: 0.107978\n",
      "\n",
      "Test set: Average loss: 0.3358, Accuracy: 9033/10000 (90.3%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0.0%)]\tLoss: 0.096283\n",
      "Train Epoch: 11 [2560/60000 (4.3%)]\tLoss: 0.105595\n",
      "Train Epoch: 11 [5120/60000 (8.5%)]\tLoss: 0.146541\n",
      "Train Epoch: 11 [7680/60000 (12.8%)]\tLoss: 0.082716\n",
      "Train Epoch: 11 [10240/60000 (17.0%)]\tLoss: 0.254048\n",
      "Train Epoch: 11 [12800/60000 (21.3%)]\tLoss: 0.146626\n",
      "Train Epoch: 11 [15360/60000 (25.5%)]\tLoss: 0.118515\n",
      "Train Epoch: 11 [17920/60000 (29.8%)]\tLoss: 0.157643\n",
      "Train Epoch: 11 [20480/60000 (34.0%)]\tLoss: 0.077382\n",
      "Train Epoch: 11 [23040/60000 (38.3%)]\tLoss: 0.130962\n",
      "Train Epoch: 11 [25600/60000 (42.6%)]\tLoss: 0.099694\n",
      "Train Epoch: 11 [28160/60000 (46.8%)]\tLoss: 0.069445\n",
      "Train Epoch: 11 [30720/60000 (51.1%)]\tLoss: 0.091384\n",
      "Train Epoch: 11 [33280/60000 (55.3%)]\tLoss: 0.089612\n",
      "Train Epoch: 11 [35840/60000 (59.6%)]\tLoss: 0.080898\n",
      "Train Epoch: 11 [38400/60000 (63.8%)]\tLoss: 0.104657\n",
      "Train Epoch: 11 [40960/60000 (68.1%)]\tLoss: 0.067473\n",
      "Train Epoch: 11 [43520/60000 (72.3%)]\tLoss: 0.112028\n",
      "Train Epoch: 11 [46080/60000 (76.6%)]\tLoss: 0.104051\n",
      "Train Epoch: 11 [48640/60000 (80.9%)]\tLoss: 0.160651\n",
      "Train Epoch: 11 [51200/60000 (85.1%)]\tLoss: 0.086478\n",
      "Train Epoch: 11 [53760/60000 (89.4%)]\tLoss: 0.101874\n",
      "Train Epoch: 11 [56320/60000 (93.6%)]\tLoss: 0.133407\n",
      "Train Epoch: 11 [58880/60000 (97.9%)]\tLoss: 0.116725\n",
      "\n",
      "Test set: Average loss: 0.3886, Accuracy: 8973/10000 (89.7%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0.0%)]\tLoss: 0.139834\n",
      "Train Epoch: 12 [2560/60000 (4.3%)]\tLoss: 0.075463\n",
      "Train Epoch: 12 [5120/60000 (8.5%)]\tLoss: 0.098567\n",
      "Train Epoch: 12 [7680/60000 (12.8%)]\tLoss: 0.078038\n",
      "Train Epoch: 12 [10240/60000 (17.0%)]\tLoss: 0.114785\n",
      "Train Epoch: 12 [12800/60000 (21.3%)]\tLoss: 0.064227\n",
      "Train Epoch: 12 [15360/60000 (25.5%)]\tLoss: 0.080893\n",
      "Train Epoch: 12 [17920/60000 (29.8%)]\tLoss: 0.081273\n",
      "Train Epoch: 12 [20480/60000 (34.0%)]\tLoss: 0.087355\n",
      "Train Epoch: 12 [23040/60000 (38.3%)]\tLoss: 0.071853\n",
      "Train Epoch: 12 [25600/60000 (42.6%)]\tLoss: 0.061131\n",
      "Train Epoch: 12 [28160/60000 (46.8%)]\tLoss: 0.061899\n",
      "Train Epoch: 12 [30720/60000 (51.1%)]\tLoss: 0.075279\n",
      "Train Epoch: 12 [33280/60000 (55.3%)]\tLoss: 0.057369\n",
      "Train Epoch: 12 [35840/60000 (59.6%)]\tLoss: 0.080584\n",
      "Train Epoch: 12 [38400/60000 (63.8%)]\tLoss: 0.076440\n",
      "Train Epoch: 12 [40960/60000 (68.1%)]\tLoss: 0.073119\n",
      "Train Epoch: 12 [43520/60000 (72.3%)]\tLoss: 0.143794\n",
      "Train Epoch: 12 [46080/60000 (76.6%)]\tLoss: 0.127960\n",
      "Train Epoch: 12 [48640/60000 (80.9%)]\tLoss: 0.130428\n",
      "Train Epoch: 12 [51200/60000 (85.1%)]\tLoss: 0.116446\n",
      "Train Epoch: 12 [53760/60000 (89.4%)]\tLoss: 0.140237\n",
      "Train Epoch: 12 [56320/60000 (93.6%)]\tLoss: 0.138939\n",
      "Train Epoch: 12 [58880/60000 (97.9%)]\tLoss: 0.165777\n",
      "\n",
      "Test set: Average loss: 0.3407, Accuracy: 9076/10000 (90.8%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0.0%)]\tLoss: 0.132194\n",
      "Train Epoch: 13 [2560/60000 (4.3%)]\tLoss: 0.079760\n",
      "Train Epoch: 13 [5120/60000 (8.5%)]\tLoss: 0.063243\n",
      "Train Epoch: 13 [7680/60000 (12.8%)]\tLoss: 0.086189\n",
      "Train Epoch: 13 [10240/60000 (17.0%)]\tLoss: 0.073391\n",
      "Train Epoch: 13 [12800/60000 (21.3%)]\tLoss: 0.085776\n",
      "Train Epoch: 13 [15360/60000 (25.5%)]\tLoss: 0.078626\n",
      "Train Epoch: 13 [17920/60000 (29.8%)]\tLoss: 0.049241\n",
      "Train Epoch: 13 [20480/60000 (34.0%)]\tLoss: 0.073500\n",
      "Train Epoch: 13 [23040/60000 (38.3%)]\tLoss: 0.118292\n",
      "Train Epoch: 13 [25600/60000 (42.6%)]\tLoss: 0.085434\n",
      "Train Epoch: 13 [28160/60000 (46.8%)]\tLoss: 0.076451\n",
      "Train Epoch: 13 [30720/60000 (51.1%)]\tLoss: 0.124286\n",
      "Train Epoch: 13 [33280/60000 (55.3%)]\tLoss: 0.063606\n",
      "Train Epoch: 13 [35840/60000 (59.6%)]\tLoss: 0.099081\n",
      "Train Epoch: 13 [38400/60000 (63.8%)]\tLoss: 0.109289\n",
      "Train Epoch: 13 [40960/60000 (68.1%)]\tLoss: 0.072199\n",
      "Train Epoch: 13 [43520/60000 (72.3%)]\tLoss: 0.091391\n",
      "Train Epoch: 13 [46080/60000 (76.6%)]\tLoss: 0.128379\n",
      "Train Epoch: 13 [48640/60000 (80.9%)]\tLoss: 0.133078\n",
      "Train Epoch: 13 [51200/60000 (85.1%)]\tLoss: 0.124981\n",
      "Train Epoch: 13 [53760/60000 (89.4%)]\tLoss: 0.092182\n",
      "Train Epoch: 13 [56320/60000 (93.6%)]\tLoss: 0.086745\n",
      "Train Epoch: 13 [58880/60000 (97.9%)]\tLoss: 0.071503\n",
      "\n",
      "Test set: Average loss: 0.3243, Accuracy: 9126/10000 (91.3%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0.0%)]\tLoss: 0.061436\n",
      "Train Epoch: 14 [2560/60000 (4.3%)]\tLoss: 0.050183\n",
      "Train Epoch: 14 [5120/60000 (8.5%)]\tLoss: 0.040989\n",
      "Train Epoch: 14 [7680/60000 (12.8%)]\tLoss: 0.085722\n",
      "Train Epoch: 14 [10240/60000 (17.0%)]\tLoss: 0.076098\n",
      "Train Epoch: 14 [12800/60000 (21.3%)]\tLoss: 0.055242\n",
      "Train Epoch: 14 [15360/60000 (25.5%)]\tLoss: 0.083445\n",
      "Train Epoch: 14 [17920/60000 (29.8%)]\tLoss: 0.053020\n",
      "Train Epoch: 14 [20480/60000 (34.0%)]\tLoss: 0.076964\n",
      "Train Epoch: 14 [23040/60000 (38.3%)]\tLoss: 0.131259\n",
      "Train Epoch: 14 [25600/60000 (42.6%)]\tLoss: 0.085269\n",
      "Train Epoch: 14 [28160/60000 (46.8%)]\tLoss: 0.163339\n",
      "Train Epoch: 14 [30720/60000 (51.1%)]\tLoss: 0.198736\n",
      "Train Epoch: 14 [33280/60000 (55.3%)]\tLoss: 0.115865\n",
      "Train Epoch: 14 [35840/60000 (59.6%)]\tLoss: 0.102628\n",
      "Train Epoch: 14 [38400/60000 (63.8%)]\tLoss: 0.110908\n",
      "Train Epoch: 14 [40960/60000 (68.1%)]\tLoss: 0.104713\n",
      "Train Epoch: 14 [43520/60000 (72.3%)]\tLoss: 0.066176\n",
      "Train Epoch: 14 [46080/60000 (76.6%)]\tLoss: 0.078148\n",
      "Train Epoch: 14 [48640/60000 (80.9%)]\tLoss: 0.087029\n",
      "Train Epoch: 14 [51200/60000 (85.1%)]\tLoss: 0.053301\n",
      "Train Epoch: 14 [53760/60000 (89.4%)]\tLoss: 0.077317\n",
      "Train Epoch: 14 [56320/60000 (93.6%)]\tLoss: 0.077522\n",
      "Train Epoch: 14 [58880/60000 (97.9%)]\tLoss: 0.064724\n",
      "\n",
      "Test set: Average loss: 0.3343, Accuracy: 9121/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0.0%)]\tLoss: 0.046476\n",
      "Train Epoch: 15 [2560/60000 (4.3%)]\tLoss: 0.111355\n",
      "Train Epoch: 15 [5120/60000 (8.5%)]\tLoss: 0.073229\n",
      "Train Epoch: 15 [7680/60000 (12.8%)]\tLoss: 0.093362\n",
      "Train Epoch: 15 [10240/60000 (17.0%)]\tLoss: 0.070235\n",
      "Train Epoch: 15 [12800/60000 (21.3%)]\tLoss: 0.105007\n",
      "Train Epoch: 15 [15360/60000 (25.5%)]\tLoss: 0.177850\n",
      "Train Epoch: 15 [17920/60000 (29.8%)]\tLoss: 0.119401\n",
      "Train Epoch: 15 [20480/60000 (34.0%)]\tLoss: 0.156578\n",
      "Train Epoch: 15 [23040/60000 (38.3%)]\tLoss: 0.209172\n",
      "Train Epoch: 15 [25600/60000 (42.6%)]\tLoss: 0.169105\n",
      "Train Epoch: 15 [28160/60000 (46.8%)]\tLoss: 0.118592\n",
      "Train Epoch: 15 [30720/60000 (51.1%)]\tLoss: 0.134378\n",
      "Train Epoch: 15 [33280/60000 (55.3%)]\tLoss: 0.066509\n",
      "Train Epoch: 15 [35840/60000 (59.6%)]\tLoss: 0.087321\n",
      "Train Epoch: 15 [38400/60000 (63.8%)]\tLoss: 0.064009\n",
      "Train Epoch: 15 [40960/60000 (68.1%)]\tLoss: 0.105567\n",
      "Train Epoch: 15 [43520/60000 (72.3%)]\tLoss: 0.061810\n",
      "Train Epoch: 15 [46080/60000 (76.6%)]\tLoss: 0.077204\n",
      "Train Epoch: 15 [48640/60000 (80.9%)]\tLoss: 0.099741\n",
      "Train Epoch: 15 [51200/60000 (85.1%)]\tLoss: 0.086727\n",
      "Train Epoch: 15 [53760/60000 (89.4%)]\tLoss: 0.086344\n",
      "Train Epoch: 15 [56320/60000 (93.6%)]\tLoss: 0.071582\n",
      "Train Epoch: 15 [58880/60000 (97.9%)]\tLoss: 0.098258\n",
      "\n",
      "Test set: Average loss: 0.3622, Accuracy: 9084/10000 (90.8%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0.0%)]\tLoss: 0.062578\n",
      "Train Epoch: 16 [2560/60000 (4.3%)]\tLoss: 0.096874\n",
      "Train Epoch: 16 [5120/60000 (8.5%)]\tLoss: 0.069296\n",
      "Train Epoch: 16 [7680/60000 (12.8%)]\tLoss: 0.103642\n",
      "Train Epoch: 16 [10240/60000 (17.0%)]\tLoss: 0.099228\n",
      "Train Epoch: 16 [12800/60000 (21.3%)]\tLoss: 0.102479\n",
      "Train Epoch: 16 [15360/60000 (25.5%)]\tLoss: 0.123716\n",
      "Train Epoch: 16 [17920/60000 (29.8%)]\tLoss: 0.136293\n",
      "Train Epoch: 16 [20480/60000 (34.0%)]\tLoss: 0.101531\n",
      "Train Epoch: 16 [23040/60000 (38.3%)]\tLoss: 0.077104\n",
      "Train Epoch: 16 [25600/60000 (42.6%)]\tLoss: 0.097193\n",
      "Train Epoch: 16 [28160/60000 (46.8%)]\tLoss: 0.054134\n",
      "Train Epoch: 16 [30720/60000 (51.1%)]\tLoss: 0.080108\n",
      "Train Epoch: 16 [33280/60000 (55.3%)]\tLoss: 0.096322\n",
      "Train Epoch: 16 [35840/60000 (59.6%)]\tLoss: 0.065743\n",
      "Train Epoch: 16 [38400/60000 (63.8%)]\tLoss: 0.093230\n",
      "Train Epoch: 16 [40960/60000 (68.1%)]\tLoss: 0.069677\n",
      "Train Epoch: 16 [43520/60000 (72.3%)]\tLoss: 0.041374\n",
      "Train Epoch: 16 [46080/60000 (76.6%)]\tLoss: 0.056960\n",
      "Train Epoch: 16 [48640/60000 (80.9%)]\tLoss: 0.078521\n",
      "Train Epoch: 16 [51200/60000 (85.1%)]\tLoss: 0.110505\n",
      "Train Epoch: 16 [53760/60000 (89.4%)]\tLoss: 0.094336\n",
      "Train Epoch: 16 [56320/60000 (93.6%)]\tLoss: 0.099292\n",
      "Train Epoch: 16 [58880/60000 (97.9%)]\tLoss: 0.096429\n",
      "\n",
      "Test set: Average loss: 0.3910, Accuracy: 9007/10000 (90.1%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0.0%)]\tLoss: 0.128803\n",
      "Train Epoch: 17 [2560/60000 (4.3%)]\tLoss: 0.156997\n",
      "Train Epoch: 17 [5120/60000 (8.5%)]\tLoss: 0.110768\n",
      "Train Epoch: 17 [7680/60000 (12.8%)]\tLoss: 0.144702\n",
      "Train Epoch: 17 [10240/60000 (17.0%)]\tLoss: 0.094190\n",
      "Train Epoch: 17 [12800/60000 (21.3%)]\tLoss: 0.113762\n",
      "Train Epoch: 17 [15360/60000 (25.5%)]\tLoss: 0.085474\n",
      "Train Epoch: 17 [17920/60000 (29.8%)]\tLoss: 0.056228\n",
      "Train Epoch: 17 [20480/60000 (34.0%)]\tLoss: 0.080885\n",
      "Train Epoch: 17 [23040/60000 (38.3%)]\tLoss: 0.085247\n",
      "Train Epoch: 17 [25600/60000 (42.6%)]\tLoss: 0.074066\n",
      "Train Epoch: 17 [28160/60000 (46.8%)]\tLoss: 0.050058\n",
      "Train Epoch: 17 [30720/60000 (51.1%)]\tLoss: 0.046852\n",
      "Train Epoch: 17 [33280/60000 (55.3%)]\tLoss: 0.075623\n",
      "Train Epoch: 17 [35840/60000 (59.6%)]\tLoss: 0.082653\n",
      "Train Epoch: 17 [38400/60000 (63.8%)]\tLoss: 0.087002\n",
      "Train Epoch: 17 [40960/60000 (68.1%)]\tLoss: 0.064654\n",
      "Train Epoch: 17 [43520/60000 (72.3%)]\tLoss: 0.074202\n",
      "Train Epoch: 17 [46080/60000 (76.6%)]\tLoss: 0.107345\n",
      "Train Epoch: 17 [48640/60000 (80.9%)]\tLoss: 0.118539\n",
      "Train Epoch: 17 [51200/60000 (85.1%)]\tLoss: 0.086651\n",
      "Train Epoch: 17 [53760/60000 (89.4%)]\tLoss: 0.167841\n",
      "Train Epoch: 17 [56320/60000 (93.6%)]\tLoss: 0.143412\n",
      "Train Epoch: 17 [58880/60000 (97.9%)]\tLoss: 0.139381\n",
      "\n",
      "Test set: Average loss: 0.3853, Accuracy: 9014/10000 (90.1%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0.0%)]\tLoss: 0.116229\n",
      "Train Epoch: 18 [2560/60000 (4.3%)]\tLoss: 0.130541\n",
      "Train Epoch: 18 [5120/60000 (8.5%)]\tLoss: 0.066015\n",
      "Train Epoch: 18 [7680/60000 (12.8%)]\tLoss: 0.063040\n",
      "Train Epoch: 18 [10240/60000 (17.0%)]\tLoss: 0.042418\n",
      "Train Epoch: 18 [12800/60000 (21.3%)]\tLoss: 0.044606\n",
      "Train Epoch: 18 [15360/60000 (25.5%)]\tLoss: 0.059024\n",
      "Train Epoch: 18 [17920/60000 (29.8%)]\tLoss: 0.055258\n",
      "Train Epoch: 18 [20480/60000 (34.0%)]\tLoss: 0.073365\n",
      "Train Epoch: 18 [23040/60000 (38.3%)]\tLoss: 0.092432\n",
      "Train Epoch: 18 [25600/60000 (42.6%)]\tLoss: 0.090852\n",
      "Train Epoch: 18 [28160/60000 (46.8%)]\tLoss: 0.072604\n",
      "Train Epoch: 18 [30720/60000 (51.1%)]\tLoss: 0.064331\n",
      "Train Epoch: 18 [33280/60000 (55.3%)]\tLoss: 0.109657\n",
      "Train Epoch: 18 [35840/60000 (59.6%)]\tLoss: 0.124699\n",
      "Train Epoch: 18 [38400/60000 (63.8%)]\tLoss: 0.055874\n",
      "Train Epoch: 18 [40960/60000 (68.1%)]\tLoss: 0.084556\n",
      "Train Epoch: 18 [43520/60000 (72.3%)]\tLoss: 0.116221\n",
      "Train Epoch: 18 [46080/60000 (76.6%)]\tLoss: 0.084612\n",
      "Train Epoch: 18 [48640/60000 (80.9%)]\tLoss: 0.111343\n",
      "Train Epoch: 18 [51200/60000 (85.1%)]\tLoss: 0.159604\n",
      "Train Epoch: 18 [53760/60000 (89.4%)]\tLoss: 0.144543\n",
      "Train Epoch: 18 [56320/60000 (93.6%)]\tLoss: 0.105956\n",
      "Train Epoch: 18 [58880/60000 (97.9%)]\tLoss: 0.105110\n",
      "\n",
      "Test set: Average loss: 0.3542, Accuracy: 9069/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0.0%)]\tLoss: 0.045655\n",
      "Train Epoch: 19 [2560/60000 (4.3%)]\tLoss: 0.057206\n",
      "Train Epoch: 19 [5120/60000 (8.5%)]\tLoss: 0.079724\n",
      "Train Epoch: 19 [7680/60000 (12.8%)]\tLoss: 0.051859\n",
      "Train Epoch: 19 [10240/60000 (17.0%)]\tLoss: 0.082480\n",
      "Train Epoch: 19 [12800/60000 (21.3%)]\tLoss: 0.062760\n",
      "Train Epoch: 19 [15360/60000 (25.5%)]\tLoss: 0.043576\n",
      "Train Epoch: 19 [17920/60000 (29.8%)]\tLoss: 0.086254\n",
      "Train Epoch: 19 [20480/60000 (34.0%)]\tLoss: 0.056388\n",
      "Train Epoch: 19 [23040/60000 (38.3%)]\tLoss: 0.073602\n",
      "Train Epoch: 19 [25600/60000 (42.6%)]\tLoss: 0.065195\n",
      "Train Epoch: 19 [28160/60000 (46.8%)]\tLoss: 0.122626\n",
      "Train Epoch: 19 [30720/60000 (51.1%)]\tLoss: 0.050925\n",
      "Train Epoch: 19 [33280/60000 (55.3%)]\tLoss: 0.073251\n",
      "Train Epoch: 19 [35840/60000 (59.6%)]\tLoss: 0.070407\n",
      "Train Epoch: 19 [38400/60000 (63.8%)]\tLoss: 0.112387\n",
      "Train Epoch: 19 [40960/60000 (68.1%)]\tLoss: 0.131816\n",
      "Train Epoch: 19 [43520/60000 (72.3%)]\tLoss: 0.118283\n",
      "Train Epoch: 19 [46080/60000 (76.6%)]\tLoss: 0.091086\n",
      "Train Epoch: 19 [48640/60000 (80.9%)]\tLoss: 0.119385\n",
      "Train Epoch: 19 [51200/60000 (85.1%)]\tLoss: 0.034949\n",
      "Train Epoch: 19 [53760/60000 (89.4%)]\tLoss: 0.073461\n",
      "Train Epoch: 19 [56320/60000 (93.6%)]\tLoss: 0.092320\n",
      "Train Epoch: 19 [58880/60000 (97.9%)]\tLoss: 0.090773\n",
      "\n",
      "Test set: Average loss: 0.3580, Accuracy: 9125/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0.0%)]\tLoss: 0.053243\n",
      "Train Epoch: 20 [2560/60000 (4.3%)]\tLoss: 0.070368\n",
      "Train Epoch: 20 [5120/60000 (8.5%)]\tLoss: 0.070505\n",
      "Train Epoch: 20 [7680/60000 (12.8%)]\tLoss: 0.055928\n",
      "Train Epoch: 20 [10240/60000 (17.0%)]\tLoss: 0.052574\n",
      "Train Epoch: 20 [12800/60000 (21.3%)]\tLoss: 0.065385\n",
      "Train Epoch: 20 [15360/60000 (25.5%)]\tLoss: 0.049737\n",
      "Train Epoch: 20 [17920/60000 (29.8%)]\tLoss: 0.093534\n",
      "Train Epoch: 20 [20480/60000 (34.0%)]\tLoss: 0.093598\n",
      "Train Epoch: 20 [23040/60000 (38.3%)]\tLoss: 0.110913\n",
      "Train Epoch: 20 [25600/60000 (42.6%)]\tLoss: 0.192555\n",
      "Train Epoch: 20 [28160/60000 (46.8%)]\tLoss: 0.076351\n",
      "Train Epoch: 20 [30720/60000 (51.1%)]\tLoss: 0.121227\n",
      "Train Epoch: 20 [33280/60000 (55.3%)]\tLoss: 0.124275\n",
      "Train Epoch: 20 [35840/60000 (59.6%)]\tLoss: 0.092362\n",
      "Train Epoch: 20 [38400/60000 (63.8%)]\tLoss: 0.101646\n",
      "Train Epoch: 20 [40960/60000 (68.1%)]\tLoss: 0.114203\n",
      "Train Epoch: 20 [43520/60000 (72.3%)]\tLoss: 0.062266\n",
      "Train Epoch: 20 [46080/60000 (76.6%)]\tLoss: 0.054029\n",
      "Train Epoch: 20 [48640/60000 (80.9%)]\tLoss: 0.059104\n",
      "Train Epoch: 20 [51200/60000 (85.1%)]\tLoss: 0.067564\n",
      "Train Epoch: 20 [53760/60000 (89.4%)]\tLoss: 0.084658\n",
      "Train Epoch: 20 [56320/60000 (93.6%)]\tLoss: 0.049478\n",
      "Train Epoch: 20 [58880/60000 (97.9%)]\tLoss: 0.072851\n",
      "\n",
      "Test set: Average loss: 0.3631, Accuracy: 9114/10000 (91.1%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0.0%)]\tLoss: 0.047156\n",
      "Train Epoch: 21 [2560/60000 (4.3%)]\tLoss: 0.031050\n",
      "Train Epoch: 21 [5120/60000 (8.5%)]\tLoss: 0.033320\n",
      "Train Epoch: 21 [7680/60000 (12.8%)]\tLoss: 0.072264\n",
      "Train Epoch: 21 [10240/60000 (17.0%)]\tLoss: 0.106305\n",
      "Train Epoch: 21 [12800/60000 (21.3%)]\tLoss: 0.080826\n",
      "Train Epoch: 21 [15360/60000 (25.5%)]\tLoss: 0.096568\n",
      "Train Epoch: 21 [17920/60000 (29.8%)]\tLoss: 0.110448\n",
      "Train Epoch: 21 [20480/60000 (34.0%)]\tLoss: 0.107173\n",
      "Train Epoch: 21 [23040/60000 (38.3%)]\tLoss: 0.081983\n",
      "Train Epoch: 21 [25600/60000 (42.6%)]\tLoss: 0.174225\n",
      "Train Epoch: 21 [28160/60000 (46.8%)]\tLoss: 0.136844\n",
      "Train Epoch: 21 [30720/60000 (51.1%)]\tLoss: 0.097212\n",
      "Train Epoch: 21 [33280/60000 (55.3%)]\tLoss: 0.068262\n",
      "Train Epoch: 21 [35840/60000 (59.6%)]\tLoss: 0.065720\n",
      "Train Epoch: 21 [38400/60000 (63.8%)]\tLoss: 0.095382\n",
      "Train Epoch: 21 [40960/60000 (68.1%)]\tLoss: 0.051677\n",
      "Train Epoch: 21 [43520/60000 (72.3%)]\tLoss: 0.042576\n",
      "Train Epoch: 21 [46080/60000 (76.6%)]\tLoss: 0.078952\n",
      "Train Epoch: 21 [48640/60000 (80.9%)]\tLoss: 0.073041\n",
      "Train Epoch: 21 [51200/60000 (85.1%)]\tLoss: 0.046757\n",
      "Train Epoch: 21 [53760/60000 (89.4%)]\tLoss: 0.127736\n",
      "Train Epoch: 21 [56320/60000 (93.6%)]\tLoss: 0.075602\n",
      "Train Epoch: 21 [58880/60000 (97.9%)]\tLoss: 0.043534\n",
      "\n",
      "Test set: Average loss: 0.4065, Accuracy: 9064/10000 (90.6%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0.0%)]\tLoss: 0.048591\n",
      "Train Epoch: 22 [2560/60000 (4.3%)]\tLoss: 0.076732\n",
      "Train Epoch: 22 [5120/60000 (8.5%)]\tLoss: 0.092626\n",
      "Train Epoch: 22 [7680/60000 (12.8%)]\tLoss: 0.059763\n",
      "Train Epoch: 22 [10240/60000 (17.0%)]\tLoss: 0.093242\n",
      "Train Epoch: 22 [12800/60000 (21.3%)]\tLoss: 0.105135\n",
      "Train Epoch: 22 [15360/60000 (25.5%)]\tLoss: 0.073726\n",
      "Train Epoch: 22 [17920/60000 (29.8%)]\tLoss: 0.118578\n",
      "Train Epoch: 22 [20480/60000 (34.0%)]\tLoss: 0.111818\n",
      "Train Epoch: 22 [23040/60000 (38.3%)]\tLoss: 0.053818\n",
      "Train Epoch: 22 [25600/60000 (42.6%)]\tLoss: 0.109295\n",
      "Train Epoch: 22 [28160/60000 (46.8%)]\tLoss: 0.053878\n",
      "Train Epoch: 22 [30720/60000 (51.1%)]\tLoss: 0.067218\n",
      "Train Epoch: 22 [33280/60000 (55.3%)]\tLoss: 0.050009\n",
      "Train Epoch: 22 [35840/60000 (59.6%)]\tLoss: 0.045468\n",
      "Train Epoch: 22 [38400/60000 (63.8%)]\tLoss: 0.050244\n",
      "Train Epoch: 22 [40960/60000 (68.1%)]\tLoss: 0.094417\n",
      "Train Epoch: 22 [43520/60000 (72.3%)]\tLoss: 0.044198\n",
      "Train Epoch: 22 [46080/60000 (76.6%)]\tLoss: 0.073511\n",
      "Train Epoch: 22 [48640/60000 (80.9%)]\tLoss: 0.074058\n",
      "Train Epoch: 22 [51200/60000 (85.1%)]\tLoss: 0.057308\n",
      "Train Epoch: 22 [53760/60000 (89.4%)]\tLoss: 0.096746\n",
      "Train Epoch: 22 [56320/60000 (93.6%)]\tLoss: 0.139786\n",
      "Train Epoch: 22 [58880/60000 (97.9%)]\tLoss: 0.084257\n",
      "\n",
      "Test set: Average loss: 0.4203, Accuracy: 8974/10000 (89.7%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0.0%)]\tLoss: 0.111267\n",
      "Train Epoch: 23 [2560/60000 (4.3%)]\tLoss: 0.080863\n",
      "Train Epoch: 23 [5120/60000 (8.5%)]\tLoss: 0.066433\n",
      "Train Epoch: 23 [7680/60000 (12.8%)]\tLoss: 0.119495\n",
      "Train Epoch: 23 [10240/60000 (17.0%)]\tLoss: 0.143256\n",
      "Train Epoch: 23 [12800/60000 (21.3%)]\tLoss: 0.090240\n",
      "Train Epoch: 23 [15360/60000 (25.5%)]\tLoss: 0.063129\n",
      "Train Epoch: 23 [17920/60000 (29.8%)]\tLoss: 0.056673\n",
      "Train Epoch: 23 [20480/60000 (34.0%)]\tLoss: 0.074366\n",
      "Train Epoch: 23 [23040/60000 (38.3%)]\tLoss: 0.031733\n",
      "Train Epoch: 23 [25600/60000 (42.6%)]\tLoss: 0.047063\n",
      "Train Epoch: 23 [28160/60000 (46.8%)]\tLoss: 0.046499\n",
      "Train Epoch: 23 [30720/60000 (51.1%)]\tLoss: 0.064303\n",
      "Train Epoch: 23 [33280/60000 (55.3%)]\tLoss: 0.067907\n",
      "Train Epoch: 23 [35840/60000 (59.6%)]\tLoss: 0.034637\n",
      "Train Epoch: 23 [38400/60000 (63.8%)]\tLoss: 0.058980\n",
      "Train Epoch: 23 [40960/60000 (68.1%)]\tLoss: 0.069388\n",
      "Train Epoch: 23 [43520/60000 (72.3%)]\tLoss: 0.065743\n",
      "Train Epoch: 23 [46080/60000 (76.6%)]\tLoss: 0.081632\n",
      "Train Epoch: 23 [48640/60000 (80.9%)]\tLoss: 0.086954\n",
      "Train Epoch: 23 [51200/60000 (85.1%)]\tLoss: 0.119402\n",
      "Train Epoch: 23 [53760/60000 (89.4%)]\tLoss: 0.104235\n",
      "Train Epoch: 23 [56320/60000 (93.6%)]\tLoss: 0.100293\n",
      "Train Epoch: 23 [58880/60000 (97.9%)]\tLoss: 0.130258\n",
      "\n",
      "Test set: Average loss: 0.4155, Accuracy: 9003/10000 (90.0%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0.0%)]\tLoss: 0.088338\n",
      "Train Epoch: 24 [2560/60000 (4.3%)]\tLoss: 0.055318\n",
      "Train Epoch: 24 [5120/60000 (8.5%)]\tLoss: 0.079843\n",
      "Train Epoch: 24 [7680/60000 (12.8%)]\tLoss: 0.060286\n",
      "Train Epoch: 24 [10240/60000 (17.0%)]\tLoss: 0.029809\n",
      "Train Epoch: 24 [12800/60000 (21.3%)]\tLoss: 0.051972\n",
      "Train Epoch: 24 [15360/60000 (25.5%)]\tLoss: 0.061970\n",
      "Train Epoch: 24 [17920/60000 (29.8%)]\tLoss: 0.028403\n",
      "Train Epoch: 24 [20480/60000 (34.0%)]\tLoss: 0.055666\n",
      "Train Epoch: 24 [23040/60000 (38.3%)]\tLoss: 0.046344\n",
      "Train Epoch: 24 [25600/60000 (42.6%)]\tLoss: 0.043873\n",
      "Train Epoch: 24 [28160/60000 (46.8%)]\tLoss: 0.076023\n",
      "Train Epoch: 24 [30720/60000 (51.1%)]\tLoss: 0.049864\n",
      "Train Epoch: 24 [33280/60000 (55.3%)]\tLoss: 0.054275\n",
      "Train Epoch: 24 [35840/60000 (59.6%)]\tLoss: 0.122793\n",
      "Train Epoch: 24 [38400/60000 (63.8%)]\tLoss: 0.110106\n",
      "Train Epoch: 24 [40960/60000 (68.1%)]\tLoss: 0.141770\n",
      "Train Epoch: 24 [43520/60000 (72.3%)]\tLoss: 0.146680\n",
      "Train Epoch: 24 [46080/60000 (76.6%)]\tLoss: 0.126789\n",
      "Train Epoch: 24 [48640/60000 (80.9%)]\tLoss: 0.110016\n",
      "Train Epoch: 24 [51200/60000 (85.1%)]\tLoss: 0.121272\n",
      "Train Epoch: 24 [53760/60000 (89.4%)]\tLoss: 0.149867\n",
      "Train Epoch: 24 [56320/60000 (93.6%)]\tLoss: 0.110617\n",
      "Train Epoch: 24 [58880/60000 (97.9%)]\tLoss: 0.027050\n",
      "\n",
      "Test set: Average loss: 0.3745, Accuracy: 9088/10000 (90.9%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0.0%)]\tLoss: 0.053235\n",
      "Train Epoch: 25 [2560/60000 (4.3%)]\tLoss: 0.039044\n",
      "Train Epoch: 25 [5120/60000 (8.5%)]\tLoss: 0.033218\n",
      "Train Epoch: 25 [7680/60000 (12.8%)]\tLoss: 0.023471\n",
      "Train Epoch: 25 [10240/60000 (17.0%)]\tLoss: 0.065540\n",
      "Train Epoch: 25 [12800/60000 (21.3%)]\tLoss: 0.059377\n",
      "Train Epoch: 25 [15360/60000 (25.5%)]\tLoss: 0.055452\n",
      "Train Epoch: 25 [17920/60000 (29.8%)]\tLoss: 0.039562\n",
      "Train Epoch: 25 [20480/60000 (34.0%)]\tLoss: 0.092555\n",
      "Train Epoch: 25 [23040/60000 (38.3%)]\tLoss: 0.043286\n",
      "Train Epoch: 25 [25600/60000 (42.6%)]\tLoss: 0.036451\n",
      "Train Epoch: 25 [28160/60000 (46.8%)]\tLoss: 0.137697\n",
      "Train Epoch: 25 [30720/60000 (51.1%)]\tLoss: 0.088113\n",
      "Train Epoch: 25 [33280/60000 (55.3%)]\tLoss: 0.109804\n",
      "Train Epoch: 25 [35840/60000 (59.6%)]\tLoss: 0.123603\n",
      "Train Epoch: 25 [38400/60000 (63.8%)]\tLoss: 0.172179\n",
      "Train Epoch: 25 [40960/60000 (68.1%)]\tLoss: 0.166007\n",
      "Train Epoch: 25 [43520/60000 (72.3%)]\tLoss: 0.088239\n",
      "Train Epoch: 25 [46080/60000 (76.6%)]\tLoss: 0.120047\n",
      "Train Epoch: 25 [48640/60000 (80.9%)]\tLoss: 0.067678\n",
      "Train Epoch: 25 [51200/60000 (85.1%)]\tLoss: 0.063100\n",
      "Train Epoch: 25 [53760/60000 (89.4%)]\tLoss: 0.074698\n",
      "Train Epoch: 25 [56320/60000 (93.6%)]\tLoss: 0.036331\n",
      "Train Epoch: 25 [58880/60000 (97.9%)]\tLoss: 0.034093\n",
      "\n",
      "Test set: Average loss: 0.3843, Accuracy: 9098/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0.0%)]\tLoss: 0.039555\n",
      "Train Epoch: 26 [2560/60000 (4.3%)]\tLoss: 0.038315\n",
      "Train Epoch: 26 [5120/60000 (8.5%)]\tLoss: 0.046077\n",
      "Train Epoch: 26 [7680/60000 (12.8%)]\tLoss: 0.058592\n",
      "Train Epoch: 26 [10240/60000 (17.0%)]\tLoss: 0.041449\n",
      "Train Epoch: 26 [12800/60000 (21.3%)]\tLoss: 0.047531\n",
      "Train Epoch: 26 [15360/60000 (25.5%)]\tLoss: 0.088275\n",
      "Train Epoch: 26 [17920/60000 (29.8%)]\tLoss: 0.037877\n",
      "Train Epoch: 26 [20480/60000 (34.0%)]\tLoss: 0.128410\n",
      "Train Epoch: 26 [23040/60000 (38.3%)]\tLoss: 0.105292\n",
      "Train Epoch: 26 [25600/60000 (42.6%)]\tLoss: 0.084966\n",
      "Train Epoch: 26 [28160/60000 (46.8%)]\tLoss: 0.116461\n",
      "Train Epoch: 26 [30720/60000 (51.1%)]\tLoss: 0.155920\n",
      "Train Epoch: 26 [33280/60000 (55.3%)]\tLoss: 0.083352\n",
      "Train Epoch: 26 [35840/60000 (59.6%)]\tLoss: 0.150961\n",
      "Train Epoch: 26 [38400/60000 (63.8%)]\tLoss: 0.067869\n",
      "Train Epoch: 26 [40960/60000 (68.1%)]\tLoss: 0.077067\n",
      "Train Epoch: 26 [43520/60000 (72.3%)]\tLoss: 0.056734\n",
      "Train Epoch: 26 [46080/60000 (76.6%)]\tLoss: 0.054986\n",
      "Train Epoch: 26 [48640/60000 (80.9%)]\tLoss: 0.098185\n",
      "Train Epoch: 26 [51200/60000 (85.1%)]\tLoss: 0.049272\n",
      "Train Epoch: 26 [53760/60000 (89.4%)]\tLoss: 0.063575\n",
      "Train Epoch: 26 [56320/60000 (93.6%)]\tLoss: 0.078030\n",
      "Train Epoch: 26 [58880/60000 (97.9%)]\tLoss: 0.070633\n",
      "\n",
      "Test set: Average loss: 0.3762, Accuracy: 9124/10000 (91.2%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0.0%)]\tLoss: 0.037768\n",
      "Train Epoch: 27 [2560/60000 (4.3%)]\tLoss: 0.034725\n",
      "Train Epoch: 27 [5120/60000 (8.5%)]\tLoss: 0.065676\n",
      "Train Epoch: 27 [7680/60000 (12.8%)]\tLoss: 0.079462\n",
      "Train Epoch: 27 [10240/60000 (17.0%)]\tLoss: 0.082659\n",
      "Train Epoch: 27 [12800/60000 (21.3%)]\tLoss: 0.054393\n",
      "Train Epoch: 27 [15360/60000 (25.5%)]\tLoss: 0.138644\n",
      "Train Epoch: 27 [17920/60000 (29.8%)]\tLoss: 0.107788\n",
      "Train Epoch: 27 [20480/60000 (34.0%)]\tLoss: 0.072104\n",
      "Train Epoch: 27 [23040/60000 (38.3%)]\tLoss: 0.035788\n",
      "Train Epoch: 27 [25600/60000 (42.6%)]\tLoss: 0.098832\n",
      "Train Epoch: 27 [28160/60000 (46.8%)]\tLoss: 0.058569\n",
      "Train Epoch: 27 [30720/60000 (51.1%)]\tLoss: 0.092111\n",
      "Train Epoch: 27 [33280/60000 (55.3%)]\tLoss: 0.028574\n",
      "Train Epoch: 27 [35840/60000 (59.6%)]\tLoss: 0.063458\n",
      "Train Epoch: 27 [38400/60000 (63.8%)]\tLoss: 0.055033\n",
      "Train Epoch: 27 [40960/60000 (68.1%)]\tLoss: 0.041882\n",
      "Train Epoch: 27 [43520/60000 (72.3%)]\tLoss: 0.035814\n",
      "Train Epoch: 27 [46080/60000 (76.6%)]\tLoss: 0.055509\n",
      "Train Epoch: 27 [48640/60000 (80.9%)]\tLoss: 0.064519\n",
      "Train Epoch: 27 [51200/60000 (85.1%)]\tLoss: 0.071632\n",
      "Train Epoch: 27 [53760/60000 (89.4%)]\tLoss: 0.105489\n",
      "Train Epoch: 27 [56320/60000 (93.6%)]\tLoss: 0.054687\n",
      "Train Epoch: 27 [58880/60000 (97.9%)]\tLoss: 0.078074\n",
      "\n",
      "Test set: Average loss: 0.4677, Accuracy: 9024/10000 (90.2%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0.0%)]\tLoss: 0.051985\n",
      "Train Epoch: 28 [2560/60000 (4.3%)]\tLoss: 0.083932\n",
      "Train Epoch: 28 [5120/60000 (8.5%)]\tLoss: 0.111502\n",
      "Train Epoch: 28 [7680/60000 (12.8%)]\tLoss: 0.105858\n",
      "Train Epoch: 28 [10240/60000 (17.0%)]\tLoss: 0.088441\n",
      "Train Epoch: 28 [12800/60000 (21.3%)]\tLoss: 0.082420\n",
      "Train Epoch: 28 [15360/60000 (25.5%)]\tLoss: 0.061174\n",
      "Train Epoch: 28 [17920/60000 (29.8%)]\tLoss: 0.039838\n",
      "Train Epoch: 28 [20480/60000 (34.0%)]\tLoss: 0.056226\n",
      "Train Epoch: 28 [23040/60000 (38.3%)]\tLoss: 0.055517\n",
      "Train Epoch: 28 [25600/60000 (42.6%)]\tLoss: 0.060526\n",
      "Train Epoch: 28 [28160/60000 (46.8%)]\tLoss: 0.057079\n",
      "Train Epoch: 28 [30720/60000 (51.1%)]\tLoss: 0.047627\n",
      "Train Epoch: 28 [33280/60000 (55.3%)]\tLoss: 0.024180\n",
      "Train Epoch: 28 [35840/60000 (59.6%)]\tLoss: 0.043696\n",
      "Train Epoch: 28 [38400/60000 (63.8%)]\tLoss: 0.040933\n",
      "Train Epoch: 28 [40960/60000 (68.1%)]\tLoss: 0.047362\n",
      "Train Epoch: 28 [43520/60000 (72.3%)]\tLoss: 0.047174\n",
      "Train Epoch: 28 [46080/60000 (76.6%)]\tLoss: 0.037461\n",
      "Train Epoch: 28 [48640/60000 (80.9%)]\tLoss: 0.029010\n",
      "Train Epoch: 28 [51200/60000 (85.1%)]\tLoss: 0.098967\n",
      "Train Epoch: 28 [53760/60000 (89.4%)]\tLoss: 0.119447\n",
      "Train Epoch: 28 [56320/60000 (93.6%)]\tLoss: 0.100150\n",
      "Train Epoch: 28 [58880/60000 (97.9%)]\tLoss: 0.124695\n",
      "\n",
      "Test set: Average loss: 0.4895, Accuracy: 9029/10000 (90.3%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0.0%)]\tLoss: 0.070843\n",
      "Train Epoch: 29 [2560/60000 (4.3%)]\tLoss: 0.098499\n",
      "Train Epoch: 29 [5120/60000 (8.5%)]\tLoss: 0.087920\n",
      "Train Epoch: 29 [7680/60000 (12.8%)]\tLoss: 0.080930\n",
      "Train Epoch: 29 [10240/60000 (17.0%)]\tLoss: 0.073774\n",
      "Train Epoch: 29 [12800/60000 (21.3%)]\tLoss: 0.073178\n",
      "Train Epoch: 29 [15360/60000 (25.5%)]\tLoss: 0.065361\n",
      "Train Epoch: 29 [17920/60000 (29.8%)]\tLoss: 0.075015\n",
      "Train Epoch: 29 [20480/60000 (34.0%)]\tLoss: 0.094405\n",
      "Train Epoch: 29 [23040/60000 (38.3%)]\tLoss: 0.053101\n",
      "Train Epoch: 29 [25600/60000 (42.6%)]\tLoss: 0.061982\n",
      "Train Epoch: 29 [28160/60000 (46.8%)]\tLoss: 0.061246\n",
      "Train Epoch: 29 [30720/60000 (51.1%)]\tLoss: 0.081115\n",
      "Train Epoch: 29 [33280/60000 (55.3%)]\tLoss: 0.047888\n",
      "Train Epoch: 29 [35840/60000 (59.6%)]\tLoss: 0.048377\n",
      "Train Epoch: 29 [38400/60000 (63.8%)]\tLoss: 0.071641\n",
      "Train Epoch: 29 [40960/60000 (68.1%)]\tLoss: 0.096509\n",
      "Train Epoch: 29 [43520/60000 (72.3%)]\tLoss: 0.059638\n",
      "Train Epoch: 29 [46080/60000 (76.6%)]\tLoss: 0.113638\n",
      "Train Epoch: 29 [48640/60000 (80.9%)]\tLoss: 0.107997\n",
      "Train Epoch: 29 [51200/60000 (85.1%)]\tLoss: 0.074777\n",
      "Train Epoch: 29 [53760/60000 (89.4%)]\tLoss: 0.120608\n",
      "Train Epoch: 29 [56320/60000 (93.6%)]\tLoss: 0.093717\n",
      "Train Epoch: 29 [58880/60000 (97.9%)]\tLoss: 0.096988\n",
      "\n",
      "Test set: Average loss: 0.4256, Accuracy: 9040/10000 (90.4%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0.0%)]\tLoss: 0.049524\n",
      "Train Epoch: 30 [2560/60000 (4.3%)]\tLoss: 0.055148\n",
      "Train Epoch: 30 [5120/60000 (8.5%)]\tLoss: 0.087898\n",
      "Train Epoch: 30 [7680/60000 (12.8%)]\tLoss: 0.076176\n",
      "Train Epoch: 30 [10240/60000 (17.0%)]\tLoss: 0.043489\n",
      "Train Epoch: 30 [12800/60000 (21.3%)]\tLoss: 0.042933\n",
      "Train Epoch: 30 [15360/60000 (25.5%)]\tLoss: 0.061655\n",
      "Train Epoch: 30 [17920/60000 (29.8%)]\tLoss: 0.053420\n",
      "Train Epoch: 30 [20480/60000 (34.0%)]\tLoss: 0.061003\n",
      "Train Epoch: 30 [23040/60000 (38.3%)]\tLoss: 0.046298\n",
      "Train Epoch: 30 [25600/60000 (42.6%)]\tLoss: 0.046768\n",
      "Train Epoch: 30 [28160/60000 (46.8%)]\tLoss: 0.091748\n",
      "Train Epoch: 30 [30720/60000 (51.1%)]\tLoss: 0.029138\n",
      "Train Epoch: 30 [33280/60000 (55.3%)]\tLoss: 0.056562\n",
      "Train Epoch: 30 [35840/60000 (59.6%)]\tLoss: 0.080219\n",
      "Train Epoch: 30 [38400/60000 (63.8%)]\tLoss: 0.070348\n",
      "Train Epoch: 30 [40960/60000 (68.1%)]\tLoss: 0.097197\n",
      "Train Epoch: 30 [43520/60000 (72.3%)]\tLoss: 0.103722\n",
      "Train Epoch: 30 [46080/60000 (76.6%)]\tLoss: 0.054506\n",
      "Train Epoch: 30 [48640/60000 (80.9%)]\tLoss: 0.129432\n",
      "Train Epoch: 30 [51200/60000 (85.1%)]\tLoss: 0.113154\n",
      "Train Epoch: 30 [53760/60000 (89.4%)]\tLoss: 0.065397\n",
      "Train Epoch: 30 [56320/60000 (93.6%)]\tLoss: 0.076565\n",
      "Train Epoch: 30 [58880/60000 (97.9%)]\tLoss: 0.073377\n",
      "\n",
      "Test set: Average loss: 0.4164, Accuracy: 9072/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0.0%)]\tLoss: 0.040700\n",
      "Train Epoch: 31 [2560/60000 (4.3%)]\tLoss: 0.045408\n",
      "Train Epoch: 31 [5120/60000 (8.5%)]\tLoss: 0.043187\n",
      "Train Epoch: 31 [7680/60000 (12.8%)]\tLoss: 0.036916\n",
      "Train Epoch: 31 [10240/60000 (17.0%)]\tLoss: 0.066374\n",
      "Train Epoch: 31 [12800/60000 (21.3%)]\tLoss: 0.029030\n",
      "Train Epoch: 31 [15360/60000 (25.5%)]\tLoss: 0.038941\n",
      "Train Epoch: 31 [17920/60000 (29.8%)]\tLoss: 0.038063\n",
      "Train Epoch: 31 [20480/60000 (34.0%)]\tLoss: 0.037912\n",
      "Train Epoch: 31 [23040/60000 (38.3%)]\tLoss: 0.068384\n",
      "Train Epoch: 31 [25600/60000 (42.6%)]\tLoss: 0.037411\n",
      "Train Epoch: 31 [28160/60000 (46.8%)]\tLoss: 0.133886\n",
      "Train Epoch: 31 [30720/60000 (51.1%)]\tLoss: 0.087083\n",
      "Train Epoch: 31 [33280/60000 (55.3%)]\tLoss: 0.103677\n",
      "Train Epoch: 31 [35840/60000 (59.6%)]\tLoss: 0.047001\n",
      "Train Epoch: 31 [38400/60000 (63.8%)]\tLoss: 0.091801\n",
      "Train Epoch: 31 [40960/60000 (68.1%)]\tLoss: 0.112341\n",
      "Train Epoch: 31 [43520/60000 (72.3%)]\tLoss: 0.101781\n",
      "Train Epoch: 31 [46080/60000 (76.6%)]\tLoss: 0.082809\n",
      "Train Epoch: 31 [48640/60000 (80.9%)]\tLoss: 0.052355\n",
      "Train Epoch: 31 [51200/60000 (85.1%)]\tLoss: 0.054207\n",
      "Train Epoch: 31 [53760/60000 (89.4%)]\tLoss: 0.057621\n",
      "Train Epoch: 31 [56320/60000 (93.6%)]\tLoss: 0.061120\n",
      "Train Epoch: 31 [58880/60000 (97.9%)]\tLoss: 0.047797\n",
      "\n",
      "Test set: Average loss: 0.4176, Accuracy: 9098/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0.0%)]\tLoss: 0.039540\n",
      "Train Epoch: 32 [2560/60000 (4.3%)]\tLoss: 0.052370\n",
      "Train Epoch: 32 [5120/60000 (8.5%)]\tLoss: 0.037370\n",
      "Train Epoch: 32 [7680/60000 (12.8%)]\tLoss: 0.039347\n",
      "Train Epoch: 32 [10240/60000 (17.0%)]\tLoss: 0.050646\n",
      "Train Epoch: 32 [12800/60000 (21.3%)]\tLoss: 0.056194\n",
      "Train Epoch: 32 [15360/60000 (25.5%)]\tLoss: 0.082269\n",
      "Train Epoch: 32 [17920/60000 (29.8%)]\tLoss: 0.055287\n",
      "Train Epoch: 32 [20480/60000 (34.0%)]\tLoss: 0.037167\n",
      "Train Epoch: 32 [23040/60000 (38.3%)]\tLoss: 0.031852\n",
      "Train Epoch: 32 [25600/60000 (42.6%)]\tLoss: 0.073621\n",
      "Train Epoch: 32 [28160/60000 (46.8%)]\tLoss: 0.090624\n",
      "Train Epoch: 32 [30720/60000 (51.1%)]\tLoss: 0.228494\n",
      "Train Epoch: 32 [33280/60000 (55.3%)]\tLoss: 0.075266\n",
      "Train Epoch: 32 [35840/60000 (59.6%)]\tLoss: 0.061665\n",
      "Train Epoch: 32 [38400/60000 (63.8%)]\tLoss: 0.053158\n",
      "Train Epoch: 32 [40960/60000 (68.1%)]\tLoss: 0.052202\n",
      "Train Epoch: 32 [43520/60000 (72.3%)]\tLoss: 0.063455\n",
      "Train Epoch: 32 [46080/60000 (76.6%)]\tLoss: 0.033599\n",
      "Train Epoch: 32 [48640/60000 (80.9%)]\tLoss: 0.037461\n",
      "Train Epoch: 32 [51200/60000 (85.1%)]\tLoss: 0.065617\n",
      "Train Epoch: 32 [53760/60000 (89.4%)]\tLoss: 0.042495\n",
      "Train Epoch: 32 [56320/60000 (93.6%)]\tLoss: 0.041710\n",
      "Train Epoch: 32 [58880/60000 (97.9%)]\tLoss: 0.055819\n",
      "\n",
      "Test set: Average loss: 0.4542, Accuracy: 9100/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0.0%)]\tLoss: 0.046860\n",
      "Train Epoch: 33 [2560/60000 (4.3%)]\tLoss: 0.050501\n",
      "Train Epoch: 33 [5120/60000 (8.5%)]\tLoss: 0.069030\n",
      "Train Epoch: 33 [7680/60000 (12.8%)]\tLoss: 0.089515\n",
      "Train Epoch: 33 [10240/60000 (17.0%)]\tLoss: 0.048378\n",
      "Train Epoch: 33 [12800/60000 (21.3%)]\tLoss: 0.091523\n",
      "Train Epoch: 33 [15360/60000 (25.5%)]\tLoss: 0.128657\n",
      "Train Epoch: 33 [17920/60000 (29.8%)]\tLoss: 0.122915\n",
      "Train Epoch: 33 [20480/60000 (34.0%)]\tLoss: 0.093406\n",
      "Train Epoch: 33 [23040/60000 (38.3%)]\tLoss: 0.053129\n",
      "Train Epoch: 33 [25600/60000 (42.6%)]\tLoss: 0.090140\n",
      "Train Epoch: 33 [28160/60000 (46.8%)]\tLoss: 0.039150\n",
      "Train Epoch: 33 [30720/60000 (51.1%)]\tLoss: 0.069003\n",
      "Train Epoch: 33 [33280/60000 (55.3%)]\tLoss: 0.069789\n",
      "Train Epoch: 33 [35840/60000 (59.6%)]\tLoss: 0.069333\n",
      "Train Epoch: 33 [38400/60000 (63.8%)]\tLoss: 0.044591\n",
      "Train Epoch: 33 [40960/60000 (68.1%)]\tLoss: 0.038226\n",
      "Train Epoch: 33 [43520/60000 (72.3%)]\tLoss: 0.032393\n",
      "Train Epoch: 33 [46080/60000 (76.6%)]\tLoss: 0.025705\n",
      "Train Epoch: 33 [48640/60000 (80.9%)]\tLoss: 0.064304\n",
      "Train Epoch: 33 [51200/60000 (85.1%)]\tLoss: 0.054722\n",
      "Train Epoch: 33 [53760/60000 (89.4%)]\tLoss: 0.048054\n",
      "Train Epoch: 33 [56320/60000 (93.6%)]\tLoss: 0.033930\n",
      "Train Epoch: 33 [58880/60000 (97.9%)]\tLoss: 0.081124\n",
      "\n",
      "Test set: Average loss: 0.4838, Accuracy: 9052/10000 (90.5%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0.0%)]\tLoss: 0.049608\n",
      "Train Epoch: 34 [2560/60000 (4.3%)]\tLoss: 0.047457\n",
      "Train Epoch: 34 [5120/60000 (8.5%)]\tLoss: 0.127455\n",
      "Train Epoch: 34 [7680/60000 (12.8%)]\tLoss: 0.083093\n",
      "Train Epoch: 34 [10240/60000 (17.0%)]\tLoss: 0.151375\n",
      "Train Epoch: 34 [12800/60000 (21.3%)]\tLoss: 0.083032\n",
      "Train Epoch: 34 [15360/60000 (25.5%)]\tLoss: 0.083667\n",
      "Train Epoch: 34 [17920/60000 (29.8%)]\tLoss: 0.104082\n",
      "Train Epoch: 34 [20480/60000 (34.0%)]\tLoss: 0.077615\n",
      "Train Epoch: 34 [23040/60000 (38.3%)]\tLoss: 0.057915\n",
      "Train Epoch: 34 [25600/60000 (42.6%)]\tLoss: 0.026135\n",
      "Train Epoch: 34 [28160/60000 (46.8%)]\tLoss: 0.063351\n",
      "Train Epoch: 34 [30720/60000 (51.1%)]\tLoss: 0.057672\n",
      "Train Epoch: 34 [33280/60000 (55.3%)]\tLoss: 0.055900\n",
      "Train Epoch: 34 [35840/60000 (59.6%)]\tLoss: 0.043509\n",
      "Train Epoch: 34 [38400/60000 (63.8%)]\tLoss: 0.042641\n",
      "Train Epoch: 34 [40960/60000 (68.1%)]\tLoss: 0.071740\n",
      "Train Epoch: 34 [43520/60000 (72.3%)]\tLoss: 0.046599\n",
      "Train Epoch: 34 [46080/60000 (76.6%)]\tLoss: 0.083663\n",
      "Train Epoch: 34 [48640/60000 (80.9%)]\tLoss: 0.066566\n",
      "Train Epoch: 34 [51200/60000 (85.1%)]\tLoss: 0.075015\n",
      "Train Epoch: 34 [53760/60000 (89.4%)]\tLoss: 0.047803\n",
      "Train Epoch: 34 [56320/60000 (93.6%)]\tLoss: 0.111556\n",
      "Train Epoch: 34 [58880/60000 (97.9%)]\tLoss: 0.131727\n",
      "\n",
      "Test set: Average loss: 0.5081, Accuracy: 8998/10000 (90.0%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0.0%)]\tLoss: 0.075652\n",
      "Train Epoch: 35 [2560/60000 (4.3%)]\tLoss: 0.090273\n",
      "Train Epoch: 35 [5120/60000 (8.5%)]\tLoss: 0.051807\n",
      "Train Epoch: 35 [7680/60000 (12.8%)]\tLoss: 0.029484\n",
      "Train Epoch: 35 [10240/60000 (17.0%)]\tLoss: 0.059407\n",
      "Train Epoch: 35 [12800/60000 (21.3%)]\tLoss: 0.066102\n",
      "Train Epoch: 35 [15360/60000 (25.5%)]\tLoss: 0.062031\n",
      "Train Epoch: 35 [17920/60000 (29.8%)]\tLoss: 0.020131\n",
      "Train Epoch: 35 [20480/60000 (34.0%)]\tLoss: 0.057146\n",
      "Train Epoch: 35 [23040/60000 (38.3%)]\tLoss: 0.087052\n",
      "Train Epoch: 35 [25600/60000 (42.6%)]\tLoss: 0.023916\n",
      "Train Epoch: 35 [28160/60000 (46.8%)]\tLoss: 0.044197\n",
      "Train Epoch: 35 [30720/60000 (51.1%)]\tLoss: 0.032299\n",
      "Train Epoch: 35 [33280/60000 (55.3%)]\tLoss: 0.043190\n",
      "Train Epoch: 35 [35840/60000 (59.6%)]\tLoss: 0.039320\n",
      "Train Epoch: 35 [38400/60000 (63.8%)]\tLoss: 0.026617\n",
      "Train Epoch: 35 [40960/60000 (68.1%)]\tLoss: 0.115142\n",
      "Train Epoch: 35 [43520/60000 (72.3%)]\tLoss: 0.074547\n",
      "Train Epoch: 35 [46080/60000 (76.6%)]\tLoss: 0.069499\n",
      "Train Epoch: 35 [48640/60000 (80.9%)]\tLoss: 0.089517\n",
      "Train Epoch: 35 [51200/60000 (85.1%)]\tLoss: 0.125332\n",
      "Train Epoch: 35 [53760/60000 (89.4%)]\tLoss: 0.036018\n",
      "Train Epoch: 35 [56320/60000 (93.6%)]\tLoss: 0.105588\n",
      "Train Epoch: 35 [58880/60000 (97.9%)]\tLoss: 0.063761\n",
      "\n",
      "Test set: Average loss: 0.4560, Accuracy: 9057/10000 (90.6%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0.0%)]\tLoss: 0.084963\n",
      "Train Epoch: 36 [2560/60000 (4.3%)]\tLoss: 0.073540\n",
      "Train Epoch: 36 [5120/60000 (8.5%)]\tLoss: 0.022888\n",
      "Train Epoch: 36 [7680/60000 (12.8%)]\tLoss: 0.039565\n",
      "Train Epoch: 36 [10240/60000 (17.0%)]\tLoss: 0.019980\n",
      "Train Epoch: 36 [12800/60000 (21.3%)]\tLoss: 0.023229\n",
      "Train Epoch: 36 [15360/60000 (25.5%)]\tLoss: 0.041322\n",
      "Train Epoch: 36 [17920/60000 (29.8%)]\tLoss: 0.061612\n",
      "Train Epoch: 36 [20480/60000 (34.0%)]\tLoss: 0.048191\n",
      "Train Epoch: 36 [23040/60000 (38.3%)]\tLoss: 0.043552\n",
      "Train Epoch: 36 [25600/60000 (42.6%)]\tLoss: 0.049573\n",
      "Train Epoch: 36 [28160/60000 (46.8%)]\tLoss: 0.068607\n",
      "Train Epoch: 36 [30720/60000 (51.1%)]\tLoss: 0.049703\n",
      "Train Epoch: 36 [33280/60000 (55.3%)]\tLoss: 0.039920\n",
      "Train Epoch: 36 [35840/60000 (59.6%)]\tLoss: 0.096333\n",
      "Train Epoch: 36 [38400/60000 (63.8%)]\tLoss: 0.053475\n",
      "Train Epoch: 36 [40960/60000 (68.1%)]\tLoss: 0.048472\n",
      "Train Epoch: 36 [43520/60000 (72.3%)]\tLoss: 0.074518\n",
      "Train Epoch: 36 [46080/60000 (76.6%)]\tLoss: 0.056572\n",
      "Train Epoch: 36 [48640/60000 (80.9%)]\tLoss: 0.075769\n",
      "Train Epoch: 36 [51200/60000 (85.1%)]\tLoss: 0.058861\n",
      "Train Epoch: 36 [53760/60000 (89.4%)]\tLoss: 0.041013\n",
      "Train Epoch: 36 [56320/60000 (93.6%)]\tLoss: 0.035046\n",
      "Train Epoch: 36 [58880/60000 (97.9%)]\tLoss: 0.024248\n",
      "\n",
      "Test set: Average loss: 0.4555, Accuracy: 9085/10000 (90.8%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0.0%)]\tLoss: 0.066644\n",
      "Train Epoch: 37 [2560/60000 (4.3%)]\tLoss: 0.031817\n",
      "Train Epoch: 37 [5120/60000 (8.5%)]\tLoss: 0.017137\n",
      "Train Epoch: 37 [7680/60000 (12.8%)]\tLoss: 0.021714\n",
      "Train Epoch: 37 [10240/60000 (17.0%)]\tLoss: 0.031995\n",
      "Train Epoch: 37 [12800/60000 (21.3%)]\tLoss: 0.056944\n",
      "Train Epoch: 37 [15360/60000 (25.5%)]\tLoss: 0.028159\n",
      "Train Epoch: 37 [17920/60000 (29.8%)]\tLoss: 0.032543\n",
      "Train Epoch: 37 [20480/60000 (34.0%)]\tLoss: 0.091487\n",
      "Train Epoch: 37 [23040/60000 (38.3%)]\tLoss: 0.043854\n",
      "Train Epoch: 37 [25600/60000 (42.6%)]\tLoss: 0.040254\n",
      "Train Epoch: 37 [28160/60000 (46.8%)]\tLoss: 0.135220\n",
      "Train Epoch: 37 [30720/60000 (51.1%)]\tLoss: 0.116122\n",
      "Train Epoch: 37 [33280/60000 (55.3%)]\tLoss: 0.133284\n",
      "Train Epoch: 37 [35840/60000 (59.6%)]\tLoss: 0.075567\n",
      "Train Epoch: 37 [38400/60000 (63.8%)]\tLoss: 0.059354\n",
      "Train Epoch: 37 [40960/60000 (68.1%)]\tLoss: 0.114229\n",
      "Train Epoch: 37 [43520/60000 (72.3%)]\tLoss: 0.081260\n",
      "Train Epoch: 37 [46080/60000 (76.6%)]\tLoss: 0.059492\n",
      "Train Epoch: 37 [48640/60000 (80.9%)]\tLoss: 0.028472\n",
      "Train Epoch: 37 [51200/60000 (85.1%)]\tLoss: 0.064553\n",
      "Train Epoch: 37 [53760/60000 (89.4%)]\tLoss: 0.021985\n",
      "Train Epoch: 37 [56320/60000 (93.6%)]\tLoss: 0.036166\n",
      "Train Epoch: 37 [58880/60000 (97.9%)]\tLoss: 0.054846\n",
      "\n",
      "Test set: Average loss: 0.4442, Accuracy: 9105/10000 (91.1%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0.0%)]\tLoss: 0.013811\n",
      "Train Epoch: 38 [2560/60000 (4.3%)]\tLoss: 0.043435\n",
      "Train Epoch: 38 [5120/60000 (8.5%)]\tLoss: 0.041835\n",
      "Train Epoch: 38 [7680/60000 (12.8%)]\tLoss: 0.029968\n",
      "Train Epoch: 38 [10240/60000 (17.0%)]\tLoss: 0.060040\n",
      "Train Epoch: 38 [12800/60000 (21.3%)]\tLoss: 0.035356\n",
      "Train Epoch: 38 [15360/60000 (25.5%)]\tLoss: 0.096395\n",
      "Train Epoch: 38 [17920/60000 (29.8%)]\tLoss: 0.087619\n",
      "Train Epoch: 38 [20480/60000 (34.0%)]\tLoss: 0.071979\n",
      "Train Epoch: 38 [23040/60000 (38.3%)]\tLoss: 0.109699\n",
      "Train Epoch: 38 [25600/60000 (42.6%)]\tLoss: 0.096514\n",
      "Train Epoch: 38 [28160/60000 (46.8%)]\tLoss: 0.125698\n",
      "Train Epoch: 38 [30720/60000 (51.1%)]\tLoss: 0.068325\n",
      "Train Epoch: 38 [33280/60000 (55.3%)]\tLoss: 0.035186\n",
      "Train Epoch: 38 [35840/60000 (59.6%)]\tLoss: 0.030451\n",
      "Train Epoch: 38 [38400/60000 (63.8%)]\tLoss: 0.042339\n",
      "Train Epoch: 38 [40960/60000 (68.1%)]\tLoss: 0.029682\n",
      "Train Epoch: 38 [43520/60000 (72.3%)]\tLoss: 0.063822\n",
      "Train Epoch: 38 [46080/60000 (76.6%)]\tLoss: 0.032886\n",
      "Train Epoch: 38 [48640/60000 (80.9%)]\tLoss: 0.019918\n",
      "Train Epoch: 38 [51200/60000 (85.1%)]\tLoss: 0.048113\n",
      "Train Epoch: 38 [53760/60000 (89.4%)]\tLoss: 0.034818\n",
      "Train Epoch: 38 [56320/60000 (93.6%)]\tLoss: 0.059010\n",
      "Train Epoch: 38 [58880/60000 (97.9%)]\tLoss: 0.042012\n",
      "\n",
      "Test set: Average loss: 0.4758, Accuracy: 9091/10000 (90.9%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0.0%)]\tLoss: 0.029637\n",
      "Train Epoch: 39 [2560/60000 (4.3%)]\tLoss: 0.063838\n",
      "Train Epoch: 39 [5120/60000 (8.5%)]\tLoss: 0.046587\n",
      "Train Epoch: 39 [7680/60000 (12.8%)]\tLoss: 0.059332\n",
      "Train Epoch: 39 [10240/60000 (17.0%)]\tLoss: 0.085710\n",
      "Train Epoch: 39 [12800/60000 (21.3%)]\tLoss: 0.037865\n",
      "Train Epoch: 39 [15360/60000 (25.5%)]\tLoss: 0.069108\n",
      "Train Epoch: 39 [17920/60000 (29.8%)]\tLoss: 0.066607\n",
      "Train Epoch: 39 [20480/60000 (34.0%)]\tLoss: 0.046182\n",
      "Train Epoch: 39 [23040/60000 (38.3%)]\tLoss: 0.064906\n",
      "Train Epoch: 39 [25600/60000 (42.6%)]\tLoss: 0.052709\n",
      "Train Epoch: 39 [28160/60000 (46.8%)]\tLoss: 0.032753\n",
      "Train Epoch: 39 [30720/60000 (51.1%)]\tLoss: 0.078292\n",
      "Train Epoch: 39 [33280/60000 (55.3%)]\tLoss: 0.044328\n",
      "Train Epoch: 39 [35840/60000 (59.6%)]\tLoss: 0.031749\n",
      "Train Epoch: 39 [38400/60000 (63.8%)]\tLoss: 0.034942\n",
      "Train Epoch: 39 [40960/60000 (68.1%)]\tLoss: 0.057195\n",
      "Train Epoch: 39 [43520/60000 (72.3%)]\tLoss: 0.024659\n",
      "Train Epoch: 39 [46080/60000 (76.6%)]\tLoss: 0.023990\n",
      "Train Epoch: 39 [48640/60000 (80.9%)]\tLoss: 0.037256\n",
      "Train Epoch: 39 [51200/60000 (85.1%)]\tLoss: 0.053911\n",
      "Train Epoch: 39 [53760/60000 (89.4%)]\tLoss: 0.061416\n",
      "Train Epoch: 39 [56320/60000 (93.6%)]\tLoss: 0.070828\n",
      "Train Epoch: 39 [58880/60000 (97.9%)]\tLoss: 0.115748\n",
      "\n",
      "Test set: Average loss: 0.5511, Accuracy: 9003/10000 (90.0%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0.0%)]\tLoss: 0.106342\n",
      "Train Epoch: 40 [2560/60000 (4.3%)]\tLoss: 0.048384\n",
      "Train Epoch: 40 [5120/60000 (8.5%)]\tLoss: 0.161776\n",
      "Train Epoch: 40 [7680/60000 (12.8%)]\tLoss: 0.122395\n",
      "Train Epoch: 40 [10240/60000 (17.0%)]\tLoss: 0.166771\n",
      "Train Epoch: 40 [12800/60000 (21.3%)]\tLoss: 0.058109\n",
      "Train Epoch: 40 [15360/60000 (25.5%)]\tLoss: 0.053030\n",
      "Train Epoch: 40 [17920/60000 (29.8%)]\tLoss: 0.062928\n",
      "Train Epoch: 40 [20480/60000 (34.0%)]\tLoss: 0.039119\n",
      "Train Epoch: 40 [23040/60000 (38.3%)]\tLoss: 0.025509\n",
      "Train Epoch: 40 [25600/60000 (42.6%)]\tLoss: 0.048186\n",
      "Train Epoch: 40 [28160/60000 (46.8%)]\tLoss: 0.047643\n",
      "Train Epoch: 40 [30720/60000 (51.1%)]\tLoss: 0.031593\n",
      "Train Epoch: 40 [33280/60000 (55.3%)]\tLoss: 0.047921\n",
      "Train Epoch: 40 [35840/60000 (59.6%)]\tLoss: 0.044464\n",
      "Train Epoch: 40 [38400/60000 (63.8%)]\tLoss: 0.028421\n",
      "Train Epoch: 40 [40960/60000 (68.1%)]\tLoss: 0.034660\n",
      "Train Epoch: 40 [43520/60000 (72.3%)]\tLoss: 0.058750\n",
      "Train Epoch: 40 [46080/60000 (76.6%)]\tLoss: 0.056491\n",
      "Train Epoch: 40 [48640/60000 (80.9%)]\tLoss: 0.018604\n",
      "Train Epoch: 40 [51200/60000 (85.1%)]\tLoss: 0.115151\n",
      "Train Epoch: 40 [53760/60000 (89.4%)]\tLoss: 0.127264\n",
      "Train Epoch: 40 [56320/60000 (93.6%)]\tLoss: 0.067609\n",
      "Train Epoch: 40 [58880/60000 (97.9%)]\tLoss: 0.073855\n",
      "\n",
      "Test set: Average loss: 0.5396, Accuracy: 8992/10000 (89.9%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0.0%)]\tLoss: 0.054930\n",
      "Train Epoch: 41 [2560/60000 (4.3%)]\tLoss: 0.079000\n",
      "Train Epoch: 41 [5120/60000 (8.5%)]\tLoss: 0.046920\n",
      "Train Epoch: 41 [7680/60000 (12.8%)]\tLoss: 0.064481\n",
      "Train Epoch: 41 [10240/60000 (17.0%)]\tLoss: 0.042046\n",
      "Train Epoch: 41 [12800/60000 (21.3%)]\tLoss: 0.035715\n",
      "Train Epoch: 41 [15360/60000 (25.5%)]\tLoss: 0.030563\n",
      "Train Epoch: 41 [17920/60000 (29.8%)]\tLoss: 0.042153\n",
      "Train Epoch: 41 [20480/60000 (34.0%)]\tLoss: 0.057555\n",
      "Train Epoch: 41 [23040/60000 (38.3%)]\tLoss: 0.025428\n",
      "Train Epoch: 41 [25600/60000 (42.6%)]\tLoss: 0.015843\n",
      "Train Epoch: 41 [28160/60000 (46.8%)]\tLoss: 0.052261\n",
      "Train Epoch: 41 [30720/60000 (51.1%)]\tLoss: 0.029418\n",
      "Train Epoch: 41 [33280/60000 (55.3%)]\tLoss: 0.035905\n",
      "Train Epoch: 41 [35840/60000 (59.6%)]\tLoss: 0.072255\n",
      "Train Epoch: 41 [38400/60000 (63.8%)]\tLoss: 0.071869\n",
      "Train Epoch: 41 [40960/60000 (68.1%)]\tLoss: 0.034461\n",
      "Train Epoch: 41 [43520/60000 (72.3%)]\tLoss: 0.067694\n",
      "Train Epoch: 41 [46080/60000 (76.6%)]\tLoss: 0.085291\n",
      "Train Epoch: 41 [48640/60000 (80.9%)]\tLoss: 0.079994\n",
      "Train Epoch: 41 [51200/60000 (85.1%)]\tLoss: 0.050701\n",
      "Train Epoch: 41 [53760/60000 (89.4%)]\tLoss: 0.114233\n",
      "Train Epoch: 41 [56320/60000 (93.6%)]\tLoss: 0.040970\n",
      "Train Epoch: 41 [58880/60000 (97.9%)]\tLoss: 0.057072\n",
      "\n",
      "Test set: Average loss: 0.4511, Accuracy: 9053/10000 (90.5%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0.0%)]\tLoss: 0.053160\n",
      "Train Epoch: 42 [2560/60000 (4.3%)]\tLoss: 0.021763\n",
      "Train Epoch: 42 [5120/60000 (8.5%)]\tLoss: 0.033202\n",
      "Train Epoch: 42 [7680/60000 (12.8%)]\tLoss: 0.031857\n",
      "Train Epoch: 42 [10240/60000 (17.0%)]\tLoss: 0.025990\n",
      "Train Epoch: 42 [12800/60000 (21.3%)]\tLoss: 0.033478\n",
      "Train Epoch: 42 [15360/60000 (25.5%)]\tLoss: 0.036313\n",
      "Train Epoch: 42 [17920/60000 (29.8%)]\tLoss: 0.018308\n",
      "Train Epoch: 42 [20480/60000 (34.0%)]\tLoss: 0.041453\n",
      "Train Epoch: 42 [23040/60000 (38.3%)]\tLoss: 0.044443\n",
      "Train Epoch: 42 [25600/60000 (42.6%)]\tLoss: 0.028083\n",
      "Train Epoch: 42 [28160/60000 (46.8%)]\tLoss: 0.044850\n",
      "Train Epoch: 42 [30720/60000 (51.1%)]\tLoss: 0.052672\n",
      "Train Epoch: 42 [33280/60000 (55.3%)]\tLoss: 0.053394\n",
      "Train Epoch: 42 [35840/60000 (59.6%)]\tLoss: 0.127711\n",
      "Train Epoch: 42 [38400/60000 (63.8%)]\tLoss: 0.064327\n",
      "Train Epoch: 42 [40960/60000 (68.1%)]\tLoss: 0.077968\n",
      "Train Epoch: 42 [43520/60000 (72.3%)]\tLoss: 0.064411\n",
      "Train Epoch: 42 [46080/60000 (76.6%)]\tLoss: 0.042084\n",
      "Train Epoch: 42 [48640/60000 (80.9%)]\tLoss: 0.063201\n",
      "Train Epoch: 42 [51200/60000 (85.1%)]\tLoss: 0.061144\n",
      "Train Epoch: 42 [53760/60000 (89.4%)]\tLoss: 0.052414\n",
      "Train Epoch: 42 [56320/60000 (93.6%)]\tLoss: 0.015829\n",
      "Train Epoch: 42 [58880/60000 (97.9%)]\tLoss: 0.040728\n",
      "\n",
      "Test set: Average loss: 0.4775, Accuracy: 9075/10000 (90.8%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0.0%)]\tLoss: 0.020844\n",
      "Train Epoch: 43 [2560/60000 (4.3%)]\tLoss: 0.039797\n",
      "Train Epoch: 43 [5120/60000 (8.5%)]\tLoss: 0.030908\n",
      "Train Epoch: 43 [7680/60000 (12.8%)]\tLoss: 0.032963\n",
      "Train Epoch: 43 [10240/60000 (17.0%)]\tLoss: 0.035311\n",
      "Train Epoch: 43 [12800/60000 (21.3%)]\tLoss: 0.034877\n",
      "Train Epoch: 43 [15360/60000 (25.5%)]\tLoss: 0.056937\n",
      "Train Epoch: 43 [17920/60000 (29.8%)]\tLoss: 0.036989\n",
      "Train Epoch: 43 [20480/60000 (34.0%)]\tLoss: 0.061491\n",
      "Train Epoch: 43 [23040/60000 (38.3%)]\tLoss: 0.050762\n",
      "Train Epoch: 43 [25600/60000 (42.6%)]\tLoss: 0.083350\n",
      "Train Epoch: 43 [28160/60000 (46.8%)]\tLoss: 0.080183\n",
      "Train Epoch: 43 [30720/60000 (51.1%)]\tLoss: 0.062962\n",
      "Train Epoch: 43 [33280/60000 (55.3%)]\tLoss: 0.142109\n",
      "Train Epoch: 43 [35840/60000 (59.6%)]\tLoss: 0.093885\n",
      "Train Epoch: 43 [38400/60000 (63.8%)]\tLoss: 0.043889\n",
      "Train Epoch: 43 [40960/60000 (68.1%)]\tLoss: 0.049448\n",
      "Train Epoch: 43 [43520/60000 (72.3%)]\tLoss: 0.050494\n",
      "Train Epoch: 43 [46080/60000 (76.6%)]\tLoss: 0.033485\n",
      "Train Epoch: 43 [48640/60000 (80.9%)]\tLoss: 0.023054\n",
      "Train Epoch: 43 [51200/60000 (85.1%)]\tLoss: 0.082028\n",
      "Train Epoch: 43 [53760/60000 (89.4%)]\tLoss: 0.058812\n",
      "Train Epoch: 43 [56320/60000 (93.6%)]\tLoss: 0.073174\n",
      "Train Epoch: 43 [58880/60000 (97.9%)]\tLoss: 0.018626\n",
      "\n",
      "Test set: Average loss: 0.4730, Accuracy: 9101/10000 (91.0%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0.0%)]\tLoss: 0.057146\n",
      "Train Epoch: 44 [2560/60000 (4.3%)]\tLoss: 0.033878\n",
      "Train Epoch: 44 [5120/60000 (8.5%)]\tLoss: 0.054027\n",
      "Train Epoch: 44 [7680/60000 (12.8%)]\tLoss: 0.032852\n",
      "Train Epoch: 44 [10240/60000 (17.0%)]\tLoss: 0.040835\n",
      "Train Epoch: 44 [12800/60000 (21.3%)]\tLoss: 0.019682\n",
      "Train Epoch: 44 [15360/60000 (25.5%)]\tLoss: 0.084040\n",
      "Train Epoch: 44 [17920/60000 (29.8%)]\tLoss: 0.067464\n",
      "Train Epoch: 44 [20480/60000 (34.0%)]\tLoss: 0.060359\n",
      "Train Epoch: 44 [23040/60000 (38.3%)]\tLoss: 0.055862\n",
      "Train Epoch: 44 [25600/60000 (42.6%)]\tLoss: 0.064849\n",
      "Train Epoch: 44 [28160/60000 (46.8%)]\tLoss: 0.073488\n",
      "Train Epoch: 44 [30720/60000 (51.1%)]\tLoss: 0.056795\n",
      "Train Epoch: 44 [33280/60000 (55.3%)]\tLoss: 0.043753\n",
      "Train Epoch: 44 [35840/60000 (59.6%)]\tLoss: 0.026386\n",
      "Train Epoch: 44 [38400/60000 (63.8%)]\tLoss: 0.048077\n",
      "Train Epoch: 44 [40960/60000 (68.1%)]\tLoss: 0.054289\n",
      "Train Epoch: 44 [43520/60000 (72.3%)]\tLoss: 0.041956\n",
      "Train Epoch: 44 [46080/60000 (76.6%)]\tLoss: 0.041208\n",
      "Train Epoch: 44 [48640/60000 (80.9%)]\tLoss: 0.028395\n",
      "Train Epoch: 44 [51200/60000 (85.1%)]\tLoss: 0.054217\n",
      "Train Epoch: 44 [53760/60000 (89.4%)]\tLoss: 0.059881\n",
      "Train Epoch: 44 [56320/60000 (93.6%)]\tLoss: 0.047435\n",
      "Train Epoch: 44 [58880/60000 (97.9%)]\tLoss: 0.029385\n",
      "\n",
      "Test set: Average loss: 0.5594, Accuracy: 9054/10000 (90.5%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0.0%)]\tLoss: 0.048717\n",
      "Train Epoch: 45 [2560/60000 (4.3%)]\tLoss: 0.055092\n",
      "Train Epoch: 45 [5120/60000 (8.5%)]\tLoss: 0.073380\n",
      "Train Epoch: 45 [7680/60000 (12.8%)]\tLoss: 0.094581\n",
      "Train Epoch: 45 [10240/60000 (17.0%)]\tLoss: 0.075606\n",
      "Train Epoch: 45 [12800/60000 (21.3%)]\tLoss: 0.082800\n",
      "Train Epoch: 45 [15360/60000 (25.5%)]\tLoss: 0.043918\n",
      "Train Epoch: 45 [17920/60000 (29.8%)]\tLoss: 0.077473\n",
      "Train Epoch: 45 [20480/60000 (34.0%)]\tLoss: 0.082609\n",
      "Train Epoch: 45 [23040/60000 (38.3%)]\tLoss: 0.089134\n",
      "Train Epoch: 45 [25600/60000 (42.6%)]\tLoss: 0.059904\n",
      "Train Epoch: 45 [28160/60000 (46.8%)]\tLoss: 0.066497\n",
      "Train Epoch: 45 [30720/60000 (51.1%)]\tLoss: 0.026339\n",
      "Train Epoch: 45 [33280/60000 (55.3%)]\tLoss: 0.037174\n",
      "Train Epoch: 45 [35840/60000 (59.6%)]\tLoss: 0.025826\n",
      "Train Epoch: 45 [38400/60000 (63.8%)]\tLoss: 0.060929\n",
      "Train Epoch: 45 [40960/60000 (68.1%)]\tLoss: 0.039476\n",
      "Train Epoch: 45 [43520/60000 (72.3%)]\tLoss: 0.040072\n",
      "Train Epoch: 45 [46080/60000 (76.6%)]\tLoss: 0.047300\n",
      "Train Epoch: 45 [48640/60000 (80.9%)]\tLoss: 0.026206\n",
      "Train Epoch: 45 [51200/60000 (85.1%)]\tLoss: 0.047797\n",
      "Train Epoch: 45 [53760/60000 (89.4%)]\tLoss: 0.041134\n",
      "Train Epoch: 45 [56320/60000 (93.6%)]\tLoss: 0.115846\n",
      "Train Epoch: 45 [58880/60000 (97.9%)]\tLoss: 0.095556\n",
      "\n",
      "Test set: Average loss: 0.5637, Accuracy: 8964/10000 (89.6%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0.0%)]\tLoss: 0.064867\n",
      "Train Epoch: 46 [2560/60000 (4.3%)]\tLoss: 0.150916\n",
      "Train Epoch: 46 [5120/60000 (8.5%)]\tLoss: 0.118552\n",
      "Train Epoch: 46 [7680/60000 (12.8%)]\tLoss: 0.102320\n",
      "Train Epoch: 46 [10240/60000 (17.0%)]\tLoss: 0.051482\n",
      "Train Epoch: 46 [12800/60000 (21.3%)]\tLoss: 0.086775\n",
      "Train Epoch: 46 [15360/60000 (25.5%)]\tLoss: 0.029520\n",
      "Train Epoch: 46 [17920/60000 (29.8%)]\tLoss: 0.062597\n",
      "Train Epoch: 46 [20480/60000 (34.0%)]\tLoss: 0.075436\n",
      "Train Epoch: 46 [23040/60000 (38.3%)]\tLoss: 0.045920\n",
      "Train Epoch: 46 [25600/60000 (42.6%)]\tLoss: 0.027359\n",
      "Train Epoch: 46 [28160/60000 (46.8%)]\tLoss: 0.018549\n",
      "Train Epoch: 46 [30720/60000 (51.1%)]\tLoss: 0.055596\n",
      "Train Epoch: 46 [33280/60000 (55.3%)]\tLoss: 0.045712\n",
      "Train Epoch: 46 [35840/60000 (59.6%)]\tLoss: 0.029224\n",
      "Train Epoch: 46 [38400/60000 (63.8%)]\tLoss: 0.026317\n",
      "Train Epoch: 46 [40960/60000 (68.1%)]\tLoss: 0.048663\n",
      "Train Epoch: 46 [43520/60000 (72.3%)]\tLoss: 0.027236\n",
      "Train Epoch: 46 [46080/60000 (76.6%)]\tLoss: 0.069723\n",
      "Train Epoch: 46 [48640/60000 (80.9%)]\tLoss: 0.066778\n",
      "Train Epoch: 46 [51200/60000 (85.1%)]\tLoss: 0.082870\n",
      "Train Epoch: 46 [53760/60000 (89.4%)]\tLoss: 0.037556\n",
      "Train Epoch: 46 [56320/60000 (93.6%)]\tLoss: 0.076007\n",
      "Train Epoch: 46 [58880/60000 (97.9%)]\tLoss: 0.042672\n",
      "\n",
      "Test set: Average loss: 0.5100, Accuracy: 9058/10000 (90.6%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0.0%)]\tLoss: 0.018933\n",
      "Train Epoch: 47 [2560/60000 (4.3%)]\tLoss: 0.039736\n",
      "Train Epoch: 47 [5120/60000 (8.5%)]\tLoss: 0.069331\n",
      "Train Epoch: 47 [7680/60000 (12.8%)]\tLoss: 0.031166\n",
      "Train Epoch: 47 [10240/60000 (17.0%)]\tLoss: 0.023112\n",
      "Train Epoch: 47 [12800/60000 (21.3%)]\tLoss: 0.026128\n",
      "Train Epoch: 47 [15360/60000 (25.5%)]\tLoss: 0.022967\n",
      "Train Epoch: 47 [17920/60000 (29.8%)]\tLoss: 0.036381\n",
      "Train Epoch: 47 [20480/60000 (34.0%)]\tLoss: 0.032209\n",
      "Train Epoch: 47 [23040/60000 (38.3%)]\tLoss: 0.009438\n",
      "Train Epoch: 47 [25600/60000 (42.6%)]\tLoss: 0.033136\n",
      "Train Epoch: 47 [28160/60000 (46.8%)]\tLoss: 0.036846\n",
      "Train Epoch: 47 [30720/60000 (51.1%)]\tLoss: 0.028657\n",
      "Train Epoch: 47 [33280/60000 (55.3%)]\tLoss: 0.030925\n",
      "Train Epoch: 47 [35840/60000 (59.6%)]\tLoss: 0.055109\n",
      "Train Epoch: 47 [38400/60000 (63.8%)]\tLoss: 0.078159\n",
      "Train Epoch: 47 [40960/60000 (68.1%)]\tLoss: 0.105964\n",
      "Train Epoch: 47 [43520/60000 (72.3%)]\tLoss: 0.094117\n",
      "Train Epoch: 47 [46080/60000 (76.6%)]\tLoss: 0.054832\n",
      "Train Epoch: 47 [48640/60000 (80.9%)]\tLoss: 0.168083\n",
      "Train Epoch: 47 [51200/60000 (85.1%)]\tLoss: 0.057690\n",
      "Train Epoch: 47 [53760/60000 (89.4%)]\tLoss: 0.059942\n",
      "Train Epoch: 47 [56320/60000 (93.6%)]\tLoss: 0.052624\n",
      "Train Epoch: 47 [58880/60000 (97.9%)]\tLoss: 0.032844\n",
      "\n",
      "Test set: Average loss: 0.4797, Accuracy: 9072/10000 (90.7%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0.0%)]\tLoss: 0.024583\n",
      "Train Epoch: 48 [2560/60000 (4.3%)]\tLoss: 0.019126\n",
      "Train Epoch: 48 [5120/60000 (8.5%)]\tLoss: 0.031693\n",
      "Train Epoch: 48 [7680/60000 (12.8%)]\tLoss: 0.038251\n",
      "Train Epoch: 48 [10240/60000 (17.0%)]\tLoss: 0.029826\n",
      "Train Epoch: 48 [12800/60000 (21.3%)]\tLoss: 0.022060\n",
      "Train Epoch: 48 [15360/60000 (25.5%)]\tLoss: 0.036119\n",
      "Train Epoch: 48 [17920/60000 (29.8%)]\tLoss: 0.033992\n",
      "Train Epoch: 48 [20480/60000 (34.0%)]\tLoss: 0.045942\n",
      "Train Epoch: 48 [23040/60000 (38.3%)]\tLoss: 0.065484\n",
      "Train Epoch: 48 [25600/60000 (42.6%)]\tLoss: 0.032241\n",
      "Train Epoch: 48 [28160/60000 (46.8%)]\tLoss: 0.028831\n",
      "Train Epoch: 48 [30720/60000 (51.1%)]\tLoss: 0.073677\n",
      "Train Epoch: 48 [33280/60000 (55.3%)]\tLoss: 0.092542\n",
      "Train Epoch: 48 [35840/60000 (59.6%)]\tLoss: 0.092845\n",
      "Train Epoch: 48 [38400/60000 (63.8%)]\tLoss: 0.103278\n",
      "Train Epoch: 48 [40960/60000 (68.1%)]\tLoss: 0.079152\n",
      "Train Epoch: 48 [43520/60000 (72.3%)]\tLoss: 0.071955\n",
      "Train Epoch: 48 [46080/60000 (76.6%)]\tLoss: 0.045874\n",
      "Train Epoch: 48 [48640/60000 (80.9%)]\tLoss: 0.044703\n",
      "Train Epoch: 48 [51200/60000 (85.1%)]\tLoss: 0.043863\n",
      "Train Epoch: 48 [53760/60000 (89.4%)]\tLoss: 0.033558\n",
      "Train Epoch: 48 [56320/60000 (93.6%)]\tLoss: 0.035279\n",
      "Train Epoch: 48 [58880/60000 (97.9%)]\tLoss: 0.043454\n",
      "\n",
      "Test set: Average loss: 0.4797, Accuracy: 9112/10000 (91.1%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0.0%)]\tLoss: 0.016991\n",
      "Train Epoch: 49 [2560/60000 (4.3%)]\tLoss: 0.041959\n",
      "Train Epoch: 49 [5120/60000 (8.5%)]\tLoss: 0.031426\n",
      "Train Epoch: 49 [7680/60000 (12.8%)]\tLoss: 0.060063\n",
      "Train Epoch: 49 [10240/60000 (17.0%)]\tLoss: 0.016605\n",
      "Train Epoch: 49 [12800/60000 (21.3%)]\tLoss: 0.017404\n",
      "Train Epoch: 49 [15360/60000 (25.5%)]\tLoss: 0.039987\n",
      "Train Epoch: 49 [17920/60000 (29.8%)]\tLoss: 0.048767\n",
      "Train Epoch: 49 [20480/60000 (34.0%)]\tLoss: 0.042270\n",
      "Train Epoch: 49 [23040/60000 (38.3%)]\tLoss: 0.088733\n",
      "Train Epoch: 49 [25600/60000 (42.6%)]\tLoss: 0.088664\n",
      "Train Epoch: 49 [28160/60000 (46.8%)]\tLoss: 0.095828\n",
      "Train Epoch: 49 [30720/60000 (51.1%)]\tLoss: 0.049377\n",
      "Train Epoch: 49 [33280/60000 (55.3%)]\tLoss: 0.066437\n",
      "Train Epoch: 49 [35840/60000 (59.6%)]\tLoss: 0.081497\n",
      "Train Epoch: 49 [38400/60000 (63.8%)]\tLoss: 0.050832\n",
      "Train Epoch: 49 [40960/60000 (68.1%)]\tLoss: 0.053402\n",
      "Train Epoch: 49 [43520/60000 (72.3%)]\tLoss: 0.039173\n",
      "Train Epoch: 49 [46080/60000 (76.6%)]\tLoss: 0.036211\n",
      "Train Epoch: 49 [48640/60000 (80.9%)]\tLoss: 0.024657\n",
      "Train Epoch: 49 [51200/60000 (85.1%)]\tLoss: 0.036302\n",
      "Train Epoch: 49 [53760/60000 (89.4%)]\tLoss: 0.025482\n",
      "Train Epoch: 49 [56320/60000 (93.6%)]\tLoss: 0.029778\n",
      "Train Epoch: 49 [58880/60000 (97.9%)]\tLoss: 0.017988\n",
      "\n",
      "Test set: Average loss: 0.5221, Accuracy: 9088/10000 (90.9%)\n",
      "\n",
      "Best accuracy: 0.9133\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model(config_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def repr_and_saves(seed, cuda = False, log = 'logs', save = 'results', backup_path = 'backups'):\n",
    "#     torch.manual_seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     if cuda:\n",
    "#         torch.cuda.manual_seed(seed)\n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "#         torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#     if not os.path.exists(save):\n",
    "#         os.makedirs(save)\n",
    "#     if backup_path is not None and not os.path.exists(backup_path):\n",
    "#         os.makedirs(backup_path)\n",
    "#     if not os.path.exists(log):\n",
    "#         os.makedirs(log)\n",
    "\n",
    "# def get_loaders(batch_size, test_batch_size): \n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.FashionMNIST('./data.fashionMNIST', train=True, download=True,\n",
    "#                     transform=transforms.Compose([\n",
    "#                         transforms.Pad(2),\n",
    "#                         #transforms.RandomCrop(32),\n",
    "#                         #transforms.RandomHorizontalFlip(),\n",
    "#                         transforms.ToTensor(),\n",
    "#                         transforms.Normalize((0.5,), (0.5,))\n",
    "#                     ])),\n",
    "#     batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.FashionMNIST('./data.fashionMNIST', train=False, transform=transforms.Compose([\n",
    "#         transforms.Pad(2),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,), (0.5,))\n",
    "#     ])),\n",
    "#     batch_size=test_batch_size, shuffle=True)\n",
    "    \n",
    "#     return train_loader, test_loader\n",
    "\n",
    "\n",
    "# def freeze_sparse_gate(model: nn.Module):\n",
    "#     # do not update all SparseGate\n",
    "#     for sub_module in model.modules():\n",
    "#         if isinstance(sub_module, models.common.SparseGate):\n",
    "#             for p in sub_module.parameters():\n",
    "#                 # do not update SparseGate\n",
    "#                 p.requires_grad = False\n",
    "                \n",
    "# def define_optim(model, bn_wd, lr, momentum, weight_decay): \n",
    "#     if bn_wd:\n",
    "#         no_wd_type = [models.common.SparseGate]\n",
    "#     else:\n",
    "#         # do not apply weight decay on bn layers\n",
    "#         no_wd_type = [models.common.SparseGate, nn.BatchNorm2d, nn.BatchNorm1d]\n",
    "\n",
    "#     no_wd_params = []  # do not apply weight decay on these parameters\n",
    "#     for module_name, sub_module in model.named_modules():\n",
    "#         for t in no_wd_type:\n",
    "#             if isinstance(sub_module, t):\n",
    "#                 for param_name, param in sub_module.named_parameters():\n",
    "#                     no_wd_params.append(param)\n",
    "#                     print(f\"No weight decay param: module {module_name} param {param_name}\")\n",
    "\n",
    "#     no_wd_params_set = set(no_wd_params)  # apply weight decay on the rest of parameters\n",
    "#     wd_params = []\n",
    "#     for param_name, model_p in model.named_parameters():\n",
    "#         if model_p not in no_wd_params_set:\n",
    "#             wd_params.append(model_p)\n",
    "#             print(f\"Weight decay param: parameter name {param_name}\")\n",
    "\n",
    "#     optimizer = torch.optim.SGD([{'params': list(no_wd_params), 'weight_decay': 0.},\n",
    "#                                 {'params': list(wd_params), 'weight_decay': weight_decay}],\n",
    "#                                 lr,\n",
    "#                                 momentum=momentum)\n",
    "    \n",
    "#     return optimizer\n",
    "\n",
    "\n",
    "\n",
    "# def bn_weights(model):\n",
    "#     weights = []\n",
    "#     bias = []\n",
    "#     for name, m in model.named_modules():\n",
    "#         if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "#             weights.append((name, m.weight.data))\n",
    "#             bias.append((name, m.bias.data))\n",
    "\n",
    "#     return weights, bias\n",
    "#     pass\n",
    "\n",
    "\n",
    "# # def adjust_learning_rate(optimizer, epoch, gammas, schedule, config):\n",
    "# #     \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "# #     lr = config.get('lr')\n",
    "# #     assert len(gammas) == len(schedule), \"length of gammas and schedule should be equal\"\n",
    "# #     for (gamma, step) in zip(gammas, schedule):\n",
    "# #         if epoch >= step:\n",
    "# #             lr = lr * gamma\n",
    "# #         else:\n",
    "# #             break\n",
    "# #     for param_group in optimizer.param_groups:\n",
    "# #         param_group['lr'] = lr\n",
    "# #     return lr\n",
    "\n",
    "\n",
    "# # additional subgradient descent on the sparsity-induced penalty term\n",
    "# def updateBN(config, model):\n",
    "#     if config.get('loss') == LossType.L1_SPARSITY_REGULARIZATION:\n",
    "#         sparsity = config.get('lbd')\n",
    "#         bn_modules = list(filter(lambda m: (isinstance(m[1], nn.BatchNorm2d) or isinstance(m[1], nn.BatchNorm1d)),\n",
    "#                                  model.named_modules()))\n",
    "#         bn_modules = list(map(lambda m: m[1], bn_modules))  # remove module name\n",
    "#         for m in bn_modules:\n",
    "#             if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "#                 m.weight.grad.data.add_(sparsity * torch.sign(m.weight.data))\n",
    "#     else:\n",
    "#         raise NotImplementedError(f\"Do not support loss: {config.get('loss')}\")\n",
    "\n",
    "\n",
    "# def clamp_bn(model, lower_bound=0, upper_bound=1):\n",
    "#     if model.gate:\n",
    "#         sparse_modules = list(filter(lambda m: isinstance(m, SparseGate), model.modules()))\n",
    "#     else:\n",
    "#         sparse_modules = list(\n",
    "#             filter(lambda m: isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d), model.modules()))\n",
    "\n",
    "#     for m in sparse_modules:\n",
    "#         m.weight.data.clamp_(lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "# def set_bn_zero(model: nn.Module, threshold=0.0):\n",
    "#     \"\"\"\n",
    "#     Set bn bias to zero\n",
    "#     Note: The operation is inplace. Parameters of the model will be changed!\n",
    "#     :param model: to set\n",
    "#     :param threshold: set bn bias to zero if corresponding lambda <= threshold\n",
    "#     :return modified model, the number of zero bn channels\n",
    "#     \"\"\"\n",
    "#     with torch.no_grad():\n",
    "#         mask_length = 0\n",
    "#         for name, sub_module in model.named_modules():\n",
    "#             # only process bn modules\n",
    "#             if not (isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d)):\n",
    "#                 continue\n",
    "\n",
    "#             mask = sub_module.weight.detach() <= threshold\n",
    "#             sub_module.weight[mask] = 0.\n",
    "#             sub_module.bias[mask] = 0.\n",
    "\n",
    "#             mask_length += torch.sum(mask).item()\n",
    "\n",
    "#     return model, mask_length\n",
    "\n",
    "\n",
    "# def bn_sparsity(model, loss_type, sparsity, t, alpha,\n",
    "#                 flops_weighted: bool, weight_min=None, weight_max=None):\n",
    "#     \"\"\"\n",
    "\n",
    "#     :type model: torch.nn.Module\n",
    "#     :type alpha: float\n",
    "#     :type t: float\n",
    "#     :type sparsity: float\n",
    "#     :type loss_type: LossType\n",
    "#     \"\"\"\n",
    "#     bn_modules = model.get_sparse_layers()\n",
    "\n",
    "#     if loss_type == LossType.POLARIZATION or loss_type == LossType.L2_POLARIZATION:\n",
    "#         # compute global mean of all sparse vectors\n",
    "#         n_ = sum(map(lambda m: m.weight.data.shape[0], bn_modules))\n",
    "#         sparse_weights_mean = torch.sum(torch.stack(list(map(lambda m: torch.sum(m.weight), bn_modules)))) / n_\n",
    "\n",
    "#         sparsity_loss = 0.\n",
    "#         if flops_weighted:\n",
    "#             for sub_module in model.modules():\n",
    "#                 if isinstance(sub_module, model.building_block):\n",
    "#                     flops_weight = sub_module.get_conv_flops_weight(update=True, scaling=True)\n",
    "#                     sub_module_sparse_layers = sub_module.get_sparse_modules()\n",
    "\n",
    "#                     for sparse_m, flops_w in zip(sub_module_sparse_layers, flops_weight):\n",
    "#                         # linear rescale the weight from [0, 1] to [lambda_min, lambda_max]\n",
    "#                         flops_w = weight_min + (weight_max - weight_min) * flops_w\n",
    "\n",
    "#                         sparsity_term = t * torch.sum(torch.abs(sparse_m.weight.view(-1))) - torch.sum(\n",
    "#                             torch.abs(sparse_m.weight.view(-1) - alpha * sparse_weights_mean))\n",
    "#                         sparsity_loss += flops_w * sparsity * sparsity_term\n",
    "#             return sparsity_loss\n",
    "#         else:\n",
    "#             for m in bn_modules:\n",
    "#                 if loss_type == LossType.POLARIZATION:\n",
    "#                     sparsity_term = t * torch.sum(torch.abs(m.weight)) - torch.sum(\n",
    "#                         torch.abs(m.weight - alpha * sparse_weights_mean))\n",
    "#                 elif loss_type == LossType.L2_POLARIZATION:\n",
    "#                     sparsity_term = t * torch.sum(torch.abs(m.weight)) - torch.sum(\n",
    "#                         (m.weight - alpha * sparse_weights_mean) ** 2)\n",
    "#                 else:\n",
    "#                     raise ValueError(f\"Unexpected loss type: {loss_type}\")\n",
    "#                 sparsity_loss += sparsity * sparsity_term\n",
    "\n",
    "#             return sparsity_loss\n",
    "#     else:\n",
    "#         raise ValueError()\n",
    "\n",
    "\n",
    "# def train(model, epoch, train_loader, optimizer, lr_scheduler, config, history_score, global_step):\n",
    "#     model.train()\n",
    "#     #global history_score, global_step \n",
    "#     avg_loss = 0.\n",
    "#     avg_sparsity_loss = 0.\n",
    "#     train_acc = 0.\n",
    "#     total_data = 0\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         if config.get('cuda'):\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         if isinstance(output, tuple):\n",
    "#             output, output_aux = output\n",
    "#         loss = F.cross_entropy(output, target)\n",
    "\n",
    "#         # logging\n",
    "#         avg_loss += loss.data.item()\n",
    "#         pred = output.data.max(1, keepdim=True)[1]\n",
    "#         train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "#         total_data += target.data.shape[0]\n",
    "\n",
    "#         if config.get('loss') in {LossType.POLARIZATION,\n",
    "#                          LossType.L2_POLARIZATION}:\n",
    "#             sparsity_loss = bn_sparsity(model, config.get('loss'), config.get('lbd'),\n",
    "#                                         t=config.get('t'), alpha=config.get('alpha'),\n",
    "#                                         flops_weighted=config.get('flops_weighted'),\n",
    "#                                         weight_max=config.get('weight_max'), weight_min=config.get('weight_min'))\n",
    "#             loss += sparsity_loss\n",
    "#             avg_sparsity_loss += sparsity_loss.data.item()\n",
    "#         loss.backward()\n",
    "        \n",
    "#         if config.get('loss') in {LossType.L1_SPARSITY_REGULARIZATION}:\n",
    "#             updateBN(config, model)\n",
    "            \n",
    "#         optimizer.step()\n",
    "#         if config.get('loss') in {LossType.POLARIZATION,\n",
    "#                          LossType.L2_POLARIZATION}:\n",
    "#             clamp_bn(model, upper_bound=config.get('clamp'))\n",
    "#         global_step += 1\n",
    "        \n",
    "#         lr_scheduler.step()\n",
    "        \n",
    "#         if batch_idx % config.get('log_interval') == 0:\n",
    "#             print('Step: {} Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 global_step, epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                                     100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "#     history_score[epoch][0] = avg_loss / len(train_loader)\n",
    "#     history_score[epoch][1] = float(train_acc) / float(total_data)\n",
    "#     history_score[epoch][3] = avg_sparsity_loss / len(train_loader)\n",
    "#     return history_score, global_step\n",
    "\n",
    "\n",
    "# def test(model, test_loader, config):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             if config.get('cuda'):\n",
    "#                 data, target = data.cuda(), target.cuda()\n",
    "#             output = model(data)\n",
    "#             if isinstance(output, tuple):\n",
    "#                 output, output_aux = output\n",
    "#             test_loss += F.cross_entropy(output, target, size_average=False).data.item()  # sum up batch loss\n",
    "#             pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * float(correct) / len(test_loader.dataset)))\n",
    "#     return float(correct) / float(len(test_loader.dataset))\n",
    "\n",
    "\n",
    "# def save_checkpoint(state, is_best, filepath, backup: bool, backup_path: str, epoch: int, max_backup: int, config):\n",
    "#     state['config'] = config\n",
    "\n",
    "#     torch.save(state, os.path.join(filepath, 'checkpoint.pth.tar'))\n",
    "#     if is_best:\n",
    "#         shutil.copyfile(os.path.join(filepath, 'checkpoint.pth.tar'), os.path.join(filepath, 'model_best.pth.tar'))\n",
    "#     if backup and backup_path is not None:\n",
    "#         shutil.copyfile(os.path.join(filepath, 'checkpoint.pth.tar'),\n",
    "#                         os.path.join(backup_path, 'checkpoint_{}.pth.tar'.format(epoch)))\n",
    "\n",
    "#         if max_backup is not None:\n",
    "#             while True:\n",
    "#                 # remove redundant backup checkpoints to save space\n",
    "#                 checkpoint_match = map(lambda f_name: re.fullmatch(\"checkpoint_([0-9]+).pth.tar\", f_name),\n",
    "#                                        os.listdir(backup_path))\n",
    "#                 checkpoint_match = filter(lambda m: m is not None, checkpoint_match)\n",
    "#                 checkpoint_id: typing.List[int] = list(map(lambda m: int(m.group(1)), checkpoint_match))\n",
    "#                 checkpoint_count = len(checkpoint_id)\n",
    "#                 if checkpoint_count > max_backup:\n",
    "#                     min_checkpoint_epoch = min(checkpoint_id)\n",
    "#                     min_checkpoint_path = os.path.join(backup_path,\n",
    "#                                                        'checkpoint_{}.pth.tar'.format(min_checkpoint_epoch))\n",
    "#                     print(f\"Too much checkpoints (Max {max_backup}, got {checkpoint_count}).\")\n",
    "#                     print(f\"Remove file: {min_checkpoint_path}\")\n",
    "#                     os.remove(min_checkpoint_path)\n",
    "#                 else:\n",
    "#                     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_model(config): \n",
    "#     config['cuda'] = not config.get('no_cuda') and torch.cuda.is_available()\n",
    "#     config['loss'] = LossType.from_string(config.get('loss'))\n",
    "#     #config.get('decay_epoch') = sorted([int(config.get('epochs') * i if i < 1 else i) for i in config.get('decay_epoch')])\n",
    "#     if not config.get('seed'):\n",
    "#         config['seed'] = random.randint(500, 1000)\n",
    "    \n",
    "#     repr_and_saves(config.get('seed'))\n",
    "\n",
    "#     train_loader, test_loader = get_loaders(config.get('batch_size'), config.get('test_batch_size'))\n",
    "#     num_classes = 10 \n",
    "    \n",
    "    \n",
    "#     if not config.get('retrain'):\n",
    "#         model = LeNet5(gate=config.get('gate'), bn_init_value=config.get('bn_init_value'))\n",
    "#     else:  # initialize model for retraining with configs\n",
    "#         checkpoint = torch.load(config.get('retrain'))\n",
    "#         if config.get('arch') == \"leNet\":\n",
    "#             model = models.__dict__[config.get('arch')](num_classes=num_classes, cfg=checkpoint['cfg'])\n",
    "#         else:\n",
    "#             raise NotImplementedError(f\"Do not support {config.get('arch')} for retrain.\")\n",
    "        \n",
    "#     if config.get('fix_gate'):\n",
    "#         if config.get('lbd') != 0:\n",
    "#             raise ValueError(\"The lambda must be 0 in fix-gate mode.\")\n",
    "#         # do not update all SparseGate\n",
    "#         freeze_sparse_gate(model)\n",
    "        \n",
    "#     optimizer = define_optim(model, config.get('bn_wd'), config.get('lr'), config.get('momentum'), config.get('weight_decay'))\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 100, eta_min=0.0, last_epoch=-1, verbose='deprecated')\n",
    "    \n",
    "#     best_prec1 = 0.0\n",
    "#     global_step = 0\n",
    "#     writer = SummaryWriter(logdir=config.get('log', 'logs'))\n",
    "#     history_score = np.zeros((config.get('epochs'), 6))\n",
    "\n",
    "#     for epoch in range(config.get('start_epoch', 0), config.get('epochs')):\n",
    "#         if config.get('max_epoch') is not None and epoch >= config.get('max_epoch'):\n",
    "#             break\n",
    "\n",
    "#         #current_learning_rate = adjust_learning_rate(optimizer, epoch, config.get('gammas'), config.get('decay_epoch'), config)\n",
    "#         print(\"Start epoch {}/{}...\".format(epoch, config.get('epochs')))\n",
    "\n",
    "#         #weights, bias = bn_weights(model)\n",
    "        \n",
    "#         weights, bias = bn_weights(model)\n",
    "#         for bn_name, bn_weight in weights:\n",
    "#             writer.add_histogram(\"bn/\" + bn_name, bn_weight, global_step=epoch)\n",
    "#         for bn_name, bn_bias in bias:\n",
    "#             writer.add_histogram(\"bn_bias/\" + bn_name, bn_bias, global_step=epoch)\n",
    "#         # visualize conv kernels\n",
    "#         for name, sub_modules in model.named_modules():\n",
    "#             if isinstance(sub_modules, nn.Conv2d):\n",
    "#                 writer.add_histogram(\"conv_kernels/\" + name, sub_modules.weight, global_step=epoch)\n",
    "#         if config['gate']:\n",
    "#             for gate_name, m in model.named_modules():\n",
    "#                 if isinstance(m, SparseGate):\n",
    "#                     writer.add_histogram(\"gate/\" + gate_name, m.weight, global_step=epoch)\n",
    "\n",
    "        \n",
    "#         history_score, global_step = train(model, epoch, train_loader, optimizer, lr_scheduler, config, history_score, global_step)\n",
    "\n",
    "#         prec1 = test(model, test_loader, config)\n",
    "#         history_score[epoch][2] = prec1\n",
    "#         np.savetxt(os.path.join(config.get('save'), 'record.txt'), history_score, fmt='%10.5f', delimiter=',')\n",
    "#         is_best = prec1 > best_prec1\n",
    "#         best_prec1 = max(prec1, best_prec1)\n",
    "#         save_checkpoint({\n",
    "#             'epoch': epoch + 1,\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'best_prec1': best_prec1,\n",
    "#             'optimizer': optimizer.state_dict(),\n",
    "#         }, is_best, filepath=config.get('save', 'results'),\n",
    "#             backup_path=config.get('backup_path', 'backups'),\n",
    "#             backup=epoch % config.get('backup_freq', 10) == 0,\n",
    "#             epoch=epoch,\n",
    "#             max_backup=config.get('max_backup', 25), \n",
    "#             config = config\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#         # write the tensorboard\n",
    "#         writer.add_scalar(\"train/average_loss\", history_score[epoch][0], epoch)\n",
    "#         writer.add_scalar(\"train/sparsity_loss\", history_score[epoch][3], epoch)\n",
    "#         writer.add_scalar(\"train/train_acc\", history_score[epoch][1], epoch)\n",
    "#         writer.add_scalar(\"train/lr\", optimizer.param_groups[0]['lr'], epoch)\n",
    "#         writer.add_scalar(\"val/acc\", prec1, epoch)\n",
    "#         writer.add_scalar(\"val/best_acc\", best_prec1, epoch)\n",
    "\n",
    "\n",
    "#         # flops\n",
    "#         # if config.get('loss') in {LossType.POLARIZATION, LossType.L2_POLARIZATION}:\n",
    "#         #     flops_grad, flops_fixed, baseline_flops = prune_while_training(model, arch=config.get('arch'),\n",
    "#         #                                                                 prune_mode=\"default\",\n",
    "#         #                                                                 num_classes=num_classes)\n",
    "#         #     print(f\" --> FLOPs in epoch (grad) {epoch}: {flops_grad:,}, ratio: {flops_grad / baseline_flops}\")\n",
    "#         #     print(f\" --> FLOPs in epoch (fixed) {epoch}: {flops_fixed:,}, ratio: {flops_fixed / baseline_flops}\")\n",
    "#         #     if config.get('loss') == LossType.POLARIZATION and config.get('target_flops') and (\n",
    "#         #             flops_grad / baseline_flops) <= config.get('target_flops') and config.get('gate'):\n",
    "#         #         print(\"The grad pruning FLOPs archieve the target FLOPs.\")\n",
    "#         #         print(f\"Current pruning ratio: {flops_grad / baseline_flops}\")\n",
    "#         #         print(\"Stop polarization from current epoch and continue training.\")\n",
    "\n",
    "#         #         # do not apply polarization loss\n",
    "#         #         config['lbd'] = 0\n",
    "#         #         freeze_sparse_gate(model)\n",
    "#         #         if config.get('backup_freq') > 20:\n",
    "#         #             config['backup_freq'] = 20\n",
    "\n",
    "#     # if config.get('loss') == LossType.POLARIZATION and config.get('target_flops') and (\n",
    "#     #         flops_grad / baseline_flops) > config.get('target_flops') and config.get('gate'):\n",
    "#     #     print(\"WARNING: the FLOPs does not achieve the target FLOPs at the end of training.\")\n",
    "#     print(\"Best accuracy: \" + str(best_prec1))\n",
    "#     history_score[-1][0] = best_prec1\n",
    "#     np.savetxt(os.path.join(config.get('save'), 'record.txt'), history_score, fmt='%10.5f', delimiter=',')\n",
    "\n",
    "#     writer.close()\n",
    "\n",
    "#     print(\"Best accuracy: \" + str(best_prec1))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
